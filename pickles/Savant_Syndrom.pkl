(iversion
Page
p1
(dp2
S'revisions'
p3
(lp4
(iversion
Version
p5
(dp6
S'date'
p7
cdatetime
datetime
p8
(S'\x07\xde\x0c\x11\x0f2\x06\x04x\x88'
tRp9
sS'text'
p10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p11
sS'paragraphs'
p12
(lp13
(iversion
Paragraph
p14
(dp15
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose anintelligent assistive system with two primary tasks. First, it shoulddetect important edits and promote them to the relevant authors. Second,it should anticipate possible semantic conflicts between variousauthors' contributions, alerting when appropriate in order to ensurethat the writing process goes smoothly."
p16
sS'changed'
p17
I00
sS'nextindex'
p18
NsS'lastindex'
p19
Nsba(iversion
Paragraph
p20
(dp21
g10
S'When authors collaborate on a paper, they need to communicate constantlyto ensure they are on the same page. Because the authors need to makesure their edits are coherent with the rest of the paper, includingsections written by others, they need to read the entire paperfrequently, or rely on updates communicated by their co-authors. Evenwith constant communication, authors can get lost in the volume of editsfrom other collaborators. Further, Kittur et al. have shown that in acollaborative environment such as Wikipedia, the majority of edits nolonger add content but instead do maintenance work and add discussions\\cite{kittur2007he}. Therefore, an assistive system with a summary ofthe significant changes contributed by other authors would be helpful,as shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p22
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p23
(dp24
g10
S"We hypothesized that when an author makes a significant edit to aparagraph, it eventually triggers a series of adjustments in relatedparagraphs. In fact, a significant edit prompted changes in relatedparagraphs eighty percent of the time. However, in collaborativewriting, these resulting edits do not occur instantaneously. Beforethese adjustments occur, semantic conflicts might occur between theauthors' content. Instead of waiting for other authors to discover theinconsistency caused by one author's edit, we want an assistive systemto predict when and where these conflicts may occur, in order to alerteven more specifically."
p25
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p26
(dp27
g10
S'In order to achieve this, the system is composed of the following threecomponents: (1) tracking paragraphs; (2) identifying significant changesto paragraphs, and (3) predicting future changes to the article.'
p28
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p29
(dp30
g10
S'Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes helps the system promote only the mostimportant changes and decide whether to alert collaborating authors.'
p31
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p32
(dp33
g10
S"Predicting future changes enables the system to not only report changesthat have already been made, but also draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p34
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p35
(dp36
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve thewriting process, as shown by Birnholtz et al.'
p37
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p38
(dp39
g10
S'\\cite{birnholtz2012tracking}.There has been some research on the topicof analyzing relevant changes between two versions of a text. Neuwirthet al. use flexible diffing \\cite{neuwirth1992flexible} to detect andreport important changes. Fong et al. attempt to categorize edits\\cite{fong2010did}, which, according to Papadopoulou et al.'
p40
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p41
(dp42
g10
S'\\cite{papadopoulou2007structured}, can be useful for detecting importantchanges. Tam et al. developed an interface to show these categorizedchanges to users \\cite{tam2006framework}. Hainsworth et al.'
p43
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p44
(dp45
g10
S'\\cite{hainsworth2006enabling} detect and alert authors about mergeconflicts. De Silva uses edit histories in order to find structurewithin a text and to help co-authors write coherent documents\\cite{de2007narrative}. Nunes et al. analyze the impact of public eventson the frequency of edits in the collaborative writing environment,Wikipedia, and argue that edits are predictable\\cite{nunes2008wikichanges}.'
p46
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p47
(dp48
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a widevariety of Wikipedia articles that undergo intense editing processes.'
p49
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p50
(dp51
g10
S'Wikipedia is a unique source because it presents extensive data forcollaborative writing. The findings use the complete revision revisionhistory of 41 different articles chosen from a diverse set of topics,from famous people and places to mathematical algorithms to novels. Thisapproach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions with consequential changes, theversions with simple typo fixes~\\footnote{We defined minor edits as  having a Levenshtein distance of under fifteen.} were eliminated aswell to reduce the number of maintenance edits \\cite{kittur2007he}. Thisresulted in a total of 17,199 versions across the 41 articles, with anaverage length of 25.71 paragraphs. Wikipedia data affords resultsapplicable to other collaborative writing spaces, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In fact, on average, 15 authors make 80\\% of theedits to an article (see Figure~{[}fig:authors{]}). This enables theconsideration of interactions between authors, which is crucial forlearning about collaborative behavior.'
p52
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p53
(dp54
g10
S'\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein editratio measure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision, we computed the Levenshtein ratio betweeneach paragraph in the old version and each paragraph in the new version.'
p55
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p56
(dp57
g10
S"Two paragraphs are mapped across the revision if they each had thehighest Levenshtein ratio for the other. If a paragraph in the newversion had no ``matches'', meaning that none of its ratios were above athreshold of 0.4, this paragraph was new. If a paragraph in the oldversion had no ``matches'', then it was deleted in the revision."
p58
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p59
(dp60
g10
S'Figure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10and 12 of the old version were deleted, while the others found clearmatches.'
p61
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p62
(dp63
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph'stopic and content. For this calculation, the Levenshtein ratio does notprovide the right kind of information. For example, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple key words will slightly lower the Levenshtein ratio,but could drastically affect the content."
p64
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p65
(dp66
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution ofthe differences between a paragraph's Levenshtein ratios and LSI ratios,the Levenshtein and LSI ratios demonstrate very different statistics. Ingeneral, the topic similarity ratio is closer to one than thelevenshtein ratio."
p67
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p68
(dp69
g10
S"\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Latent Semantic Indexing\\cite{deerwester1990indexing} is a form of topic modeling thatcalculates the topic similarity between two texts. Its strengths lie inaccounting for synonyms and not penalizing for typographical errors. Theprocess begins by composing a corpus for each Wikipedia article from allof the documents (paragraphs of the versions of the article). Itanalyzes tokens (a specific instance of a word), eliminating those thatonly occur once, as well as stopword tokens, such as `the' or `and'. Itthen creates a TF-IDF matrix, which assigns a weight to every token ineach document, which indicates the importance of that token for thisdocument. This weight increases proportionally to the frequency of theword in the document, but accounts for the frequency of the word in thecorpus, such that the frequent occurrence of a usually uncommon word isgiven a larger weight to signify this importance."
p70
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p71
(dp72
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p73
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p74
(dp75
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p76
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p77
(dp78
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p79
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p80
(dp81
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p82
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p83
(dp84
g10
S'Therefore, in order to predict future conflicts, an assistive systemneeds to detect significant changes and then determine consequentlywhich paragraphs were most likely to change.'
p85
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p86
(dp87
g10
S'We looked at three possible types of inter-paragraph relationships.'
p88
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p89
(dp90
g10
S'Paragraphs could be related by physical proximity: perhaps theneighboring paragraphs would require adjustments, as they are likelypart of the same section. Paragraphs could also be related by topic. Forexample, in an academic paper, the discussion section and the conclusionshould present similar themes. If one changes, the other may need to beedited to reflect this change. For each significant change, we used theexisting LSI Topic Model to determine which paragraphs discussed similartopics. Lastly, paragraphs could be related because of similar edithistories. For each significant change, we evaluated the edit history ofthis paragraph with every other paragraph in the article. We labeledpairs as related if they changed or remained unchanged together overhalf the time. With a higher threshold, the sample size decreases, butwith a lower threshold, the results become less predictive of asignificant change prompting further edits. This threshold strikes abalance between these two outcomes.'
p91
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p92
(dp93
g10
S"To evaluate these both of these suspected relationships, we looked atthe related paragraphs' edit patterns in the ten versions following thesignificant change. If the related paragraphs changed together over halfthe time, the paragraphs with this relationship proved to be related inthe future, verifying the relationship at the time of the significantchange."
p94
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p95
(dp96
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutiveversions of a paper, we calculated the number of versions from theparagraphs' inception to its demise. On average, paragraphs lasted 83article revisions."
p97
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p98
(dp99
g10
S'\\subsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p100
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p101
(dp102
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p103
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p104
(dp105
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p106
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p107
(dp108
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, when aparagraph is edited for the first time in a while, further adjustmentsare triggered in the near future.'
p109
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p110
(dp111
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p112
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p113
(dp114
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p115
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p116
(dp117
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times of at least one significant change}\\\\EditHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p118
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p119
(dp120
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endheadTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewlineEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewlineProximity? & ? & ? & ?\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p121
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p122
(dp123
g10
S'The correlation coefficient was 0.99 for all numbers.'
p124
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p125
(dp126
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p127
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p128
(dp129
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p130
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p131
(dp132
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p133
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p134
(dp135
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p136
sg17
I00
sg18
Nsg19
NsbasS'author'
p137
S'OfraAmir'
p138
sba(iversion
Version
p139
(dp140
g7
g8
(S'\x07\xde\x0c\x11\x17-\x03\x03\xe8\x00'
tRp141
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate both of these suspected relationships, we looked at the\nrelated paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions. {[}a{]}\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p142
sg12
(lp143
(iversion
Paragraph
p144
(dp145
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose anintelligent assistive system with two primary tasks. First, it shoulddetect important edits and promote them to the relevant authors. Second,it should anticipate possible semantic conflicts between variousauthors' contributions, alerting when appropriate in order to ensurethat the writing process goes smoothly."
p146
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p147
(dp148
g10
S'When authors collaborate on a paper, they need to communicate constantlyto ensure they are on the same page. Because the authors need to makesure their edits are coherent with the rest of the paper, includingsections written by others, they need to read the entire paperfrequently, or rely on updates communicated by their co-authors. Evenwith constant communication, authors can get lost in the volume of editsfrom other collaborators. Further, Kittur et al. have shown that in acollaborative environment such as Wikipedia, the majority of edits nolonger add content but instead do maintenance work and add discussions\\cite{kittur2007he}. Therefore, an assistive system with a summary ofthe significant changes contributed by other authors would be helpful,as shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p149
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p150
(dp151
g10
S"We hypothesized that when an author makes a significant edit to aparagraph, it eventually triggers a series of adjustments in relatedparagraphs. In fact, a significant edit prompted changes in relatedparagraphs eighty percent of the time. However, in collaborativewriting, these resulting edits do not occur instantaneously. Beforethese adjustments occur, semantic conflicts might occur between theauthors' content. Instead of waiting for other authors to discover theinconsistency caused by one author's edit, we want an assistive systemto predict when and where these conflicts may occur, in order to alerteven more specifically."
p152
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p153
(dp154
g10
S'In order to achieve this, the system is composed of the following threecomponents: (1) tracking paragraphs; (2) identifying significant changesto paragraphs, and (3) predicting future changes to the article.'
p155
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p156
(dp157
g10
S'Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes helps the system promote only the mostimportant changes and decide whether to alert collaborating authors.'
p158
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p159
(dp160
g10
S"Predicting future changes enables the system to not only report changesthat have already been made, but also draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p161
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p162
(dp163
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve thewriting process, as shown by Birnholtz et al.'
p164
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p165
(dp166
g10
S'\\cite{birnholtz2012tracking}.There has been some research on the topicof analyzing relevant changes between two versions of a text. Neuwirthet al. use flexible diffing \\cite{neuwirth1992flexible} to detect andreport important changes. Fong et al. attempt to categorize edits\\cite{fong2010did}, which, according to Papadopoulou et al.'
p167
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p168
(dp169
g10
S'\\cite{papadopoulou2007structured}, can be useful for detecting importantchanges. Tam et al. developed an interface to show these categorizedchanges to users \\cite{tam2006framework}. Hainsworth et al.'
p170
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p171
(dp172
g10
S'\\cite{hainsworth2006enabling} detect and alert authors about mergeconflicts. De Silva uses edit histories in order to find structurewithin a text and to help co-authors write coherent documents\\cite{de2007narrative}. Nunes et al. analyze the impact of public eventson the frequency of edits in the collaborative writing environment,Wikipedia, and argue that edits are predictable\\cite{nunes2008wikichanges}.'
p173
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p174
(dp175
g10
S'\\section{Approach}\\label{approach}\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein editratio measure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision, we computed the Levenshtein ratio betweeneach paragraph in the old version and each paragraph in the new version.'
p176
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p177
(dp178
g10
S"Two paragraphs are mapped across the revision if they each had thehighest Levenshtein ratio for the other. If a paragraph in the newversion had no ``matches'', meaning that none of its ratios were above athreshold of 0.4, this paragraph was new. If a paragraph in the oldversion had no ``matches'', then it was deleted in the revision."
p179
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p180
(dp181
g10
S'Figure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10and 12 of the old version were deleted, while the others found clearmatches.'
p182
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p183
(dp184
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph'stopic and content. For this calculation, the Levenshtein ratio does notprovide the right kind of information. For example, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple key words will slightly lower the Levenshtein ratio,but could drastically affect the content."
p185
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p186
(dp187
g10
S"Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Latent Semantic Indexing\\cite{deerwester1990indexing} is a form of topic modeling thatcalculates the topic similarity between two texts. Its strengths lie inaccounting for synonyms and not penalizing for typographical errors. Theprocess begins by composing a corpus for each Wikipedia article from allof the documents (paragraphs of the versions of the article). Itanalyzes tokens (a specific instance of a word), eliminating those thatonly occur once, as well as stopword tokens, such as `the' or `and'. Itthen creates a TF-IDF matrix, which assigns a weight to every token ineach document, which indicates the importance of that token for thisdocument. This weight increases proportionally to the frequency of theword in the document, but accounts for the frequency of the word in thecorpus, such that the frequent occurrence of a usually uncommon word isgiven a larger weight to signify this importance."
p188
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p189
(dp190
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p191
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p192
(dp193
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p194
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p195
(dp196
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution ofthe differences between a paragraph's Levenshtein ratios and LSI ratios,the Levenshtein and LSI ratios demonstrate very different statistics. Ingeneral, the topic similarity ratio is closer to one than thelevenshtein ratio."
p197
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p198
(dp199
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p200
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p201
(dp202
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p203
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p204
(dp205
g10
S'Therefore, in order to predict future conflicts, an assistive systemneeds to detect significant changes and then determine consequentlywhich paragraphs were most likely to change.'
p206
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p207
(dp208
g10
S'We looked at three possible types of inter-paragraph relationships.'
p209
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p210
(dp211
g10
S'Paragraphs could be related by physical proximity: perhaps theneighboring paragraphs would require adjustments, as they are likelypart of the same section. Paragraphs could also be related by topic. Forexample, in an academic paper, the discussion section and the conclusionshould present similar themes. If one changes, the other may need to beedited to reflect this change. For each significant change, we used theexisting LSI Topic Model to determine which paragraphs discussed similartopics. Lastly, paragraphs could be related because of similar edithistories. For each significant change, we evaluated the edit history ofthis paragraph with every other paragraph in the article. We labeledpairs as related if they changed or remained unchanged together overhalf the time. With a higher threshold, the sample size decreases, butwith a lower threshold, the results become less predictive of asignificant change prompting further edits. This threshold strikes abalance between these two outcomes.'
p212
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p213
(dp214
g10
S"To evaluate both of these suspected relationships, we looked at therelated paragraphs' edit patterns in the ten versions following thesignificant change. If the related paragraphs changed together over halfthe time, the paragraphs with this relationship proved to be related inthe future, verifying the relationship at the time of the significantchange."
p215
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p216
(dp217
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutiveversions of a paper, we calculated the number of versions from theparagraphs' inception to its demise. On average, paragraphs lasted 83article revisions. {[}a{]}\\subsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}."
p218
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p219
(dp220
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p221
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p222
(dp223
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p224
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p225
(dp226
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, when aparagraph is edited for the first time in a while, further adjustmentsare triggered in the near future.'
p227
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p228
(dp229
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p230
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p231
(dp232
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p233
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p234
(dp235
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times of at least one significant change}\\\\EditHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p236
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p237
(dp238
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endheadTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewlineEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewlineProximity? & ? & ? & ?\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p239
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p240
(dp241
g10
S'The correlation coefficient was 0.99 for all numbers.'
p242
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p243
(dp244
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p245
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p246
(dp247
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p248
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p249
(dp250
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p251
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p252
(dp253
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p254
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p255
sba(iversion
Version
p256
(dp257
g7
g8
(S'\x07\xde\x0c\x16\x0f+\r\n90'
tRp258
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate both of these suspected relationships, we looked at the\nrelated paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions. {[}a{]}\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}b{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}c{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p259
sg12
(lp260
(iversion
Paragraph
p261
(dp262
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose anintelligent assistive system with two primary tasks. First, it shoulddetect important edits and promote them to the relevant authors. Second,it should anticipate possible semantic conflicts between variousauthors' contributions, alerting when appropriate in order to ensurethat the writing process goes smoothly."
p263
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p264
(dp265
g10
S'When authors collaborate on a paper, they need to communicate constantlyto ensure they are on the same page. Because the authors need to makesure their edits are coherent with the rest of the paper, includingsections written by others, they need to read the entire paperfrequently, or rely on updates communicated by their co-authors. Evenwith constant communication, authors can get lost in the volume of editsfrom other collaborators. Further, Kittur et al. have shown that in acollaborative environment such as Wikipedia, the majority of edits nolonger add content but instead do maintenance work and add discussions\\cite{kittur2007he}. Therefore, an assistive system with a summary ofthe significant changes contributed by other authors would be helpful,as shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p266
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p267
(dp268
g10
S"We hypothesized that when an author makes a significant edit to aparagraph, it eventually triggers a series of adjustments in relatedparagraphs. In fact, a significant edit prompted changes in relatedparagraphs eighty percent of the time. However, in collaborativewriting, these resulting edits do not occur instantaneously. Beforethese adjustments occur, semantic conflicts might occur between theauthors' content. Instead of waiting for other authors to discover theinconsistency caused by one author's edit, we want an assistive systemto predict when and where these conflicts may occur, in order to alerteven more specifically."
p269
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p270
(dp271
g10
S'In order to achieve this, the system is composed of the following threecomponents: (1) tracking paragraphs; (2) identifying significant changesto paragraphs, and (3) predicting future changes to the article.'
p272
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p273
(dp274
g10
S'Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes helps the system promote only the mostimportant changes and decide whether to alert collaborating authors.'
p275
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p276
(dp277
g10
S"Predicting future changes enables the system to not only report changesthat have already been made, but also draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p278
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p279
(dp280
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve thewriting process, as shown by Birnholtz et al.'
p281
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p282
(dp283
g10
S'\\cite{birnholtz2012tracking}.There has been some research on the topicof analyzing relevant changes between two versions of a text. Neuwirthet al. use flexible diffing \\cite{neuwirth1992flexible} to detect andreport important changes. Fong et al. attempt to categorize edits\\cite{fong2010did}, which, according to Papadopoulou et al.'
p284
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p285
(dp286
g10
S'\\cite{papadopoulou2007structured}, can be useful for detecting importantchanges. Tam et al. developed an interface to show these categorizedchanges to users \\cite{tam2006framework}. Hainsworth et al.'
p287
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p288
(dp289
g10
S'\\cite{hainsworth2006enabling} detect and alert authors about mergeconflicts. De Silva uses edit histories in order to find structurewithin a text and to help co-authors write coherent documents\\cite{de2007narrative}. Nunes et al. analyze the impact of public eventson the frequency of edits in the collaborative writing environment,Wikipedia, and argue that edits are predictable\\cite{nunes2008wikichanges}.'
p290
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p291
(dp292
g10
S'\\section{Approach}\\label{approach}\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein editratio measure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision, we computed the Levenshtein ratio betweeneach paragraph in the old version and each paragraph in the new version.'
p293
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p294
(dp295
g10
S"Two paragraphs are mapped across the revision if they each had thehighest Levenshtein ratio for the other. If a paragraph in the newversion had no ``matches'', meaning that none of its ratios were above athreshold of 0.4, this paragraph was new. If a paragraph in the oldversion had no ``matches'', then it was deleted in the revision."
p296
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p297
(dp298
g10
S'Figure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10and 12 of the old version were deleted, while the others found clearmatches.'
p299
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p300
(dp301
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph'stopic and content. For this calculation, the Levenshtein ratio does notprovide the right kind of information. For example, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple key words will slightly lower the Levenshtein ratio,but could drastically affect the content."
p302
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p303
(dp304
g10
S"Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Latent Semantic Indexing\\cite{deerwester1990indexing} is a form of topic modeling thatcalculates the topic similarity between two texts. Its strengths lie inaccounting for synonyms and not penalizing for typographical errors. Theprocess begins by composing a corpus for each Wikipedia article from allof the documents (paragraphs of the versions of the article). Itanalyzes tokens (a specific instance of a word), eliminating those thatonly occur once, as well as stopword tokens, such as `the' or `and'. Itthen creates a TF-IDF matrix, which assigns a weight to every token ineach document, which indicates the importance of that token for thisdocument. This weight increases proportionally to the frequency of theword in the document, but accounts for the frequency of the word in thecorpus, such that the frequent occurrence of a usually uncommon word isgiven a larger weight to signify this importance."
p305
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p306
(dp307
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p308
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p309
(dp310
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p311
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p312
(dp313
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution ofthe differences between a paragraph's Levenshtein ratios and LSI ratios,the Levenshtein and LSI ratios demonstrate very different statistics. Ingeneral, the topic similarity ratio is closer to one than thelevenshtein ratio."
p314
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p315
(dp316
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p317
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p318
(dp319
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p320
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p321
(dp322
g10
S'Therefore, in order to predict future conflicts, an assistive systemneeds to detect significant changes and then determine consequentlywhich paragraphs were most likely to change.'
p323
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p324
(dp325
g10
S'We looked at three possible types of inter-paragraph relationships.'
p326
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p327
(dp328
g10
S'Paragraphs could be related by physical proximity: perhaps theneighboring paragraphs would require adjustments, as they are likelypart of the same section. Paragraphs could also be related by topic. Forexample, in an academic paper, the discussion section and the conclusionshould present similar themes. If one changes, the other may need to beedited to reflect this change. For each significant change, we used theexisting LSI Topic Model to determine which paragraphs discussed similartopics. Lastly, paragraphs could be related because of similar edithistories. For each significant change, we evaluated the edit history ofthis paragraph with every other paragraph in the article. We labeledpairs as related if they changed or remained unchanged together overhalf the time. With a higher threshold, the sample size decreases, butwith a lower threshold, the results become less predictive of asignificant change prompting further edits. This threshold strikes abalance between these two outcomes.'
p329
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p330
(dp331
g10
S"To evaluate both of these suspected relationships, we looked at therelated paragraphs' edit patterns in the ten versions following thesignificant change. If the related paragraphs changed together over halfthe time, the paragraphs with this relationship proved to be related inthe future, verifying the relationship at the time of the significantchange."
p332
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p333
(dp334
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutiveversions of a paper, we calculated the number of versions from theparagraphs' inception to its demise. On average, paragraphs lasted 83article revisions. {[}a{]}\\subsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}."
p335
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p336
(dp337
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p338
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p339
(dp340
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p341
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p342
(dp343
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, when aparagraph is edited for the first time in a while, further adjustmentsare triggered in the near future.'
p344
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p345
(dp346
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p347
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p348
(dp349
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p350
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p351
(dp352
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times of at least one significant change}\\\\EditHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p353
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p354
(dp355
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endheadTopic Similarity & 1,869 {[}b{]} & 1,203 & 63\\%\\tabularnewlineEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewlineProximity{[}c{]}? & ? & ? & ?\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p356
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p357
(dp358
g10
S'The correlation coefficient was 0.99 for all numbers.'
p359
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p360
(dp361
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p362
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p363
(dp364
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p365
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p366
(dp367
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p368
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p369
(dp370
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p371
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p372
sba(iversion
Version
p373
(dp374
g7
g8
(S"\x07\xde\x0c\x16\x10';\r\xbf\x88"
tRp375
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}b{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p376
sg12
(lp377
(iversion
Paragraph
p378
(dp379
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p380
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p381
(dp382
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p383
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p384
(dp385
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p386
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p387
(dp388
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p389
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p390
(dp391
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p392
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p393
(dp394
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for providing three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p395
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p396
(dp397
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p398
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p399
(dp400
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p401
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p402
(dp403
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p404
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p405
(dp406
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p407
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p408
(dp409
g10
S"Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. The process begins bycomposing a corpus for each Wikipedia article from all of the documents(paragraphs of the versions of the article). It analyzes tokens (aspecific instance of a word), eliminating those that only occur once, aswell as stopword tokens, such as `the' or `and'. It then creates aTF-IDF matrix, which assigns a weight to every token in each document,which indicates the importance of that token for this document. Thisweight increases proportionally to the frequency of the word in thedocument, but accounts for the frequency of the word in the corpus, suchthat the frequent occurrence of a usually uncommon word is given alarger weight to signify this importance."
p410
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p411
(dp412
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p413
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p414
(dp415
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p416
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p417
(dp418
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution ofthe differences between a paragraph's Levenshtein ratios and LSI ratios,the Levenshtein and LSI ratios demonstrate very different statistics. Ingeneral, the topic similarity ratio is closer to one than thelevenshtein ratio."
p419
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p420
(dp421
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p422
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p423
(dp424
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p425
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p426
(dp427
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p428
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p429
(dp430
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p431
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p432
(dp433
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p434
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p435
(dp436
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p437
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p438
(dp439
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article (see Figure~{[}fig:authors{]}).'
p440
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p441
(dp442
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p443
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p444
(dp445
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) thatparagraphs were correctly mapped and 2) that this method successfullyclassifies edits. We provide an example of a significant edit below.'
p446
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p447
(dp448
g10
S'While these paragraphs are clearly the same, the edit is significantbecause it contributes content and changes the tone of the paragraph.'
p449
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p450
(dp451
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p452
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p453
(dp454
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p455
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p456
(dp457
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p458
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p459
(dp460
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p461
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p462
(dp463
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times of at least one significant change}\\\\EditHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p464
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p465
(dp466
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endheadTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewlineEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewlineProximity{[}b{]}? & ? & ? & ?\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p467
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p468
(dp469
g10
S'The correlation coefficient was 0.99 for all numbers.'
p470
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p471
(dp472
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p473
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p474
(dp475
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p476
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p477
(dp478
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p479
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p480
(dp481
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p482
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p483
sba(iversion
Version
p484
(dp485
g7
g8
(S'\x07\xde\x0c\x16\x101\x02\x04U`'
tRp486
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nParagraphs related by topic similarity were found on average once every\nten versions of the text. Paragraphs related by edit history were found\non average 1.6 times per version.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}b{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p487
sg12
(lp488
(iversion
Paragraph
p489
(dp490
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p491
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p492
(dp493
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p494
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p495
(dp496
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p497
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p498
(dp499
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p500
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p501
(dp502
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p503
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p504
(dp505
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for providing three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p506
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p507
(dp508
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p509
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p510
(dp511
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p512
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p513
(dp514
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p515
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p516
(dp517
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p518
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p519
(dp520
g10
S"Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. The process begins bycomposing a corpus for each Wikipedia article from all of the documents(paragraphs of the versions of the article). It analyzes tokens (aspecific instance of a word), eliminating those that only occur once, aswell as stopword tokens, such as `the' or `and'. It then creates aTF-IDF matrix, which assigns a weight to every token in each document,which indicates the importance of that token for this document. Thisweight increases proportionally to the frequency of the word in thedocument, but accounts for the frequency of the word in the corpus, suchthat the frequent occurrence of a usually uncommon word is given alarger weight to signify this importance."
p521
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p522
(dp523
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p524
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p525
(dp526
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p527
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p528
(dp529
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution ofthe differences between a paragraph's Levenshtein ratios and LSI ratios,the Levenshtein and LSI ratios demonstrate very different statistics. Ingeneral, the topic similarity ratio is closer to one than thelevenshtein ratio."
p530
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p531
(dp532
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p533
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p534
(dp535
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p536
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p537
(dp538
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p539
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p540
(dp541
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p542
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p543
(dp544
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p545
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p546
(dp547
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p548
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p549
(dp550
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article (see Figure~{[}fig:authors{]}).'
p551
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p552
(dp553
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p554
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p555
(dp556
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) thatparagraphs were correctly mapped and 2) that this method successfullyclassifies edits. We provide an example of a significant edit below.'
p557
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p558
(dp559
g10
S'While these paragraphs are clearly the same, the edit is significantbecause it contributes content and changes the tone of the paragraph.'
p560
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p561
(dp562
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p563
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p564
(dp565
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p566
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p567
(dp568
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p569
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p570
(dp571
g10
S'Paragraphs related by topic similarity were found on average once everyten versions of the text. Paragraphs related by edit history were foundon average 1.6 times per version.'
p572
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p573
(dp574
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p575
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p576
(dp577
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times of at least one significant change}\\\\EditHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p578
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p579
(dp580
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endheadTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewlineEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewlineProximity{[}b{]}? & ? & ? & ?\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p581
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p582
(dp583
g10
S'The correlation coefficient was 0.99 for all numbers.'
p584
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p585
(dp586
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p587
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p588
(dp589
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p590
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p591
(dp592
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p593
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p594
(dp595
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p596
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p597
sba(iversion
Version
p598
(dp599
g7
g8
(S'\x07\xde\x0c\x16\x103)\x06\xae\xf0'
tRp600
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}b{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p601
sg12
(lp602
(iversion
Paragraph
p603
(dp604
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p605
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p606
(dp607
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p608
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p609
(dp610
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p611
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p612
(dp613
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p614
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p615
(dp616
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p617
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p618
(dp619
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for providing three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p620
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p621
(dp622
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p623
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p624
(dp625
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p626
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p627
(dp628
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p629
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p630
(dp631
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p632
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p633
(dp634
g10
S"Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. The process begins bycomposing a corpus for each Wikipedia article from all of the documents(paragraphs of the versions of the article). It analyzes tokens (aspecific instance of a word), eliminating those that only occur once, aswell as stopword tokens, such as `the' or `and'. It then creates aTF-IDF matrix, which assigns a weight to every token in each document,which indicates the importance of that token for this document. Thisweight increases proportionally to the frequency of the word in thedocument, but accounts for the frequency of the word in the corpus, suchthat the frequent occurrence of a usually uncommon word is given alarger weight to signify this importance."
p635
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p636
(dp637
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p638
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p639
(dp640
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p641
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p642
(dp643
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution ofthe differences between a paragraph's Levenshtein ratios and LSI ratios,the Levenshtein and LSI ratios demonstrate very different statistics. Ingeneral, the topic similarity ratio is closer to one than thelevenshtein ratio."
p644
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p645
(dp646
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p647
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p648
(dp649
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p650
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p651
(dp652
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p653
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p654
(dp655
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p656
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p657
(dp658
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p659
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p660
(dp661
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p662
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p663
(dp664
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article (see Figure~{[}fig:authors{]}).'
p665
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p666
(dp667
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p668
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p669
(dp670
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) thatparagraphs were correctly mapped and 2) that this method successfullyclassifies edits. We provide an example of a significant edit below.'
p671
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p672
(dp673
g10
S'While these paragraphs are clearly the same, the edit is significantbecause it contributes content and changes the tone of the paragraph.'
p674
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p675
(dp676
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p677
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p678
(dp679
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p680
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p681
(dp682
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p683
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p684
(dp685
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p686
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p687
(dp688
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p689
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p690
(dp691
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times of at least one significant change}\\\\EditHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p692
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p693
(dp694
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endheadTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewlineEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewlineProximity{[}b{]}? & ? & ? & ?\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p695
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p696
(dp697
g10
S'The correlation coefficient was 0.99 for all numbers.'
p698
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p699
(dp700
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p701
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p702
(dp703
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p704
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p705
(dp706
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p707
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p708
(dp709
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p710
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p711
sba(iversion
Version
p712
(dp713
g7
g8
(S'\x07\xde\x0c\x16\x11\x03\x00\x0c\xd9\x10'
tRp714
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}a{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p715
sg12
(lp716
(iversion
Paragraph
p717
(dp718
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p719
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p720
(dp721
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p722
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p723
(dp724
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p725
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p726
(dp727
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p728
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p729
(dp730
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p731
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p732
(dp733
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for providing three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p734
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p735
(dp736
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p737
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p738
(dp739
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p740
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p741
(dp742
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p743
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p744
(dp745
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p746
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p747
(dp748
g10
S"Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. The process begins bycomposing a corpus for each Wikipedia article from all of the documents(paragraphs of the versions of the article). It analyzes tokens (aspecific instance of a word), eliminating those that only occur once, aswell as stopword tokens, such as `the' or `and'. It then creates aTF-IDF matrix, which assigns a weight to every token in each document,which indicates the importance of that token for this document. Thisweight increases proportionally to the frequency of the word in thedocument, but accounts for the frequency of the word in the corpus, suchthat the frequent occurrence of a usually uncommon word is given alarger weight to signify this importance."
p749
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p750
(dp751
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p752
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p753
(dp754
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p755
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p756
(dp757
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution ofthe differences between a paragraph's Levenshtein ratios and LSI ratios,the Levenshtein and LSI ratios demonstrate very different statistics. Ingeneral, the topic similarity ratio is closer to one than thelevenshtein ratio."
p758
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p759
(dp760
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p761
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p762
(dp763
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p764
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p765
(dp766
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p767
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p768
(dp769
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p770
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p771
(dp772
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p773
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p774
(dp775
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p776
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p777
(dp778
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article (see Figure~{[}fig:authors{]}).'
p779
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p780
(dp781
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p782
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p783
(dp784
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) thatparagraphs were correctly mapped and 2) that this method successfullyclassifies edits. We provide an example of a significant edit below.'
p785
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p786
(dp787
g10
S'While these paragraphs are clearly the same, the edit is significantbecause it contributes content and changes the tone of the paragraph.'
p788
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p789
(dp790
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p791
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p792
(dp793
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p794
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p795
(dp796
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p797
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p798
(dp799
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p800
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p801
(dp802
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p803
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p804
(dp805
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p806
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p807
(dp808
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewlineProximity{[}a{]}? & ? & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p809
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p810
(dp811
g10
S'The correlation coefficient was 0.99 for all numbers.'
p812
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p813
(dp814
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p815
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p816
(dp817
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p818
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p819
(dp820
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p821
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p822
(dp823
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p824
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p825
sba(iversion
Version
p826
(dp827
g7
g8
(S'\x07\xde\x0c\x16\x11\x10!\x0c\xfc8'
tRp828
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\nAs shown in figure ~{[}fig:difflevtop{]}, which shows the distribution\nof the differences between a paragraph's Levenshtein ratios and LSI\nratios, the Levenshtein and LSI ratios demonstrate very different\nstatistics. In general, the topic similarity ratio is closer to one than\nthe levenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}a{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p829
sg12
(lp830
(iversion
Paragraph
p831
(dp832
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p833
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p834
(dp835
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p836
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p837
(dp838
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p839
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p840
(dp841
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p842
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p843
(dp844
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p845
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p846
(dp847
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for providing three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p848
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p849
(dp850
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p851
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p852
(dp853
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p854
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p855
(dp856
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p857
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p858
(dp859
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p860
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p861
(dp862
g10
S'Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors.'
p863
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p864
(dp865
g10
S"As shown in figure ~{[}fig:difflevtop{]}, which shows the distributionof the differences between a paragraph's Levenshtein ratios and LSIratios, the Levenshtein and LSI ratios demonstrate very differentstatistics. In general, the topic similarity ratio is closer to one thanthe levenshtein ratio."
p866
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p867
(dp868
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p869
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p870
(dp871
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p872
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p873
(dp874
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p875
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p876
(dp877
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p878
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p879
(dp880
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p881
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p882
(dp883
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p884
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p885
(dp886
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article (see Figure~{[}fig:authors{]}).'
p887
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p888
(dp889
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p890
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p891
(dp892
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) thatparagraphs were correctly mapped and 2) that this method successfullyclassifies edits. We provide an example of a significant edit below.'
p893
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p894
(dp895
g10
S'While these paragraphs are clearly the same, the edit is significantbecause it contributes content and changes the tone of the paragraph.'
p896
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p897
(dp898
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p899
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p900
(dp901
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p902
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p903
(dp904
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p905
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p906
(dp907
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p908
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p909
(dp910
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p911
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p912
(dp913
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p914
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p915
(dp916
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewlineProximity{[}a{]}? & ? & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p917
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p918
(dp919
g10
S'The correlation coefficient was 0.99 for all numbers.'
p920
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p921
(dp922
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p923
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p924
(dp925
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p926
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p927
(dp928
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p929
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p930
(dp931
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p932
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p933
sba(iversion
Version
p934
(dp935
g7
g8
(S'\x07\xde\x0c\x17\x01%(\x07\xef@'
tRp936
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\nAs shown in figure ~{[}fig:difflevtop{]}, which shows the distribution\nof the differences between a paragraph's Levenshtein ratios and LSI\nratios, the Levenshtein and LSI ratios demonstrate very different\nstatistics. In general, the topic similarity ratio is closer to one than\nthe levenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}c{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p937
sg12
(lp938
(iversion
Paragraph
p939
(dp940
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p941
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p942
(dp943
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p944
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p945
(dp946
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p947
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p948
(dp949
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p950
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p951
(dp952
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p953
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p954
(dp955
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for providing three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p956
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p957
(dp958
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p959
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p960
(dp961
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p962
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p963
(dp964
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p965
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p966
(dp967
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p968
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p969
(dp970
g10
S'Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors.'
p971
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p972
(dp973
g10
S"As shown in figure ~{[}fig:difflevtop{]}, which shows the distributionof the differences between a paragraph's Levenshtein ratios and LSIratios, the Levenshtein and LSI ratios demonstrate very differentstatistics. In general, the topic similarity ratio is closer to one thanthe levenshtein ratio."
p974
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p975
(dp976
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p977
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p978
(dp979
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p980
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p981
(dp982
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p983
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p984
(dp985
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p986
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p987
(dp988
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p989
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p990
(dp991
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p992
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p993
(dp994
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article (see Figure~{[}fig:authors{]}).'
p995
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p996
(dp997
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p998
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p999
(dp1000
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) thatparagraphs were correctly mapped and 2) that this method successfullyclassifies edits. We provide an example of a significant edit below.'
p1001
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1002
(dp1003
g10
S'While these paragraphs are clearly the same, the edit is significantbecause it contributes content and changes the tone of the paragraph.'
p1004
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1005
(dp1006
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p1007
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1008
(dp1009
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p1010
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1011
(dp1012
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p1013
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1014
(dp1015
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p1016
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1017
(dp1018
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}a{]}{[}b{]} are much more predictive than physicalproximity, as shown in Table~{[}table:futureEdits{]}. They are alsosignificantly more predictive than random sample controls. For controls,we compare with the original paragraph as well as a random sample of anyten consecutive versions within Wikipedia article histories.'
p1019
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1020
(dp1021
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p1022
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1023
(dp1024
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewlineProximity{[}c{]}? & ? & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p1025
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1026
(dp1027
g10
S'The correlation coefficient was 0.99 for all numbers.'
p1028
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1029
(dp1030
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p1031
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1032
(dp1033
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p1034
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1035
(dp1036
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p1037
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1038
(dp1039
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p1040
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p1041
sba(iversion
Version
p1042
(dp1043
g7
g8
(S'\x07\xde\x0c\x17\x10\x0f8\rR('
tRp1044
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}d{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p1045
sg12
(lp1046
(iversion
Paragraph
p1047
(dp1048
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p1049
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1050
(dp1051
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p1052
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1053
(dp1054
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p1055
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1056
(dp1057
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p1058
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1059
(dp1060
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p1061
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1062
(dp1063
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for providing three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p1064
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1065
(dp1066
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p1067
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1068
(dp1069
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p1070
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1071
(dp1072
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p1073
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1074
(dp1075
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p1076
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1077
(dp1078
g10
S'Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors.'
p1079
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1080
(dp1081
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p1082
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1083
(dp1084
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p1085
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1086
(dp1087
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p1088
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1089
(dp1090
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p1091
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1092
(dp1093
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p1094
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1095
(dp1096
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p1097
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1098
(dp1099
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article.'
p1100
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1101
(dp1102
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p1103
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1104
(dp1105
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) thatparagraphs were correctly mapped and 2) that this method successfullyclassifies edits. We provide an example of a significant edit below.'
p1106
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1107
(dp1108
g10
S'While these paragraphs are clearly the same, the edit is significantbecause it contributes content and changes the tone of the paragraph.'
p1109
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1110
(dp1111
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p1112
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1113
(dp1114
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p1115
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1116
(dp1117
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p1118
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1119
(dp1120
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p1121
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1122
(dp1123
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}b{]}{[}c{]} are much more predictive than physicalproximity, as shown in Table~{[}table:futureEdits{]}. They are alsosignificantly more predictive than random sample controls. For controls,we compare with the original paragraph as well as a random sample of anyten consecutive versions within Wikipedia article histories.'
p1124
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1125
(dp1126
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p1127
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1128
(dp1129
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewlineProximity{[}d{]}? & ? & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p1130
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1131
(dp1132
g10
S'The correlation coefficient was 0.99 for all numbers.'
p1133
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1134
(dp1135
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p1136
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1137
(dp1138
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p1139
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1140
(dp1141
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p1142
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1143
(dp1144
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p1145
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p1146
sba(iversion
Version
p1147
(dp1148
g7
g8
(S'\x07\xde\x0c\x17\x10\x1b7\x02\x94('
tRp1149
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p1150
sg12
(lp1151
(iversion
Paragraph
p1152
(dp1153
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p1154
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1155
(dp1156
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p1157
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1158
(dp1159
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p1160
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1161
(dp1162
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p1163
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1164
(dp1165
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p1166
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1167
(dp1168
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for the following three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p1169
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1170
(dp1171
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p1172
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1173
(dp1174
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p1175
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1176
(dp1177
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p1178
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1179
(dp1180
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p1181
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1182
(dp1183
g10
S'Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use cosine similaritybetween word vectors that represent the paragraphs, incorportatingLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) whichaccounts for synonyms and does not penalize for typographical errors.'
p1184
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1185
(dp1186
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p1187
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1188
(dp1189
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p1190
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1191
(dp1192
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p1193
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1194
(dp1195
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p1196
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1197
(dp1198
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p1199
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1200
(dp1201
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p1202
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1203
(dp1204
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article.'
p1205
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1206
(dp1207
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p1208
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1209
(dp1210
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We manually evaluated a random sample of a couple hundred of these editsto determine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p1211
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1212
(dp1213
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p1214
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1215
(dp1216
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p1217
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1218
(dp1219
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p1220
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1221
(dp1222
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p1223
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1224
(dp1225
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}b{]}{[}c{]} are much more predictive than physicalproximity, as shown in Table~{[}table:futureEdits{]}. They are alsosignificantly more predictive than random sample controls. For controls,we compare with the original paragraph as well as a random sample of anyten consecutive versions within Wikipedia article histories.'
p1226
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1227
(dp1228
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. (Proximity was not evaluated for this harsher measure, asit did almost no better than the random control for the first measure.)Further, we obtained a recall of 80\\% for these correct predictions;thus, only 20\\% of the paragraphs that should have been labeled asrelated (based on information ten versions in the future) were missed.'
p1229
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1230
(dp1231
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p1232
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1233
(dp1234
g10
S'The correlation coefficient was 0.99 for all numbers.'
p1235
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1236
(dp1237
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p1238
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1239
(dp1240
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p1241
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1242
(dp1243
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p1244
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1245
(dp1246
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p1247
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p1248
sba(iversion
Version
p1249
(dp1250
g7
g8
(S'\x07\xde\x0c\x0e\x10\x17\r\t\xee\xf8'
tRp1251
sg10
S". See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.\n\n\\section{Introduction}\\label{introduction}\n\nMaybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikis\n\nnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision Activity\n\nWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nThe system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.\n\nINSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.\n\nThis method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches.\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81 Topic Similarity .\nPhysical Proximity 24 Paragraph with original significant change 40\nRandom Sample of Paragraphs 15\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63 Editing History 27,722 19,685 71\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p1252
sg12
(lp1253
(iversion
Paragraph
p1254
(dp1255
g10
S'. See: \\url{http://www.acm.org/about/class/1998/} for help using the ACMClassification system.'
p1256
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1257
(dp1258
g10
S'\\section{Introduction}\\label{introduction}Maybe one paragraph (previous years talk about motivation in similarwork in intro and have one-two paragraphs in a background/related worksection) about how previous work tried to come up with frameworks tosupport writers and tried to investigate the writers problems. Theydescribe the motivation and the need for such a system: * TrackingChanges in Collaborative Writing: Edits, Visibility and GroupMaintenance Old examples: * Quilt: A collaborative tool for cooperativewriting - 1988 * User-centred iterative design of collaborative software-1993 * what do co-authors use? * They try to find relevant changes: *Flexible Diff-ing in a collaborative writing system * What did they do?'
p1259
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1260
(dp1261
g10
S'Deriving High-Level edit histories in Wikisnewer examples also try to classify changes: * How a Structured DocumentModel Can Support Awareness in Collaborative Authoring * A framework forasynchronous change awareness in collaborative documents and workspaces* some try to find conflicts (different definition of conflict though):* Enabling truly collaborative writing on a computer * and some try tofind an explicit structur in texts: * A narrative-based collaborativewriting tool for constructing coherent technical documents * trying topredict: * WikiChanges - Exposing Wikipedia Revision ActivityWhen authors collaborate to write a paper, they need to communicateconstantly to ensure that they are all on the same page. Because theauthors need to make sure that their edits are coherent with the rest ofthe paper, including sections written by others, they need to read theentire paper frequently, or rely on updates communicated by theircoauthors. Even with constant communication, authors can get lost in thevolume of edits from other collaborators. Therefore, an assistive systemwith a summary of the significant changes contributed by other authorswould be helpful. We hypothesize that when an author makes a significantedit to a paragraph, it eventually triggers a series of adjustments inrelated paragraphs. Before these adjustments occur, semantic conflictsmight occur between authors. We wanted a collaborative writing system toalso predict when and where these conflicts may occur, in order to alerteven more specifically.'
p1262
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1263
(dp1264
g10
S'The system is composed of the following three components: (1) trackingparagraphs; (2) identifying significant changes to paragraphs, and (3)predicting future changes to the article. Tracking paragraphs throughpaper revisions is a core capability required for monitoring changes andpredicting them. The identification of significant content changes isimportant for a system to understand how important different changes areand whether collaborating authors should be notified. Predicting futurechanges enables the system to not only report to authors about changesthat have already been made, but also draw their attention to otherparts of the document that might require changes as a result of thechanges made.'
p1265
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1266
(dp1267
g10
S"INSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changesin related paragraphs eighty percent of the time{]}, but incollaborative writing, these resulting edits do not occurinstantaneously. Instead of waiting for other authors to discover theinconsistency caused by one author's edit, we want an assistive systemthat can alert relevant authors about paragraphs that might need anadditional look as a result of an edit."
p1268
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1269
(dp1270
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a widevariety of Wikipedia articles that undergo intense editing processes.'
p1271
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1272
(dp1273
g10
S'Wikipedia is a unique source because it presents extensive data forcollaborative writing. The findings use the complete revision revisionhistory of 41 different articles chosen from a diverse set of topics,from famous people and places to mathematical algorithms to novels. Therevision histories were downloaded as raw xml data. We removedWikipedia-specific tags that indicate formatting and other irrelevantdata, and eliminated versions of the articles under 150 characters, asthey did not contain enough information. To focus only on revisions withconsequential changes, the versions with simple typo fixes{[}1{]} wereeliminated as well. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs. Wikipediadata affords results applicable to other collaborative writing spaces,because although the average article has over 400 contributing authors,most of these authors make a one-time change. In fact, on average, 15authors make 80\\% of the edits to an article. This enables theconsideration of interactions between authors, which is crucial forlearning about collaborative behavior.'
p1274
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1275
(dp1276
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein editratio measure, which is defined in equation 1.'
p1277
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1278
(dp1279
g10
S'This method differed from previous attempts in the sense that it tracksparagraphs as a whole instead of just the longest common subsequence asused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.'
p1280
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1281
(dp1282
g10
S'A Levenshtein ratio close to one between two paragraphs indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision, we computed the Levenshtein ratio betweeneach paragraph in the old version and each paragraph in the new version.'
p1283
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1284
(dp1285
g10
S"Two paragraphs are mapped across the revision if they each had thehighest Levenshtein ratio for the other. If a paragraph in the newversion had no ``matches'', meaning that none of its ratios were above athreshold of 0.4, this paragraph was new. If a paragraph in the oldversion had no ``matches'', then it was deleted in the revision. Theimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of theold version were deleted, while the others found clear matches."
p1286
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1287
(dp1288
g10
S"\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph'stopic and content. For this calculation, the Levenshtein ratio does notprovide the right kind of information. For example, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple key words will slightly lower the Levenshtein ratio,but could drastically affect the content."
p1289
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1290
(dp1291
g10
S"As shown in figure 1, which shows the distribution of the differencesbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshteinand LSI ratios demonstrate very different statistics. {[}INSERTFIGURE{]}Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Latent Semantic Indexing is a form oftopic modeling that calculates the topic similarity between two texts."
p1292
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1293
(dp1294
g10
S"Its strengths lie in accounting for synonyms and not penalizing fortypographical errors. The process begins by composing a corpus for eachWikipedia article from all of the documents (paragraphs of the versionsof the article). It analyzes tokens (a specific instance of a word),eliminating those that only occur once, as well as stopword tokens, suchas `the' or `and'. It then creates a TF-IDF matrix, which assigns aweight to every token in each document, which indicates the importanceof that token for this document. This weight increases proportionally tothe frequency of the word in the document, but accounts for thefrequency of the word in the corpus, such that the frequent occurrenceof a usually uncommon word is given a larger weight to signify thisimportance."
p1295
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1296
(dp1297
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p1298
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1299
(dp1300
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p1301
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1302
(dp1303
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p1304
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1305
(dp1306
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p1307
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1308
(dp1309
g10
S'Therefore, in order to predict future conflicts, an assistive systemneeds to detect significant changes and then determine consequentlywhich paragraphs were most likely to change.'
p1310
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1311
(dp1312
g10
S'We looked at three possible types of inter-paragraph relationships.'
p1313
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1314
(dp1315
g10
S'Paragraphs could be related by physical proximity: perhaps theneighboring paragraphs would require adjustments, as they are likelypart of the same section. Paragraphs could also be related by topic. Forexample, in an academic paper, the discussion section and the conclusionshould present similar themes. If one changes, the other may need to beedited to reflect this change. For each significant change, we used theexisting LSI Topic Model to determine which paragraphs discussed similartopics. Lastly, paragraphs could be related because of similar edithistories. For each significant change, we evaluated the edit history ofthis paragraph with every other paragraph in the article. We labeledpairs as related if they changed or remained unchanged together overhalf the time. With a higher threshold, the sample size decreases, butwith a lower threshold, the results become less predictive of asignificant change prompting further edits. This threshold strikes abalance between these two outcomes.'
p1316
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1317
(dp1318
g10
S"To evaluate these both of these suspected relationships, we looked atthe related paragraphs' edit patterns in the ten versions following thesignificant change. If the related paragraphs changed together over halfthe time, the paragraphs with this relationship proved to be related inthe future, verifying the relationship at the time of the significantchange."
p1319
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1320
(dp1321
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutiveversions of a paper, we calculated the number of versions from theparagraphs' inception to its demise. On average, paragraphs lasted 83article revisions."
p1322
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1323
(dp1324
g10
S'\\subsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15We evaluated a random sample of these edits to determine that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p1325
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1326
(dp1327
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p1328
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1329
(dp1330
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in figure {[}X{]}, when a paragraph isedited for the first time in a while, further adjustments are triggeredin the near future.'
p1331
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1332
(dp1333
g10
S'Caption: After a significant change at version 0, consequent edits aremore frequent.'
p1334
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1335
(dp1336
g10
S'We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p1337
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1338
(dp1339
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in table {[}X{]}. They are also significantly more predictive thanrandom sample controls. For controls, we compare with the originalparagraph as well as a random sample of any ten consecutive versionswithin Wikipedia article histories.'
p1340
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1341
(dp1342
g10
S'Relationship or Control Percentage of times that paragraph experiencedat least one significant change Edit History 81 Topic Similarity .'
p1343
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1344
(dp1345
g10
S'Physical Proximity 24 Paragraph with original significant change 40Random Sample of Paragraphs 15More importantly, with respect to the second measure, we correctlypredicted 63Relationship Number Found Successfully Linked Ratio of SuccessfullyLinked Topic Similarity 1,869 1,203 63 Editing History 27,722 19,685 71Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p1346
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1347
(dp1348
g10
S'The correlation coefficient was 0.99 for all numbers.'
p1349
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1350
(dp1351
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p1352
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1353
(dp1354
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p1355
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1356
(dp1357
g10
S'We imagine a couple other helpful components for an assistive systemthat our methods could provide the foundation for. Using text summaryalgorithms, the system could provide a succinct textual summary ofsignificant changes already detected. The system could also \\ldots{}.'
p1358
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1359
(dp1360
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determiningwhether a paragraph will change together in the future. Consequently, weassert that if significant edit occurs, related paragraphs should alsobe edited. A proposed assistive system will alert the relevant authorsof related paragraphs if this resulting edit does not occur. Bydetecting relationships between paragraphs in a multi-authored paper,our system can predict and alert appropriate authors if a significantchange has the potential to create a semantic conflict within the paper.'
p1361
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p1362
sba(iversion
Version
p1363
(dp1364
g7
g8
(S'\x07\xde\x0c\x17\x106$\x08M\x00'
tRp1365
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and detection of significant\nchanges that formed the basis of the prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe also plan to develop additional algorithms for summarizing changes,\nbuilding on text summary algorithms from the NLP literature **need\ncitations*** {[}d{]}and further use algorithms that measure text\ncoherency (e.g., textiling **cite**) to alert authors to lack of\ncoherency issues. Finally, we plan to explore alternative ways of\npresenting the information chosen by algorithms to users. For example,\nan assistive system might highlight changes that it deems relevant to a\nspecific author, or it could provide a list of the changes etc.\n"
p1366
sg12
(lp1367
(iversion
Paragraph
p1368
(dp1369
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p1370
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1371
(dp1372
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p1373
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1374
(dp1375
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p1376
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1377
(dp1378
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p1379
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1380
(dp1381
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p1382
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1383
(dp1384
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for the following three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p1385
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1386
(dp1387
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p1388
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1389
(dp1390
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p1391
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1392
(dp1393
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p1394
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1395
(dp1396
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p1397
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1398
(dp1399
g10
S'Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use cosine similaritybetween word vectors that represent the paragraphs, incorportatingLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) whichaccounts for synonyms and does not penalize for typographical errors.'
p1400
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1401
(dp1402
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p1403
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1404
(dp1405
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p1406
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1407
(dp1408
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p1409
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1410
(dp1411
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p1412
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1413
(dp1414
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p1415
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1416
(dp1417
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p1418
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1419
(dp1420
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article.'
p1421
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1422
(dp1423
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was on the prediction of future edits, but we also conducteda manual evaluation of paragraph mapping and detection of significantchanges that formed the basis of the prediction.'
p1424
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1425
(dp1426
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p1427
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1428
(dp1429
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We manually evaluated a random sample of a couple hundred of these editsto determine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p1430
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1431
(dp1432
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p1433
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1434
(dp1435
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p1436
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1437
(dp1438
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p1439
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1440
(dp1441
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p1442
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1443
(dp1444
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}b{]}{[}c{]} are much more predictive than physicalproximity, as shown in Table~{[}table:futureEdits{]}. They are alsosignificantly more predictive than random sample controls. For controls,we compare with the original paragraph as well as a random sample of anyten consecutive versions within Wikipedia article histories.'
p1445
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1446
(dp1447
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. (Proximity was not evaluated for this harsher measure, asit did almost no better than the random control for the first measure.)Further, we obtained a recall of 80\\% for these correct predictions;thus, only 20\\% of the paragraphs that should have been labeled asrelated (based on information ten versions in the future) were missed.'
p1448
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1449
(dp1450
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p1451
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1452
(dp1453
g10
S'The correlation coefficient was 0.99 for all numbers.'
p1454
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1455
(dp1456
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p1457
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1458
(dp1459
g10
S"Our long-term goal is to build an assistive system that will improve thecollaborative writing process. Our developed methods provide the basisfor such a system, by enabling automatic detection of significant editsand predicting their effects. These capabilities can inform decisionsabout alerting authors to specific, important changes and places in thedocument that are likely to require revisions. However, our approachthus far have not leveraged information about the authors who made theedits. In future work we plan to incorporate information about authoridentity to design personalized alerts for authors depending on theircontext of editing and history of revisions. For example, the paragraphtracking algorithm makes it possible to create a list of authors whohave contributed to a specific paragraph, which can be used to determinewho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p1460
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1461
(dp1462
g10
S'We also plan to develop additional algorithms for summarizing changes,building on text summary algorithms from the NLP literature **needcitations*** {[}d{]}and further use algorithms that measure textcoherency (e.g., textiling **cite**) to alert authors to lack ofcoherency issues. Finally, we plan to explore alternative ways ofpresenting the information chosen by algorithms to users. For example,an assistive system might highlight changes that it deems relevant to aspecific author, or it could provide a list of the changes etc.'
p1463
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p1464
sba(iversion
Version
p1465
(dp1466
g7
g8
(S'\x07\xde\x0c\x17\x11\x025\x0f#\x00'
tRp1467
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes,\nbuilding on text summary algorithms from the NLP literature **need\ncitations*** {[}d{]}and further use algorithms that measure text\ncoherency (e.g., textiling **cite**) to alert authors to lack of\ncoherency issues. Finally, we plan to explore alternative ways of\npresenting the information chosen by algorithms to users. For example,\nan assistive system might highlight changes that it deems relevant to a\nspecific author, or it could provide a list of the changes etc.\n"
p1468
sg12
(lp1469
(iversion
Paragraph
p1470
(dp1471
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p1472
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1473
(dp1474
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p1475
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1476
(dp1477
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p1478
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1479
(dp1480
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p1481
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1482
(dp1483
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p1484
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1485
(dp1486
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for the following three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p1487
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1488
(dp1489
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p1490
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1491
(dp1492
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p1493
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1494
(dp1495
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p1496
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1497
(dp1498
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p1499
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1500
(dp1501
g10
S'Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use cosine similaritybetween word vectors that represent the paragraphs, incorportatingLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) whichaccounts for synonyms and does not penalize for typographical errors.'
p1502
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1503
(dp1504
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p1505
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1506
(dp1507
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p1508
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1509
(dp1510
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p1511
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1512
(dp1513
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p1514
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1515
(dp1516
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p1517
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1518
(dp1519
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p1520
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1521
(dp1522
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article.'
p1523
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1524
(dp1525
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the foundation for edit prediction.'
p1526
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1527
(dp1528
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p1529
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1530
(dp1531
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We manually evaluated a random sample of a couple hundred of these editsto determine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p1532
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1533
(dp1534
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p1535
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1536
(dp1537
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p1538
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1539
(dp1540
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p1541
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1542
(dp1543
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p1544
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1545
(dp1546
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}b{]}{[}c{]} are much more predictive than physicalproximity, as shown in Table~{[}table:futureEdits{]}. They are alsosignificantly more predictive than random sample controls. For controls,we compare with the original paragraph as well as a random sample of anyten consecutive versions within Wikipedia article histories.'
p1547
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1548
(dp1549
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. (Proximity was not evaluated for this harsher measure, asit did almost no better than the random control for the first measure.)Further, we obtained a recall of 80\\% for these correct predictions;thus, only 20\\% of the paragraphs that should have been labeled asrelated (based on information ten versions in the future) were missed.'
p1550
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1551
(dp1552
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p1553
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1554
(dp1555
g10
S'The correlation coefficient was 0.99 for all numbers.'
p1556
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1557
(dp1558
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p1559
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1560
(dp1561
g10
S'Our long-term goal is to build an assistive system that will improve thecollaborative writing process. Our developed methods provide the basisfor such a system, by enabling automatic detection of significant editsand predicting their effects. These capabilities can inform decisionsabout alerting authors to specific, important changes and places in thedocument that are likely to require revisions. However, our approachthus far have not leveraged information about the authors who made theedits. In future work we plan to incorporate information about authoridentity to design personalized alerts for authors depending on theircontext of editing and history of revisions. For example, the paragraphtracking algorithm makes it possible to create a list of authors whohave contributed to a specific paragraph, which can be used to determinewho to alert when significant edits occur.'
p1562
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1563
(dp1564
g10
S'We also plan to develop additional algorithms for summarizing changes,building on text summary algorithms from the NLP literature **needcitations*** {[}d{]}and further use algorithms that measure textcoherency (e.g., textiling **cite**) to alert authors to lack ofcoherency issues. Finally, we plan to explore alternative ways ofpresenting the information chosen by algorithms to users. For example,an assistive system might highlight changes that it deems relevant to aspecific author, or it could provide a list of the changes etc.'
p1565
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p1566
sba(iversion
Version
p1567
(dp1568
g7
g8
(S"\x07\xde\x0c\x17\x11'\t\x03k\x00"
tRp1569
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes,\nbuilding on text summary algorithms from the NLP literature **need\ncitations*** {[}d{]}and further use algorithms that measure text\ncoherency (e.g., textiling \\cite{hearst1994multi}) to alert authors to\nlack of coherency issues. Finally, we plan to explore alternative ways\nof presenting the information chosen by algorithms to users. For\nexample, an assistive system might highlight changes that it deems\nrelevant to a specific author, or it could provide a list of the changes\netc.\n"
p1570
sg12
(lp1571
(iversion
Paragraph
p1572
(dp1573
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p1574
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1575
(dp1576
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p1577
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1578
(dp1579
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p1580
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1581
(dp1582
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p1583
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1584
(dp1585
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p1586
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1587
(dp1588
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for the following three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p1589
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1590
(dp1591
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p1592
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1593
(dp1594
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p1595
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1596
(dp1597
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p1598
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1599
(dp1600
g10
S"\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p1601
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1602
(dp1603
g10
S'Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use cosine similaritybetween word vectors that represent the paragraphs, incorportatingLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) whichaccounts for synonyms and does not penalize for typographical errors.'
p1604
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1605
(dp1606
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p1607
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1608
(dp1609
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p1610
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1611
(dp1612
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p1613
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1614
(dp1615
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p1616
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1617
(dp1618
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p1619
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1620
(dp1621
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p1622
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1623
(dp1624
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article.'
p1625
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1626
(dp1627
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the foundation for edit prediction.'
p1628
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1629
(dp1630
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p1631
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1632
(dp1633
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We manually evaluated a random sample of a couple hundred of these editsto determine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p1634
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1635
(dp1636
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p1637
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1638
(dp1639
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p1640
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1641
(dp1642
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p1643
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1644
(dp1645
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p1646
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1647
(dp1648
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}b{]}{[}c{]} are much more predictive than physicalproximity, as shown in Table~{[}table:futureEdits{]}. They are alsosignificantly more predictive than random sample controls. For controls,we compare with the original paragraph as well as a random sample of anyten consecutive versions within Wikipedia article histories.'
p1649
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1650
(dp1651
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. (Proximity was not evaluated for this harsher measure, asit did almost no better than the random control for the first measure.)Further, we obtained a recall of 80\\% for these correct predictions;thus, only 20\\% of the paragraphs that should have been labeled asrelated (based on information ten versions in the future) were missed.'
p1652
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1653
(dp1654
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p1655
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1656
(dp1657
g10
S'The correlation coefficient was 0.99 for all numbers.'
p1658
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1659
(dp1660
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p1661
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1662
(dp1663
g10
S'Our long-term goal is to build an assistive system that will improve thecollaborative writing process. Our developed methods provide the basisfor such a system, by enabling automatic detection of significant editsand predicting their effects. These capabilities can inform decisionsabout alerting authors to specific, important changes and places in thedocument that are likely to require revisions. However, our approachthus far have not leveraged information about the authors who made theedits. In future work we plan to incorporate information about authoridentity to design personalized alerts for authors depending on theircontext of editing and history of revisions. For example, the paragraphtracking algorithm makes it possible to create a list of authors whohave contributed to a specific paragraph, which can be used to determinewho to alert when significant edits occur.'
p1664
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1665
(dp1666
g10
S'We also plan to develop additional algorithms for summarizing changes,building on text summary algorithms from the NLP literature **needcitations*** {[}d{]}and further use algorithms that measure textcoherency (e.g., textiling \\cite{hearst1994multi}) to alert authors tolack of coherency issues. Finally, we plan to explore alternative waysof presenting the information chosen by algorithms to users. Forexample, an assistive system might highlight changes that it deemsrelevant to a specific author, or it could provide a list of the changesetc.'
p1667
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p1668
sba(iversion
Version
p1669
(dp1670
g7
g8
(S'\x07\xde\x0c\x17\x12/(\x01\xd4\xc0'
tRp1671
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes\nand further use algorithms that measure text coherency (e.g., textiling\n\\cite{hearst1994multi}) to alert authors to lack of coherency issues.\nFinally, we plan to explore alternative ways of presenting the\ninformation chosen by algorithms to users. For example, an assistive\nsystem might highlight changes that it deems relevant to a specific\nauthor, or it could provide a list of the changes.\n"
p1672
sg12
(lp1673
(iversion
Paragraph
p1674
(dp1675
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p1676
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1677
(dp1678
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p1679
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1680
(dp1681
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p1682
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1683
(dp1684
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p1685
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1686
(dp1687
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p1688
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1689
(dp1690
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for the following three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p1691
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1692
(dp1693
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p1694
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1695
(dp1696
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p1697
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1698
(dp1699
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p1700
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1701
(dp1702
g10
S"\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p1703
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1704
(dp1705
g10
S'Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use cosine similaritybetween word vectors that represent the paragraphs, incorportatingLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) whichaccounts for synonyms and does not penalize for typographical errors.'
p1706
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1707
(dp1708
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p1709
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1710
(dp1711
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p1712
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1713
(dp1714
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p1715
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1716
(dp1717
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p1718
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1719
(dp1720
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p1721
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1722
(dp1723
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p1724
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1725
(dp1726
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article.'
p1727
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1728
(dp1729
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the foundation for edit prediction.'
p1730
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1731
(dp1732
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p1733
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1734
(dp1735
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We manually evaluated a random sample of a couple hundred of these editsto determine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p1736
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1737
(dp1738
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p1739
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1740
(dp1741
g10
S'\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p1742
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1743
(dp1744
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p1745
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1746
(dp1747
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p1748
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1749
(dp1750
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}a{]}{[}b{]} are much more predictive than physicalproximity, as shown in Table~{[}table:futureEdits{]}. They are alsosignificantly more predictive than random sample controls. For controls,we compare with the original paragraph as well as a random sample of anyten consecutive versions within Wikipedia article histories.'
p1751
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1752
(dp1753
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. (Proximity was not evaluated for this harsher measure, asit did almost no better than the random control for the first measure.)Further, we obtained a recall of 80\\% for these correct predictions;thus, only 20\\% of the paragraphs that should have been labeled asrelated (based on information ten versions in the future) were missed.'
p1754
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1755
(dp1756
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p1757
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1758
(dp1759
g10
S'The correlation coefficient was 0.99 for all numbers.'
p1760
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1761
(dp1762
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p1763
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1764
(dp1765
g10
S'Our long-term goal is to build an assistive system that will improve thecollaborative writing process. Our developed methods provide the basisfor such a system, by enabling automatic detection of significant editsand predicting their effects. These capabilities can inform decisionsabout alerting authors to specific, important changes and places in thedocument that are likely to require revisions. However, our approachthus far have not leveraged information about the authors who made theedits. In future work we plan to incorporate information about authoridentity to design personalized alerts for authors depending on theircontext of editing and history of revisions. For example, the paragraphtracking algorithm makes it possible to create a list of authors whohave contributed to a specific paragraph, which can be used to determinewho to alert when significant edits occur.'
p1766
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1767
(dp1768
g10
S'We also plan to develop additional algorithms for summarizing changesand further use algorithms that measure text coherency (e.g., textiling\\cite{hearst1994multi}) to alert authors to lack of coherency issues.'
p1769
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1770
(dp1771
g10
S'Finally, we plan to explore alternative ways of presenting theinformation chosen by algorithms to users. For example, an assistivesystem might highlight changes that it deems relevant to a specificauthor, or it could provide a list of the changes.'
p1772
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p1773
sba(iversion
Version
p1774
(dp1775
g7
g8
(S'\x07\xde\x0c\x17\x14\n\x06\r\xbf\x88'
tRp1776
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes\nand further use algorithms that measure text coherency (e.g., textiling\n\\cite{hearst1994multi}) to alert authors to lack of coherency issues.\nFinally, we plan to explore alternative ways of presenting the\ninformation chosen by algorithms to users. For example, an assistive\nsystem might highlight changes that it deems relevant to a specific\nauthor, or it could provide a list of the changes.\n"
p1777
sg12
(lp1778
(iversion
Paragraph
p1779
(dp1780
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researcherswrite papers and proposals together, lawyers draft contracts, etc. Inrecent years, collaborative writing of documents has become even morewidespread with the support of frameworks that simplify distributedediting (e.g., google docs, dropbox). However, while document processorsprovide capabilities such as ``track changes'', ``diff'' and commenting,they lack intelligent information sharing mechanisms. They do notattempt to reason about the importance or relevance of changes todifferent authors and do not consider how edits might affect other partsof the document."
p1781
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1782
(dp1783
g10
S'In practice, the collaborative writing process requires significantcommunication between authors to update each other. Because the authorsneed to make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p1784
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1785
(dp1786
g10
S'This paper presents our initial work on developing methods that providethe basis for intelligent interactive systems that support collaboratingauthors. These methods include drawing their attention to edits that areimportant and relevant for them, as well as to other parts of thedocument that are likely to require consequent editing. Systems withsuch capabilities have potential to improve coherence and coordinationwhile reducing the communication burden.'
p1787
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1788
(dp1789
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p1790
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1791
(dp1792
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p1793
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1794
(dp1795
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for the following three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p1796
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1797
(dp1798
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p1799
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1800
(dp1801
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p1802
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1803
(dp1804
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p1805
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1806
(dp1807
g10
S"\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p1808
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1809
(dp1810
g10
S'Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Specifically, we use cosine similaritybetween word vectors that represent the paragraphs, incorportatingLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) whichaccounts for synonyms and does not penalize for typographical errors.'
p1811
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1812
(dp1813
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p1814
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1815
(dp1816
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p1817
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1818
(dp1819
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits inother parts of the documentWe considered three possible types of inter-paragraph relationships.'
p1820
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1821
(dp1822
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p1823
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1824
(dp1825
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposedmethods, using a corpus of Wikipedia articles and their revisionhistories.'
p1826
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1827
(dp1828
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. This approach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p1829
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1830
(dp1831
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article.'
p1832
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1833
(dp1834
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the foundation for edit prediction.'
p1835
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1836
(dp1837
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p1838
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1839
(dp1840
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a couple hundred of these editsto determine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p1841
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1842
(dp1843
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p1844
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1845
(dp1846
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p1847
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1848
(dp1849
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p1850
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1851
(dp1852
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}a{]}{[}b{]} are much more predictive than physicalproximity, as shown in Table~{[}table:futureEdits{]}. They are alsosignificantly more predictive than random sample controls. For controls,we compare with the original paragraph as well as a random sample of anyten consecutive versions within Wikipedia article histories.'
p1853
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1854
(dp1855
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. (Proximity was not evaluated for this harsher measure, asit did almost no better than the random control for the first measure.)Further, we obtained a recall of 80\\% for these correct predictions;thus, only 20\\% of the paragraphs that should have been labeled asrelated (based on information ten versions in the future) were missed.'
p1856
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1857
(dp1858
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p1859
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1860
(dp1861
g10
S'The correlation coefficient was 0.99 for all numbers.'
p1862
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1863
(dp1864
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p1865
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1866
(dp1867
g10
S'Our long-term goal is to build an assistive system that will improve thecollaborative writing process. Our developed methods provide the basisfor such a system, by enabling automatic detection of significant editsand predicting their effects. These capabilities can inform decisionsabout alerting authors to specific, important changes and places in thedocument that are likely to require revisions. However, our approachthus far have not leveraged information about the authors who made theedits. In future work we plan to incorporate information about authoridentity to design personalized alerts for authors depending on theircontext of editing and history of revisions. For example, the paragraphtracking algorithm makes it possible to create a list of authors whohave contributed to a specific paragraph, which can be used to determinewho to alert when significant edits occur.'
p1868
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1869
(dp1870
g10
S'We also plan to develop additional algorithms for summarizing changesand further use algorithms that measure text coherency (e.g., textiling\\cite{hearst1994multi}) to alert authors to lack of coherency issues.'
p1871
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1872
(dp1873
g10
S'Finally, we plan to explore alternative ways of presenting theinformation chosen by algorithms to users. For example, an assistivesystem might highlight changes that it deems relevant to a specificauthor, or it could provide a list of the changes.'
p1874
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p1875
sba(iversion
Version
p1876
(dp1877
g7
g8
(S'\x07\xde\x0c\x19\x0f\x0f8\ry8'
tRp1878
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication among authors to update each other. Because authors need\nto make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents initial work on developing methods that intelligent\ninteractive systems could deploy to support collaborating authors. These\nmethods include drawing authors' attention to edits that are important\nand relevant for them, as well as pointing out other parts of the\ndocument that are likely to require editing given changes they have just\nmade. Systems with such capabilities have potential to improve coherence\nand coordination while reducing authors' communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\n{[}3{]} We consider a significant change to be a noticeable change in\nthe paragraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n{[}1; omitting the ``therefore''{]}Therefore, we use a topic modeling\napproach, which is a better fit for assessing changes in content.\nSpecifically, we use cosine similarity between word vectors that\nrepresent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\n{[}2{]} By calculating the topic similarity between two concurrent\nversions of an edited paragraph, the system can detect whether a\nsignificant change has occurred. If the cosine similarity between the\ntwo paragraphs was below an empirically determined threshold of 0.8, we\nlabel the edit as significant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\npreliminary evaluation of the proposed methods used a corpus of\nWikipedia articles and their revision histories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. A variety of recent work has used this approach\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This capability\nprovides the basis for detecting significant changes and anticipating\nfuture semantic conflicts. Our edit evaluation method successfully\ndetects the most significant changes using the LSI Topic Similarity\nmodel. Based on these significant changes, our anticipate possible\nsemantic conflicts in linked paragraphs. After a significant change,\nparagraphs related to the edited paragraph were indeed more likely to be\nedited in response a couple versions later. Paragraphs linked by similar\nedit histories were most likely to need editing, with paragraphs linked\nby topic similarity not far behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific changes and places in the document\nthat are likely to require revisions. Thus far, have not investigated\nways to leverage information about the authors who made the edits. In\nfuture work, we plan to incorporate information about author identity to\ndesign personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes\nand to investigate the use of algorithms that measure text coherence\n(e.g.,Textiling \\cite{hearst1994multi}) for alerting authors to portions\nof the text that appear to lack coherence. Finally, we plan to explore\nalternative ways of presenting to authors the information chosen by the\nalgorithms as important for them to consider. For example, the system\nmight highlight changes that it deems relevant or provide a list of them\nwith links to the places they appear in the text.\n"
p1879
sg12
(lp1880
(iversion
Paragraph
p1881
(dp1882
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceor relevance of changes to different authors and do not consider howedits might affect other parts of the document."
p1883
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1884
(dp1885
g10
S'In practice, the collaborative writing process requires significantcommunication among authors to update each other. Because authors needto make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p1886
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1887
(dp1888
g10
S"This paper presents initial work on developing methods that intelligentinteractive systems could deploy to support collaborating authors. Thesemethods include drawing authors' attention to edits that are importantand relevant for them, as well as pointing out other parts of thedocument that are likely to require editing given changes they have justmade. Systems with such capabilities have potential to improve coherenceand coordination while reducing authors' communication burden."
p1889
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1890
(dp1891
g10
S'The proposed methods use NLP techniques such as distance metrics andtopic models to track paragraphs across revisions and to identifysignificant changes made to the document. Analysis of co-occurrence ofchanges in past revisions is used to identify parts of the document thattend to change together, which is used to predict which parts of adocument will require edits as a result of a significant change to aparagraph. An empirical evaluation of the approach on a corpus ofWikipedia articles shows promising initial results, as it is able totrack paragraph across revisions, identify significant changes, andpredict which paragraphs are likely to be edited following significantedits.'
p1892
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1893
(dp1894
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p1895
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1896
(dp1897
g10
S'\\section{Approach}\\label{approach}This section describes the developed methods for the following three keycapabilities: (1) tracking paragraphs; (2) identifying significantchanges to paragraphs, and (3) predicting future changes to the article.'
p1898
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1899
(dp1900
g10
S"Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes can help promote only the most importantchanges and decide whether to alert collaborating authors. Predictingfuture changes is required in order to draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p1901
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1902
(dp1903
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p1904
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1905
(dp1906
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p1907
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1908
(dp1909
g10
S"\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}{[}3{]} We consider a significant change to be a noticeable change inthe paragraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p1910
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1911
(dp1912
g10
S"{[}1; omitting the ``therefore''{]}Therefore, we use a topic modelingapproach, which is a better fit for assessing changes in content."
p1913
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1914
(dp1915
g10
S'Specifically, we use cosine similarity between word vectors thatrepresent the paragraphs, incorporating Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors.'
p1916
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1917
(dp1918
g10
S'{[}2{]} By calculating the topic similarity between two concurrentversions of an edited paragraph, the system can detect whether asignificant change has occurred. If the cosine similarity between thetwo paragraphs was below an empirically determined threshold of 0.8, welabel the edit as significant.'
p1919
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1920
(dp1921
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p1922
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1923
(dp1924
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p1925
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1926
(dp1927
g10
S'We considered three possible types of inter-paragraph relationships.'
p1928
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1929
(dp1930
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p1931
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1932
(dp1933
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}preliminary evaluation of the proposed methods used a corpus ofWikipedia articles and their revision histories.'
p1934
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1935
(dp1936
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. A variety of recent work has used this approach\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p1937
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1938
(dp1939
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article.'
p1940
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1941
(dp1942
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the foundation for edit prediction.'
p1943
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1944
(dp1945
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p1946
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1947
(dp1948
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a couple hundred of these editsto determine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p1949
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1950
(dp1951
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p1952
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1953
(dp1954
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p1955
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1956
(dp1957
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p1958
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1959
(dp1960
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}a{]}{[}b{]} are much more predictive than physicalproximity, as shown in Table~{[}table:futureEdits{]}. They are alsosignificantly more predictive than random sample controls. For controls,we compare with the original paragraph as well as a random sample of anyten consecutive versions within Wikipedia article histories.'
p1961
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1962
(dp1963
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. (Proximity was not evaluated for this harsher measure, asit did almost no better than the random control for the first measure.)Further, we obtained a recall of 80\\% for these correct predictions;thus, only 20\\% of the paragraphs that should have been labeled asrelated (based on information ten versions in the future) were missed.'
p1964
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1965
(dp1966
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p1967
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1968
(dp1969
g10
S'The correlation coefficient was 0.99 for all numbers.'
p1970
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1971
(dp1972
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This capabilityprovides the basis for detecting significant changes and anticipatingfuture semantic conflicts. Our edit evaluation method successfullydetects the most significant changes using the LSI Topic Similaritymodel. Based on these significant changes, our anticipate possiblesemantic conflicts in linked paragraphs. After a significant change,paragraphs related to the edited paragraph were indeed more likely to beedited in response a couple versions later. Paragraphs linked by similaredit histories were most likely to need editing, with paragraphs linkedby topic similarity not far behind.'
p1973
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1974
(dp1975
g10
S'Our long-term goal is to build an assistive system that will improve thecollaborative writing process. Our developed methods provide the basisfor such a system, by enabling automatic detection of significant editsand predicting their effects. These capabilities can inform decisionsabout alerting authors to specific changes and places in the documentthat are likely to require revisions. Thus far, have not investigatedways to leverage information about the authors who made the edits. Infuture work, we plan to incorporate information about author identity todesign personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur.'
p1976
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1977
(dp1978
g10
S'We also plan to develop additional algorithms for summarizing changesand to investigate the use of algorithms that measure text coherence(e.g.,Textiling \\cite{hearst1994multi}) for alerting authors to portionsof the text that appear to lack coherence. Finally, we plan to explorealternative ways of presenting to authors the information chosen by thealgorithms as important for them to consider. For example, the systemmight highlight changes that it deems relevant or provide a list of themwith links to the places they appear in the text.'
p1979
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p1980
sba(iversion
Version
p1981
(dp1982
g7
g8
(S'\x07\xde\x0c\x1d\x11\x08%\x0bm\xc8'
tRp1983
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication among authors to update each other. Because authors need\nto make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents initial work on developing methods that intelligent\ninteractive systems could deploy to support collaborating authors. These\nmethods include drawing authors' attention to edits that are important\nand relevant for them, as well as pointing out other parts of the\ndocument that are likely to require editing given changes they have just\nmade. Systems with such capabilities have potential to improve coherence\nand coordination while reducing authors' communication burden.\n\nThe paper describes methods that would enable systems to track\nparagraphs as they are revised, identify paragraphs that have\nsignificant changes, and predict likely future changes based on a\nparticular edit. The first two methods use natural-language processing\n(NLP) techniques for measuring distance between texts and for topic\nmodeling, respectively. The third is based on an analysis of\nco-occurrence of changes in past revisions. An empirical evaluation of\nthe approach on a corpus of Wikipedia articles shows promising initial\nresults. Using these methods it is possible to track paragraph across\nrevisions, identify significant changes, and predict the paragraphs that\nare likely to be edited following a significant edit of a particular\nparagraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. The capability of tracking a\nparagraph through revisions is required for both monitoring changes and\npredicting them. The capability of identifying significant content\nchanges can help promote only the most important changes and decide\nwhether to alert collaborating authors of a change. The capability of\npredicting future changes is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\n{[}3{]} We consider a significant change to be a noticeable change in\nthe paragraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n{[}1; omitting the ``therefore''{]}Therefore, we use a topic modeling\napproach, which is a better fit for assessing changes in content.\nSpecifically, we use cosine similarity between word vectors that\nrepresent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\n{[}2{]} By calculating the topic similarity between two concurrent\nversions of an edited paragraph, the system can detect whether a\nsignificant change has occurred. If the cosine similarity between the\ntwo paragraphs was below an empirically determined threshold of 0.8, we\nlabel the edit as significant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\npreliminary evaluation of the proposed methods used a corpus of\nWikipedia articles and their revision histories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. A variety of recent work has used this approach\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This capability\nprovides the basis for detecting significant changes and anticipating\nfuture semantic conflicts. Our edit evaluation method successfully\ndetects the most significant changes using the LSI Topic Similarity\nmodel. Based on these significant changes, our anticipate possible\nsemantic conflicts in linked paragraphs. After a significant change,\nparagraphs related to the edited paragraph were indeed more likely to be\nedited in response a couple versions later. Paragraphs linked by similar\nedit histories were most likely to need editing, with paragraphs linked\nby topic similarity not far behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific changes and places in the document\nthat are likely to require revisions. Thus far, have not investigated\nways to leverage information about the authors who made the edits. In\nfuture work, we plan to incorporate information about author identity to\ndesign personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes\nand to investigate the use of algorithms that measure text coherence\n(e.g.,Textiling \\cite{hearst1994multi}) for alerting authors to portions\nof the text that appear to lack coherence. Finally, we plan to explore\nalternative ways of presenting to authors the information chosen by the\nalgorithms as important for them to consider. For example, the system\nmight highlight changes that it deems relevant or provide a list of them\nwith links to the places they appear in the text.\n"
p1984
sg12
(lp1985
(iversion
Paragraph
p1986
(dp1987
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceor relevance of changes to different authors and do not consider howedits might affect other parts of the document."
p1988
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1989
(dp1990
g10
S'In practice, the collaborative writing process requires significantcommunication among authors to update each other. Because authors needto make sure their edits are coherent with the document as a whole,including sections written by others, they need to read the entiredocument frequently, or rely on updates from their co-authors. Even whenauthors communicate with each other frequently, they can get lost in thevolume of edits from other collaborators or become overwhelmed with toomuch information.'
p1991
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1992
(dp1993
g10
S"This paper presents initial work on developing methods that intelligentinteractive systems could deploy to support collaborating authors. Thesemethods include drawing authors' attention to edits that are importantand relevant for them, as well as pointing out other parts of thedocument that are likely to require editing given changes they have justmade. Systems with such capabilities have potential to improve coherenceand coordination while reducing authors' communication burden."
p1994
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1995
(dp1996
g10
S'The paper describes methods that would enable systems to trackparagraphs as they are revised, identify paragraphs that havesignificant changes, and predict likely future changes based on aparticular edit. The first two methods use natural-language processing(NLP) techniques for measuring distance between texts and for topicmodeling, respectively. The third is based on an analysis ofco-occurrence of changes in past revisions. An empirical evaluation ofthe approach on a corpus of Wikipedia articles shows promising initialresults. Using these methods it is possible to track paragraph acrossrevisions, identify significant changes, and predict the paragraphs thatare likely to be edited following a significant edit of a particularparagraph.'
p1997
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1998
(dp1999
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and hasdeveloped tools for supporting such collaboration (e.g.,Quilt~\\cite{fish1988quilt}). Most closely related to our work aremethods and tools for supporting improved \\emph{awareness} ofcollaborators about changes made to a document. These include flexiblediffing for reporting significant changes~\\cite{neuwirth1992flexible},methods for categorization of edits and interfaces for presenting themtoauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p2000
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2001
(dp2002
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for: (1) trackingparagraphs; (2) identifying significant changes to paragraphs, and (3)predicting future changes to the article. The capability of tracking aparagraph through revisions is required for both monitoring changes andpredicting them. The capability of identifying significant contentchanges can help promote only the most important changes and decidewhether to alert collaborating authors of a change. The capability ofpredicting future changes is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit."
p2003
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2004
(dp2005
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on theirLevenshtein distance, that is, the number of changed characters requiredto move from one paragraph to another, including additions, deletions,and substitutions. In particular, we use the Levenshtein edit ratiomeasure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision of a document, the algorithm computes theLevenshtein ratio between each paragraph in the old version and eachparagraph in the new version. Two paragraphs are mapped across therevision if they each have the highest Levenshtein ratio for the other.'
p2006
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2007
(dp2008
g10
S'If a paragraph in the new version has no matching paragraphs in the oldversion, meaning that none of its ratios were above a threshold of 0.4,we label the paragraph as an addition. If a paragraph in the old versionis not matched with any paragraphs in the next version, then we considerit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:paragraphs 9, 10, and 12 of the old version were deleted, while theothers found clear matches (e.g., paragraph 11 in the revised documentwas mapped with paragraph 9 in the older version of the document).'
p2009
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2010
(dp2011
g10
S"\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}{[}3{]} We consider a significant change to be a noticeable change inthe paragraph's topic and content. For this calculation, the Levenshteinratio does not provide the right kind of information. For example, iftwo of the paragraph's sentences switch places, the Levenshtein ratiowould decrease despite no meaningful change in content. On the otherhand, changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p2012
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2013
(dp2014
g10
S"{[}1; omitting the ``therefore''{]}Therefore, we use a topic modelingapproach, which is a better fit for assessing changes in content."
p2015
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2016
(dp2017
g10
S'Specifically, we use cosine similarity between word vectors thatrepresent the paragraphs, incorporating Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors.'
p2018
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2019
(dp2020
g10
S'{[}2{]} By calculating the topic similarity between two concurrentversions of an edited paragraph, the system can detect whether asignificant change has occurred. If the cosine similarity between thetwo paragraphs was below an empirically determined threshold of 0.8, welabel the edit as significant.'
p2021
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2022
(dp2023
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p2024
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2025
(dp2026
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p2027
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2028
(dp2029
g10
S'We considered three possible types of inter-paragraph relationships.'
p2030
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2031
(dp2032
g10
S'Paragraphs could be related by \\emph{proximity}: perhaps the neighboringparagraphs would require adjustments, as they are likely part of thesame section. Paragraphs could also be related by \\emph{topicsimilarity}. For example, in an academic paper, the discussion sectionand the conclusion should present similar themes. If one changes, theother may need to be edited to reflect this change. For each significantchange, we used the existing LSI Topic Model to determine whichparagraphs discussed similar topics. Lastly, paragraphs could be relatedbecause of similar \\emph{edit histories}. For each paragraph thatunderwent a significant change, we evaluated the edit history of thisparagraph with every other paragraph in the document. We labeled pairsas related if they changed or remained unchanged together over half thetime. With a higher threshold, the sample size decreases, but with alower threshold, the results become less predictive of a significantchange prompting further edits. This threshold strikes a balance betweenthese two outcomes, as discussed in the Findings section.'
p2033
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2034
(dp2035
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}preliminary evaluation of the proposed methods used a corpus ofWikipedia articles and their revision histories.'
p2036
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2037
(dp2038
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providingextensive data. For our empirical evaluation, we used the completerevision history of 41 different articles chosen from a diverse set oftopics, ranging from famous people and places to mathematical algorithmsto novels. A variety of recent work has used this approach\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus on revisions that contain some substantialchanges, the versions with simple typo fixes~\\footnote{We defined minor  edits as having a Levenshtein distance of under fifteen.} wereeliminated as well to reduce the number of maintenance edits\\cite{kittur2007he}. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs each.'
p2039
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2040
(dp2041
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces with smaller groups of collaborators, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In our corpus, 15 authors on average made 80\\%of the edits to an article.'
p2042
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2043
(dp2044
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the foundation for edit prediction.'
p2045
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2046
(dp2047
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p2048
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2049
(dp2050
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a couple hundred of these editsto determine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p2051
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2052
(dp2053
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, where eachline represents a paragraph that is edited significantly at time zerofor the first time in a while, further adjustments (as represented bydownward spikes) are triggered in the near future.'
p2054
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2055
(dp2056
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p2057
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2058
(dp2059
g10
S'In the Wikipedia data, paragraphs related by edit history were found onaverage 1.6 times per version, and paragraphs related by topicsimilarity were rarer and only found on average once every ten versionsof the text.'
p2060
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2061
(dp2062
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}a{]}{[}b{]} are much more predictive than physicalproximity, as shown in Table~{[}table:futureEdits{]}. They are alsosignificantly more predictive than random sample controls. For controls,we compare with the original paragraph as well as a random sample of anyten consecutive versions within Wikipedia article histories.'
p2063
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2064
(dp2065
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. (Proximity was not evaluated for this harsher measure, asit did almost no better than the random control for the first measure.)Further, we obtained a recall of 80\\% for these correct predictions;thus, only 20\\% of the paragraphs that should have been labeled asrelated (based on information ten versions in the future) were missed.'
p2066
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2067
(dp2068
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p2069
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2070
(dp2071
g10
S'The correlation coefficient was 0.99 for all numbers.'
p2072
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2073
(dp2074
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This capabilityprovides the basis for detecting significant changes and anticipatingfuture semantic conflicts. Our edit evaluation method successfullydetects the most significant changes using the LSI Topic Similaritymodel. Based on these significant changes, our anticipate possiblesemantic conflicts in linked paragraphs. After a significant change,paragraphs related to the edited paragraph were indeed more likely to beedited in response a couple versions later. Paragraphs linked by similaredit histories were most likely to need editing, with paragraphs linkedby topic similarity not far behind.'
p2075
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2076
(dp2077
g10
S'Our long-term goal is to build an assistive system that will improve thecollaborative writing process. Our developed methods provide the basisfor such a system, by enabling automatic detection of significant editsand predicting their effects. These capabilities can inform decisionsabout alerting authors to specific changes and places in the documentthat are likely to require revisions. Thus far, have not investigatedways to leverage information about the authors who made the edits. Infuture work, we plan to incorporate information about author identity todesign personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur.'
p2078
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2079
(dp2080
g10
S'We also plan to develop additional algorithms for summarizing changesand to investigate the use of algorithms that measure text coherence(e.g.,Textiling \\cite{hearst1994multi}) for alerting authors to portionsof the text that appear to lack coherence. Finally, we plan to explorealternative ways of presenting to authors the information chosen by thealgorithms as important for them to consider. For example, the systemmight highlight changes that it deems relevant or provide a list of themwith links to the places they appear in the text.'
p2081
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p2082
sba(iversion
Version
p2083
(dp2084
g7
g8
(S'\x07\xde\x0c\x1d\x14\x01,\x08\xbeH'
tRp2085
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nParagraphs related by edit history were found on average 1.6 times per\nversion, and paragraphs related by topic similarity were more rare and\nonly found on average once every ten versions of the text. Proximity\nrelationships always exist for each paragraphs as there are always\nneighboring paragraphs.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2086
sg12
(lp2087
(iversion
Paragraph
p2088
(dp2089
g10
S"Many documents (e.g., academic papers) are typically written by multiplecollaborators. While many existing tools support such collaborativeefforts (e.g., dropbox, google docs), these tools lack intelligentinformation sharing mechanisms. While capabilities such as ``trackchanges'' and ``diff'' visualize changes to authors, they do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktowards the development of a collaborative system for supportingmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits and predicting parts of the paper that arelikely to require changes as a result of previous edits. Preliminaryevaluation of the proposed methods shows promising results."
p2090
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2091
(dp2092
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceor relevance of changes to different authors and do not consider howedits might affect other parts of the document. Therefore, there iscurrently significant coordination overhead: authors need to frequentlyre-read the entire document or rely on communication from theirco-authors in order to keep track with the current state of the documentand ensure that their edits are mash with other edits."
p2093
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2094
(dp2095
g10
S'Because authors need to make sure their edits are coherent with thedocument as a whole, including sections written by others, they need toread the entire document frequently, or rely on updates from theirco-authors. Even when authors communicate with each other frequently,they can get lost in the volume of edits from other collaborators orbecome overwhelmed with too much information.'
p2096
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2097
(dp2098
g10
S'This paper presents our initial work towards the development of acollaborative system for assisting multi-author writing by drawingauthors attention to edits that are important and relevant for them, andpointing out other parts of the document that are likely to requireediting given changes they have just made.'
p2099
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2100
(dp2101
g10
S"The paper describes methods for tracking paragraphs as they are revised,for identifying paragraphs that have been significantly changed, and forpredicting which parts of the document are likely to change following aparticular edit. Systems with such capabilities have potential toimprove coherence and coordination while reducing authors' communicationburden. An empirical evaluation of the approach on a corpus of Wikipediaarticles shows promising initial results. Using these methods it ispossible to track paragraph across revisions, identify significantchanges, and predict the paragraphs that are likely to be editedfollowing a significant edit of a particular paragraph."
p2102
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2103
(dp2104
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorization of editsand interfaces for presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p2105
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2106
(dp2107
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our investigation of thelightweight use of NLP techniques and history tracking for providingthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in a new versioncorrespond to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion."
p2108
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2109
(dp2110
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,and 12 of the old version were deleted, while the others found clearmatches (e.g., paragraph 11 in the new version was mapped with paragraph9 in the old version).'
p2111
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2112
(dp2113
g10
S"\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach. Specifically, we use cosine similarity between wordvectors that represent the paragraphs, incorporating Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. If the cosine similaritybetween the new and old versions of a paragraph is below an empiricallydetermined threshold of 0.8, we consider the edit to be significant."
p2114
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2115
(dp2116
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p2117
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2118
(dp2119
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p2120
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2121
(dp2122
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p2123
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2124
(dp2125
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topicsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\\emph{edit histories}, i.e., paragraphs that tended to be editedtogether in previous revisions. For (3), we labeled pairs as related ifthey changed or remained unchanged together over half the time inprevious revisions.'
p2126
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2127
(dp2128
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p2129
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2130
(dp2131
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough information. To focus on revisions that contain some substantialchanges, the versions with simple typo fixes (Levenshtein distance\\(< 15\\) ) were eliminated.'
p2132
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2133
(dp2134
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the basis for edit prediction.'
p2135
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2136
(dp2137
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As can be seen, most edits areminor, and with the threshold ratio of 0.8 we labeled about 15\\% of theedits as significant.'
p2138
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2139
(dp2140
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits todetermine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p2141
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2142
(dp2143
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggersedits in other paragraphs in the next revisions. This is shown inFigure~{[}fig:edits{]}, where each line represents a paragraph that isedited significantly at time 0 after not being significantly edited inrecent versions, further adjustments (as represented by downward spikes)are triggered in the near future. We evaluated the three inter-paragraphrelationships (proximity, topic similarity and edit history) todetermine which paragraphs are more likely to require further editingafter a significant change occurs in the article.'
p2144
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2145
(dp2146
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checked whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the paragraphs continue to be edited together tenversions after the significant change, that is whether they changetogether (or remain unchanged together) more than half the time. This isa stronger indication than just undergoing at least one significantchange.'
p2147
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2148
(dp2149
g10
S'Paragraphs related by edit history were found on average 1.6 times perversion, and paragraphs related by topic similarity were more rare andonly found on average once every ten versions of the text. Proximityrelationships always exist for each paragraphs as there are alwaysneighboring paragraphs.'
p2150
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2151
(dp2152
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}a{]}{[}b{]} are much more predictive of a futuresignificant edit than proximity, as shown inTable~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p2153
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2154
(dp2155
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairsrelated by topic and 71\\% of pairs related by edit history. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions; thus, only 20\\%of the paragraphs that should have been labeled as related (based oninformation ten versions in the future) were missed.'
p2156
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2157
(dp2158
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improvethe collaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edit andfor predicting future edits, provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p2159
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2160
(dp2161
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur. We also plan to developadditional algorithms for summarizing changes and to investigate the useof algorithms that measure text coherence (e.g.,Textiling\\cite{hearst1994multi}) for alerting authors to portions of the textthat appear to lack coherence. Finally, we plan to explore alternativeways of presenting to authors the information chosen by the algorithmsas important for them to consider. For example, the system mighthighlight changes that it deems relevant or provide a list of them withlinks to the places they appear in the text.'
p2162
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p2163
sba(iversion
Version
p2164
(dp2165
g7
g8
(S'\x07\xde\x0c\x0e\x10\x18\x0f\x0c\xaa0'
tRp2166
sg10
S". See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.\n\n\\section{Introduction}\\label{introduction}\n\nMaybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikis\n\nnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision Activity\n\nWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nThe system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.\n\nINSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.\n\nThis method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches.\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in figure\n{[}X{]}.\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p2167
sg12
(lp2168
(iversion
Paragraph
p2169
(dp2170
g10
S'. See: \\url{http://www.acm.org/about/class/1998/} for help using the ACMClassification system.'
p2171
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2172
(dp2173
g10
S'\\section{Introduction}\\label{introduction}Maybe one paragraph (previous years talk about motivation in similarwork in intro and have one-two paragraphs in a background/related worksection) about how previous work tried to come up with frameworks tosupport writers and tried to investigate the writers problems. Theydescribe the motivation and the need for such a system: * TrackingChanges in Collaborative Writing: Edits, Visibility and GroupMaintenance Old examples: * Quilt: A collaborative tool for cooperativewriting - 1988 * User-centred iterative design of collaborative software-1993 * what do co-authors use? * They try to find relevant changes: *Flexible Diff-ing in a collaborative writing system * What did they do?'
p2174
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2175
(dp2176
g10
S'Deriving High-Level edit histories in Wikisnewer examples also try to classify changes: * How a Structured DocumentModel Can Support Awareness in Collaborative Authoring * A framework forasynchronous change awareness in collaborative documents and workspaces* some try to find conflicts (different definition of conflict though):* Enabling truly collaborative writing on a computer * and some try tofind an explicit structur in texts: * A narrative-based collaborativewriting tool for constructing coherent technical documents * trying topredict: * WikiChanges - Exposing Wikipedia Revision ActivityWhen authors collaborate to write a paper, they need to communicateconstantly to ensure that they are all on the same page. Because theauthors need to make sure that their edits are coherent with the rest ofthe paper, including sections written by others, they need to read theentire paper frequently, or rely on updates communicated by theircoauthors. Even with constant communication, authors can get lost in thevolume of edits from other collaborators. Therefore, an assistive systemwith a summary of the significant changes contributed by other authorswould be helpful. We hypothesize that when an author makes a significantedit to a paragraph, it eventually triggers a series of adjustments inrelated paragraphs. Before these adjustments occur, semantic conflictsmight occur between authors. We wanted a collaborative writing system toalso predict when and where these conflicts may occur, in order to alerteven more specifically.'
p2177
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2178
(dp2179
g10
S'The system is composed of the following three components: (1) trackingparagraphs; (2) identifying significant changes to paragraphs, and (3)predicting future changes to the article. Tracking paragraphs throughpaper revisions is a core capability required for monitoring changes andpredicting them. The identification of significant content changes isimportant for a system to understand how important different changes areand whether collaborating authors should be notified. Predicting futurechanges enables the system to not only report to authors about changesthat have already been made, but also draw their attention to otherparts of the document that might require changes as a result of thechanges made.'
p2180
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2181
(dp2182
g10
S"INSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changesin related paragraphs eighty percent of the time{]}, but incollaborative writing, these resulting edits do not occurinstantaneously. Instead of waiting for other authors to discover theinconsistency caused by one author's edit, we want an assistive systemthat can alert relevant authors about paragraphs that might need anadditional look as a result of an edit."
p2183
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2184
(dp2185
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a widevariety of Wikipedia articles that undergo intense editing processes.'
p2186
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2187
(dp2188
g10
S'Wikipedia is a unique source because it presents extensive data forcollaborative writing. The findings use the complete revision revisionhistory of 41 different articles chosen from a diverse set of topics,from famous people and places to mathematical algorithms to novels. Therevision histories were downloaded as raw xml data. We removedWikipedia-specific tags that indicate formatting and other irrelevantdata, and eliminated versions of the articles under 150 characters, asthey did not contain enough information. To focus only on revisions withconsequential changes, the versions with simple typo fixes{[}1{]} wereeliminated as well. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs. Wikipediadata affords results applicable to other collaborative writing spaces,because although the average article has over 400 contributing authors,most of these authors make a one-time change. In fact, on average, 15authors make 80\\% of the edits to an article. This enables theconsideration of interactions between authors, which is crucial forlearning about collaborative behavior.'
p2189
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2190
(dp2191
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein editratio measure, which is defined in equation 1.'
p2192
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2193
(dp2194
g10
S'This method differed from previous attempts in the sense that it tracksparagraphs as a whole instead of just the longest common subsequence asused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.'
p2195
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2196
(dp2197
g10
S'A Levenshtein ratio close to one between two paragraphs indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision, we computed the Levenshtein ratio betweeneach paragraph in the old version and each paragraph in the new version.'
p2198
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2199
(dp2200
g10
S"Two paragraphs are mapped across the revision if they each had thehighest Levenshtein ratio for the other. If a paragraph in the newversion had no ``matches'', meaning that none of its ratios were above athreshold of 0.4, this paragraph was new. If a paragraph in the oldversion had no ``matches'', then it was deleted in the revision. Theimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of theold version were deleted, while the others found clear matches."
p2201
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2202
(dp2203
g10
S"\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph'stopic and content. For this calculation, the Levenshtein ratio does notprovide the right kind of information. For example, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple key words will slightly lower the Levenshtein ratio,but could drastically affect the content."
p2204
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2205
(dp2206
g10
S"As shown in figure 1, which shows the distribution of the differencesbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshteinand LSI ratios demonstrate very different statistics. {[}INSERTFIGURE{]}Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Latent Semantic Indexing is a form oftopic modeling that calculates the topic similarity between two texts."
p2207
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2208
(dp2209
g10
S"Its strengths lie in accounting for synonyms and not penalizing fortypographical errors. The process begins by composing a corpus for eachWikipedia article from all of the documents (paragraphs of the versionsof the article). It analyzes tokens (a specific instance of a word),eliminating those that only occur once, as well as stopword tokens, suchas `the' or `and'. It then creates a TF-IDF matrix, which assigns aweight to every token in each document, which indicates the importanceof that token for this document. This weight increases proportionally tothe frequency of the word in the document, but accounts for thefrequency of the word in the corpus, such that the frequent occurrenceof a usually uncommon word is given a larger weight to signify thisimportance."
p2210
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2211
(dp2212
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p2213
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2214
(dp2215
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p2216
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2217
(dp2218
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p2219
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2220
(dp2221
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p2222
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2223
(dp2224
g10
S'Therefore, in order to predict future conflicts, an assistive systemneeds to detect significant changes and then determine consequentlywhich paragraphs were most likely to change.'
p2225
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2226
(dp2227
g10
S'We looked at three possible types of inter-paragraph relationships.'
p2228
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2229
(dp2230
g10
S'Paragraphs could be related by physical proximity: perhaps theneighboring paragraphs would require adjustments, as they are likelypart of the same section. Paragraphs could also be related by topic. Forexample, in an academic paper, the discussion section and the conclusionshould present similar themes. If one changes, the other may need to beedited to reflect this change. For each significant change, we used theexisting LSI Topic Model to determine which paragraphs discussed similartopics. Lastly, paragraphs could be related because of similar edithistories. For each significant change, we evaluated the edit history ofthis paragraph with every other paragraph in the article. We labeledpairs as related if they changed or remained unchanged together overhalf the time. With a higher threshold, the sample size decreases, butwith a lower threshold, the results become less predictive of asignificant change prompting further edits. This threshold strikes abalance between these two outcomes.'
p2231
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2232
(dp2233
g10
S"To evaluate these both of these suspected relationships, we looked atthe related paragraphs' edit patterns in the ten versions following thesignificant change. If the related paragraphs changed together over halfthe time, the paragraphs with this relationship proved to be related inthe future, verifying the relationship at the time of the significantchange."
p2234
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2235
(dp2236
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutiveversions of a paper, we calculated the number of versions from theparagraphs' inception to its demise. On average, paragraphs lasted 83article revisions."
p2237
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2238
(dp2239
g10
S'\\subsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown in figure{[}X{]}.'
p2240
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2241
(dp2242
g10
S'We evaluated a random sample of these edits to determine that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p2243
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2244
(dp2245
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p2246
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2247
(dp2248
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in figure {[}X{]}, when a paragraph isedited for the first time in a while, further adjustments are triggeredin the near future.'
p2249
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2250
(dp2251
g10
S'Caption: After a significant change at version 0, consequent edits aremore frequent.'
p2252
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2253
(dp2254
g10
S'We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p2255
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2256
(dp2257
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in table {[}X{]}. They are also significantly more predictive thanrandom sample controls. For controls, we compare with the originalparagraph as well as a random sample of any ten consecutive versionswithin Wikipedia article histories.'
p2258
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2259
(dp2260
g10
S'Relationship or Control Percentage of times that paragraph experiencedat least one significant change Edit History 81\\% Topic Similarity .'
p2261
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2262
(dp2263
g10
S'Physical Proximity 24\\% Paragraph with original significant change 40\\%Random Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80Relationship Number Found Successfully Linked Ratio of SuccessfullyLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,68571\\%Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p2264
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2265
(dp2266
g10
S'The correlation coefficient was 0.99 for all numbers.'
p2267
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2268
(dp2269
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p2270
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2271
(dp2272
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p2273
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2274
(dp2275
g10
S'We imagine a couple other helpful components for an assistive systemthat our methods could provide the foundation for. Using text summaryalgorithms, the system could provide a succinct textual summary ofsignificant changes already detected. The system could also \\ldots{}.'
p2276
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2277
(dp2278
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determiningwhether a paragraph will change together in the future. Consequently, weassert that if significant edit occurs, related paragraphs should alsobe edited. A proposed assistive system will alert the relevant authorsof related paragraphs if this resulting edit does not occur. Bydetecting relationships between paragraphs in a multi-authored paper,our system can predict and alert appropriate authors if a significantchange has the potential to create a semantic conflict within the paper.'
p2279
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p2280
sba(iversion
Version
p2281
(dp2282
g7
g8
(S'\x07\xdf\x01\x02\x10\x1e\x02\x05$h'
tRp2283
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nPairs of paragraphs related by edit history were found on average 1.6\ntimes per revision of the text. A pair related by topic similarity were\nonly found once every ten versions. Proximity relationships always exist\nfor each paragraphs as there are always neighboring paragraphs.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2284
sg12
(lp2285
(iversion
Paragraph
p2286
(dp2287
g10
S"Many documents (e.g., academic papers) are typically written by multiplecollaborators. While many existing tools support such collaborativeefforts (e.g., dropbox, google docs), these tools lack intelligentinformation sharing mechanisms. While capabilities such as ``trackchanges'' and ``diff'' visualize changes to authors, they do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktowards the development of a collaborative system for supportingmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits and predicting parts of the paper that arelikely to require changes as a result of previous edits. Preliminaryevaluation of the proposed methods shows promising results."
p2288
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2289
(dp2290
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceor relevance of changes to different authors and do not consider howedits might affect other parts of the document. Therefore, there iscurrently significant coordination overhead: authors need to frequentlyre-read the entire document or rely on communication from theirco-authors in order to keep track with the current state of the documentand ensure that their edits are mash with other edits."
p2291
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2292
(dp2293
g10
S'Because authors need to make sure their edits are coherent with thedocument as a whole, including sections written by others, they need toread the entire document frequently, or rely on updates from theirco-authors. Even when authors communicate with each other frequently,they can get lost in the volume of edits from other collaborators orbecome overwhelmed with too much information.'
p2294
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2295
(dp2296
g10
S'This paper presents our initial work towards the development of acollaborative system for assisting multi-author writing by drawingauthors attention to edits that are important and relevant for them, andpointing out other parts of the document that are likely to requireediting given changes they have just made.'
p2297
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2298
(dp2299
g10
S"The paper describes methods for tracking paragraphs as they are revised,for identifying paragraphs that have been significantly changed, and forpredicting which parts of the document are likely to change following aparticular edit. Systems with such capabilities have potential toimprove coherence and coordination while reducing authors' communicationburden. An empirical evaluation of the approach on a corpus of Wikipediaarticles shows promising initial results. Using these methods it ispossible to track paragraph across revisions, identify significantchanges, and predict the paragraphs that are likely to be editedfollowing a significant edit of a particular paragraph."
p2300
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2301
(dp2302
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorization of editsand interfaces for presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p2303
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2304
(dp2305
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our investigation of thelightweight use of NLP techniques and history tracking for providingthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in a new versioncorrespond to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion."
p2306
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2307
(dp2308
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,and 12 of the old version were deleted, while the others found clearmatches (e.g., paragraph 11 in the new version was mapped with paragraph9 in the old version).'
p2309
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2310
(dp2311
g10
S"\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach. Specifically, we use cosine similarity between wordvectors that represent the paragraphs, incorporating Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. If the cosine similaritybetween the new and old versions of a paragraph is below an empiricallydetermined threshold of 0.8, we consider the edit to be significant."
p2312
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2313
(dp2314
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p2315
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2316
(dp2317
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p2318
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2319
(dp2320
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p2321
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2322
(dp2323
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topicsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\\emph{edit histories}, i.e., paragraphs that tended to be editedtogether in previous revisions. For (3), we labeled pairs as related ifthey changed or remained unchanged together over half the time inprevious revisions.'
p2324
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2325
(dp2326
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p2327
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2328
(dp2329
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough information. To focus on revisions that contain some substantialchanges, the versions with simple typo fixes (Levenshtein distance\\(< 15\\) ) were eliminated.'
p2330
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2331
(dp2332
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the basis for edit prediction.'
p2333
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2334
(dp2335
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As can be seen, most edits areminor, and with the threshold ratio of 0.8 we labeled about 15\\% of theedits as significant.'
p2336
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2337
(dp2338
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits todetermine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p2339
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2340
(dp2341
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggersedits in other paragraphs in the next revisions. This is shown inFigure~{[}fig:edits{]}, where each line represents a paragraph that isedited significantly at time 0 after not being significantly edited inrecent versions, further adjustments (as represented by downward spikes)are triggered in the near future. We evaluated the three inter-paragraphrelationships (proximity, topic similarity and edit history) todetermine which paragraphs are more likely to require further editingafter a significant change occurs in the article.'
p2342
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2343
(dp2344
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checked whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the paragraphs continue to be edited together tenversions after the significant change, that is whether they changetogether (or remain unchanged together) more than half the time. This isa stronger indication than just undergoing at least one significantchange.'
p2345
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2346
(dp2347
g10
S'Pairs of paragraphs related by edit history were found on average 1.6times per revision of the text. A pair related by topic similarity wereonly found once every ten versions. Proximity relationships always existfor each paragraphs as there are always neighboring paragraphs.'
p2348
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2349
(dp2350
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}a{]}{[}b{]} are much more predictive of a futuresignificant edit than proximity, as shown inTable~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p2351
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2352
(dp2353
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairsrelated by topic and 71\\% of pairs related by edit history. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions; thus, only 20\\%of the paragraphs that should have been labeled as related (based oninformation ten versions in the future) were missed.'
p2354
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2355
(dp2356
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improvethe collaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edit andfor predicting future edits, provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p2357
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2358
(dp2359
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur. We also plan to developadditional algorithms for summarizing changes and to investigate the useof algorithms that measure text coherence (e.g.,Textiling\\cite{hearst1994multi}) for alerting authors to portions of the textthat appear to lack coherence. Finally, we plan to explore alternativeways of presenting to authors the information chosen by the algorithmsas important for them to consider. For example, the system mighthighlight changes that it deems relevant or provide a list of them withlinks to the places they appear in the text.'
p2360
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p2361
sba(iversion
Version
p2362
(dp2363
g7
g8
(S'\x07\xdf\x01\x02\x11\x04"\x00\'\x10'
tRp2364
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2365
sg12
(lp2366
(iversion
Paragraph
p2367
(dp2368
g10
S"Many documents (e.g., academic papers) are typically written by multiplecollaborators. While many existing tools support such collaborativeefforts (e.g., dropbox, google docs), these tools lack intelligentinformation sharing mechanisms. While capabilities such as ``trackchanges'' and ``diff'' visualize changes to authors, they do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktowards the development of a collaborative system for supportingmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits and predicting parts of the paper that arelikely to require changes as a result of previous edits. Preliminaryevaluation of the proposed methods shows promising results."
p2369
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2370
(dp2371
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceor relevance of changes to different authors and do not consider howedits might affect other parts of the document. Therefore, there iscurrently significant coordination overhead: authors need to frequentlyre-read the entire document or rely on communication from theirco-authors in order to keep track with the current state of the documentand ensure that their edits are mash with other edits."
p2372
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2373
(dp2374
g10
S'Because authors need to make sure their edits are coherent with thedocument as a whole, including sections written by others, they need toread the entire document frequently, or rely on updates from theirco-authors. Even when authors communicate with each other frequently,they can get lost in the volume of edits from other collaborators orbecome overwhelmed with too much information.'
p2375
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2376
(dp2377
g10
S'This paper presents our initial work towards the development of acollaborative system for assisting multi-author writing by drawingauthors attention to edits that are important and relevant for them, andpointing out other parts of the document that are likely to requireediting given changes they have just made.'
p2378
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2379
(dp2380
g10
S"The paper describes methods for tracking paragraphs as they are revised,for identifying paragraphs that have been significantly changed, and forpredicting which parts of the document are likely to change following aparticular edit. Systems with such capabilities have potential toimprove coherence and coordination while reducing authors' communicationburden. An empirical evaluation of the approach on a corpus of Wikipediaarticles shows promising initial results. Using these methods it ispossible to track paragraph across revisions, identify significantchanges, and predict the paragraphs that are likely to be editedfollowing a significant edit of a particular paragraph."
p2381
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2382
(dp2383
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorization of editsand interfaces for presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p2384
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2385
(dp2386
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our investigation of thelightweight use of NLP techniques and history tracking for providingthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion."
p2387
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2388
(dp2389
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,and 12 of the old version were deleted, while the others found clearmatches (e.g., paragraph 11 in the new version was mapped with paragraph9 in the old version).'
p2390
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2391
(dp2392
g10
S"\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach. Specifically, we use cosine similarity between wordvectors that represent the paragraphs, incorporating Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. If the cosine similaritybetween the new and old versions of a paragraph is below an empiricallydetermined threshold of 0.8, we consider the edit to be significant."
p2393
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2394
(dp2395
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p2396
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2397
(dp2398
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p2399
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2400
(dp2401
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p2402
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2403
(dp2404
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topicsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\\emph{edit histories}, i.e., paragraphs that tended to be editedtogether in previous revisions. For (3), we labeled pairs as related ifthey changed or remained unchanged together over half the time inprevious revisions.'
p2405
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2406
(dp2407
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p2408
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2409
(dp2410
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough information. To focus on revisions that contain some substantialchanges, the versions with simple typo fixes (Levenshtein distance\\(< 15\\) ) were eliminated.'
p2411
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2412
(dp2413
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the basis for edit prediction.'
p2414
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2415
(dp2416
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As can be seen, most edits areminor, and with the threshold ratio of 0.8 we labeled about 15\\% of theedits as significant.'
p2417
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2418
(dp2419
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits todetermine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p2420
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2421
(dp2422
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggersedits in other paragraphs in the next revisions. This is shown inFigure~{[}fig:edits{]}, where each line represents a paragraph that isedited significantly at time 0 after not being significantly edited inrecent versions, further adjustments (as represented by downward spikes)are triggered in the near future. We evaluated the three inter-paragraphrelationships (proximity, topic similarity and edit history) todetermine which paragraphs are more likely to require further editingafter a significant change occurs in the article.'
p2423
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2424
(dp2425
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checked whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the paragraphs continue to be edited together tenversions after the significant change, that is whether they changetogether (or remain unchanged together) more than half the time. This isa stronger indication than just undergoing at least one significantchange.'
p2426
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2427
(dp2428
g10
S'On average, 1.6 pairs of paragraphs related by edit history were foundper revision of the text. A pair related by topic similarity was onlyfound once every ten versions. Proximity relationships always exist ineach version, as most paragraphs have two neighbors.'
p2429
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2430
(dp2431
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}a{]}{[}b{]} are much more predictive of a futuresignificant edit than proximity, as shown inTable~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p2432
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2433
(dp2434
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairsrelated by topic and 71\\% of pairs related by edit history. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions; thus, only 20\\%of the paragraphs that should have been labeled as related (based oninformation ten versions in the future) were missed.'
p2435
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2436
(dp2437
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improvethe collaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edit andfor predicting future edits, provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p2438
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2439
(dp2440
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur. We also plan to developadditional algorithms for summarizing changes and to investigate the useof algorithms that measure text coherence (e.g.,Textiling\\cite{hearst1994multi}) for alerting authors to portions of the textthat appear to lack coherence. Finally, we plan to explore alternativeways of presenting to authors the information chosen by the algorithmsas important for them to consider. For example, the system mighthighlight changes that it deems relevant or provide a list of them withlinks to the places they appear in the text.'
p2441
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p2442
sba(iversion
Version
p2443
(dp2444
g7
g8
(S'\x07\xdf\x01\x02\x116\x14\x08\x06\xb0'
tRp2445
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2446
sg12
(lp2447
(iversion
Paragraph
p2448
(dp2449
g10
S"Many documents (e.g., academic papers) are typically written by multiplecollaborators. While many existing tools support such collaborativeefforts (e.g., dropbox, google docs), these tools lack intelligentinformation sharing mechanisms. While capabilities such as ``trackchanges'' and ``diff'' visualize changes to authors, they do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktowards the development of a collaborative system for supportingmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits and predicting parts of the paper that arelikely to require changes as a result of previous edits. Preliminaryevaluation of the proposed methods shows promising results."
p2450
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2451
(dp2452
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceor relevance of changes to different authors and do not consider howedits might affect other parts of the document. Therefore, there iscurrently significant coordination overhead: authors need to frequentlyre-read the entire document or rely on communication from theirco-authors in order to keep track with the current state of the documentand ensure that their edits are mash with other edits."
p2453
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2454
(dp2455
g10
S'Because authors need to make sure their edits are coherent with thedocument as a whole, including sections written by others, they need toread the entire document frequently, or rely on updates from theirco-authors. Even when authors communicate with each other frequently,they can get lost in the volume of edits from other collaborators orbecome overwhelmed with too much information.'
p2456
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2457
(dp2458
g10
S'This paper presents our initial work towards the development of acollaborative system for assisting multi-author writing by drawingauthors attention to edits that are important and relevant for them, andpointing out other parts of the document that are likely to requireediting given changes they have just made.'
p2459
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2460
(dp2461
g10
S"The paper describes methods for tracking paragraphs as they are revised,for identifying paragraphs that have been significantly changed, and forpredicting which parts of the document are likely to change following aparticular edit. Systems with such capabilities have potential toimprove coherence and coordination while reducing authors' communicationburden. An empirical evaluation of the approach on a corpus of Wikipediaarticles shows promising initial results. Using these methods it ispossible to track paragraph across revisions, identify significantchanges, and predict the paragraphs that are likely to be editedfollowing a significant edit of a particular paragraph."
p2462
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2463
(dp2464
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorization of editsand interfaces for presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p2465
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2466
(dp2467
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our investigation of thelightweight use of NLP techniques and history tracking for providingthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion."
p2468
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2469
(dp2470
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,and 12 of the old version were deleted, while the others found clearmatches (e.g., paragraph 11 in the new version was mapped with paragraph9 in the old version).'
p2471
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2472
(dp2473
g10
S"\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach. Specifically, we use cosine similarity between wordvectors that represent the paragraphs, incorporating Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. If the cosine similaritybetween the new and old versions of a paragraph is below an empiricallydetermined threshold of 0.8, we consider the edit to be significant."
p2474
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2475
(dp2476
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p2477
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2478
(dp2479
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p2480
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2481
(dp2482
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p2483
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2484
(dp2485
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith high cosine similarity. For (2), we labeled pairs as related ifthey changed or remained unchanged together over half the time inprevious revisions.'
p2486
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2487
(dp2488
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p2489
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2490
(dp2491
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough information. To focus on revisions that contain some substantialchanges, the versions with simple typo fixes (Levenshtein distance\\(< 15\\) ) were eliminated.'
p2492
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2493
(dp2494
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the basis for edit prediction.'
p2495
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2496
(dp2497
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As can be seen, most edits areminor, and with the threshold ratio of 0.8 we labeled about 15\\% of theedits as significant.'
p2498
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2499
(dp2500
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits todetermine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p2501
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2502
(dp2503
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggersedits in other paragraphs in the next revisions. This is shown inFigure~{[}fig:edits{]}, where each line represents a paragraph that isedited significantly at time 0 after not being significantly edited inrecent versions, further adjustments (as represented by downward spikes)are triggered in the near future. We evaluated the three inter-paragraphrelationships (proximity, topic similarity and edit history) todetermine which paragraphs are more likely to require further editingafter a significant change occurs in the article.'
p2504
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2505
(dp2506
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checked whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the paragraphs continue to be edited together tenversions after the significant change, that is whether they changetogether (or remain unchanged together) more than half the time. This isa stronger indication than just undergoing at least one significantchange.'
p2507
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2508
(dp2509
g10
S'On average, 1.6 pairs of paragraphs related by edit history were foundper revision of the text. A pair related by topic similarity was onlyfound once every ten versions. Proximity relationships always exist ineach version, as most paragraphs have two neighbors.'
p2510
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2511
(dp2512
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity{[}a{]}{[}b{]} are much more predictive of a futuresignificant edit than proximity, as shown inTable~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p2513
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2514
(dp2515
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairsrelated by topic and 71\\% of pairs related by edit history. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions; thus, only 20\\%of the paragraphs that should have been labeled as related (based oninformation ten versions in the future) were missed.'
p2516
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2517
(dp2518
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improvethe collaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edit andfor predicting future edits, provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p2519
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2520
(dp2521
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur. We also plan to developadditional algorithms for summarizing changes and to investigate the useof algorithms that measure text coherence (e.g.,Textiling\\cite{hearst1994multi}) for alerting authors to portions of the textthat appear to lack coherence. Finally, we plan to explore alternativeways of presenting to authors the information chosen by the algorithmsas important for them to consider. For example, the system mighthighlight changes that it deems relevant or provide a list of them withlinks to the places they appear in the text.'
p2522
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p2523
sba(iversion
Version
p2524
(dp2525
g7
g8
(S'\x07\xdf\x01\x02\x16\x1f0\x0cX('
tRp2526
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2527
sg12
(lp2528
(iversion
Paragraph
p2529
(dp2530
g10
S"Many documents (e.g., academic papers) are typically written by multiplecollaborators. While many existing tools support such collaborativeefforts (e.g., dropbox, google docs), these tools lack intelligentinformation sharing mechanisms. While capabilities such as ``trackchanges'' and ``diff'' visualize changes to authors, they do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktowards the development of a collaborative system for supportingmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits and predicting parts of the paper that arelikely to require changes as a result of previous edits. Preliminaryevaluation of the proposed methods shows promising results."
p2531
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2532
(dp2533
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceor relevance of changes to different authors and do not consider howedits might affect other parts of the document. Therefore, there iscurrently significant coordination overhead: authors need to frequentlyre-read the entire document or rely on communication from theirco-authors in order to keep track with the current state of the documentand ensure that their edits are mash with other edits."
p2534
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2535
(dp2536
g10
S'Because authors need to make sure their edits are coherent with thedocument as a whole, including sections written by others, they need toread the entire document frequently, or rely on updates from theirco-authors. Even when authors communicate with each other frequently,they can get lost in the volume of edits from other collaborators orbecome overwhelmed with too much information.'
p2537
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2538
(dp2539
g10
S'This paper presents our initial work towards the development of acollaborative system for assisting multi-author writing by drawingauthors attention to edits that are important and relevant for them, andpointing out other parts of the document that are likely to requireediting given changes they have just made.'
p2540
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2541
(dp2542
g10
S"The paper describes methods for tracking paragraphs as they are revised,for identifying paragraphs that have been significantly changed, and forpredicting which parts of the document are likely to change following aparticular edit. Systems with such capabilities have potential toimprove coherence and coordination while reducing authors' communicationburden. An empirical evaluation of the approach on a corpus of Wikipediaarticles shows promising initial results. Using these methods it ispossible to track paragraph across revisions, identify significantchanges, and predict the paragraphs that are likely to be editedfollowing a significant edit of a particular paragraph."
p2543
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2544
(dp2545
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorization of editsand interfaces for presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p2546
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2547
(dp2548
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our investigation of thelightweight use of NLP techniques and history tracking for providingthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion."
p2549
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2550
(dp2551
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,and 12 of the old version were deleted, while the others found clearmatches (e.g., paragraph 11 in the new version was mapped with paragraph9 in the old version).'
p2552
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2553
(dp2554
g10
S"\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach. Specifically, we use cosine similarity between wordvectors that represent the paragraphs, incorporating Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. If the cosine similaritybetween the new and old versions of a paragraph is below an empiricallydetermined threshold of 0.8, we consider the edit to be significant."
p2555
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2556
(dp2557
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p2558
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2559
(dp2560
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p2561
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2562
(dp2563
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p2564
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2565
(dp2566
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith high cosine similarity. For (2), we labeled pairs as related ifthey changed or remained unchanged together over half the time inprevious revisions.'
p2567
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2568
(dp2569
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p2570
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2571
(dp2572
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough information. To focus on revisions that contain some substantialchanges, the versions with simple typo fixes (Levenshtein distance\\(< 15\\) ) were eliminated.'
p2573
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2574
(dp2575
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the basis for edit prediction.'
p2576
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2577
(dp2578
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As can be seen, most edits areminor, and with the threshold ratio of 0.8 we labeled about 15\\% of theedits as significant.'
p2579
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2580
(dp2581
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits todetermine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p2582
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2583
(dp2584
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggersedits in other paragraphs in the next revisions. This is shown inFigure~{[}fig:edits{]}, where each line represents a paragraph that isedited significantly at time 0 after not being significantly edited inrecent versions, further adjustments (as represented by downward spikes)are triggered in the near future. We evaluated the three inter-paragraphrelationships (proximity, edit history, and topic similarity) todetermine which paragraphs are more likely to require further editingafter a significant change occurs in the article.'
p2585
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2586
(dp2587
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checked whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the paragraphs continue to be edited together tenversions after the significant change, that is whether they changetogether (or remain unchanged together) more than half the time. This isa stronger indication than just undergoing at least one significantchange.'
p2588
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2589
(dp2590
g10
S'On average, 1.6 pairs of paragraphs related by edit history were foundper revision of the text. A pair related by topic similarity was onlyfound once every ten versions. Proximity relationships always exist ineach version, as most paragraphs have two neighbors.'
p2591
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2592
(dp2593
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. It is also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories. For this measure, therelationship of topic similarity still needs to be evaluated.'
p2594
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2595
(dp2596
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairsrelated by edit history and 63\\% of pairs related by topic. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions; thus, only 20\\%of the paragraphs that should have been labeled as related (based oninformation ten versions in the future) were missed.'
p2597
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2598
(dp2599
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improvethe collaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edit andfor predicting future edits, provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p2600
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2601
(dp2602
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur. We also plan to developadditional algorithms for summarizing changes and to investigate the useof algorithms that measure text coherence (e.g.,Textiling\\cite{hearst1994multi}) for alerting authors to portions of the textthat appear to lack coherence. Finally, we plan to explore alternativeways of presenting to authors the information chosen by the algorithmsas important for them to consider. For example, the system mighthighlight changes that it deems relevant or provide a list of them withlinks to the places they appear in the text.'
p2603
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p2604
sba(iversion
Version
p2605
(dp2606
g7
g8
(S'\x07\xdf\x01\x02\x160$\x06\xf1X'
tRp2607
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2608
sg12
(lp2609
(iversion
Paragraph
p2610
(dp2611
g10
S"Many documents (e.g., academic papers) are typically written by multiplecollaborators. While many existing tools support such collaborativeefforts (e.g., dropbox, google docs), these tools lack intelligentinformation sharing mechanisms. While capabilities such as ``trackchanges'' and ``diff'' visualize changes to authors, they do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktowards the development of a collaborative system for supportingmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits and predicting parts of the paper that arelikely to require changes as a result of previous edits. Preliminaryevaluation of the proposed methods shows promising results."
p2612
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2613
(dp2614
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceor relevance of changes to different authors and do not consider howedits might affect other parts of the document. Therefore, there iscurrently significant coordination overhead: authors need to frequentlyre-read the entire document or rely on communication from theirco-authors in order to keep track with the current state of the documentand ensure that their edits are mash with other edits."
p2615
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2616
(dp2617
g10
S'Because authors need to make sure their edits are coherent with thedocument as a whole, including sections written by others, they need toread the entire document frequently, or rely on updates from theirco-authors. Even when authors communicate with each other frequently,they can get lost in the volume of edits from other collaborators orbecome overwhelmed with too much information.'
p2618
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2619
(dp2620
g10
S'This paper presents our initial work towards the development of acollaborative system for assisting multi-author writing by drawingauthors attention to edits that are important and relevant for them, andpointing out other parts of the document that are likely to requireediting given changes they have just made.'
p2621
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2622
(dp2623
g10
S"The paper describes methods for tracking paragraphs as they are revised,for identifying paragraphs that have been significantly changed, and forpredicting which parts of the document are likely to change following aparticular edit. Systems with such capabilities have potential toimprove coherence and coordination while reducing authors' communicationburden. An empirical evaluation of the approach on a corpus of Wikipediaarticles shows promising initial results. Using these methods it ispossible to track paragraph across revisions, identify significantchanges, and predict the paragraphs that are likely to be editedfollowing a significant edit of a particular paragraph."
p2624
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2625
(dp2626
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorization of editsand interfaces for presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p2627
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2628
(dp2629
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our investigation of thelightweight use of NLP techniques and history tracking for providingthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion."
p2630
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2631
(dp2632
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,and 12 of the old version were deleted, while the others found clearmatches (e.g., paragraph 11 in the new version was mapped with paragraph9 in the old version).'
p2633
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2634
(dp2635
g10
S"\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach. Specifically, we use cosine similarity between wordvectors that represent the paragraphs, incorporating Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. If the cosine similaritybetween the new and old versions of a paragraph is below an empiricallydetermined threshold of 0.8, we consider the edit to be significant."
p2636
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2637
(dp2638
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p2639
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2640
(dp2641
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p2642
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2643
(dp2644
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p2645
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2646
(dp2647
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith high cosine similarity. For (2), we labeled pairs as related ifthey changed or remained unchanged together over half the time inprevious revisions.'
p2648
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2649
(dp2650
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p2651
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2652
(dp2653
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough information. To focus on revisions that contain some substantialchanges, the versions with simple typo fixes (Levenshtein distance\\(< 15\\) ) were eliminated.'
p2654
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2655
(dp2656
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the basis for edit prediction.'
p2657
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2658
(dp2659
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As can be seen, most edits areminor, and with the threshold ratio of 0.8 we labeled about 15\\% of theedits as significant.'
p2660
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2661
(dp2662
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits todetermine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p2663
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2664
(dp2665
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggersedits in other paragraphs in the next revisions. This is shown inFigure~{[}fig:edits{]}, where each line represents a paragraph that isedited significantly at time 0 after not being significantly edited inrecent versions, further adjustments (as represented by downward spikes)are triggered in the near future. We evaluated the three inter-paragraphrelationships (proximity, edit history, and topic similarity) todetermine which paragraphs are more likely to require further editingafter a significant change occurs in the article.'
p2666
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2667
(dp2668
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checked whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the paragraphs continue to be edited together tenversions after the significant change, that is whether they changetogether (or remain unchanged together) more than half the time. This isa stronger indication than just undergoing at least one significantchange.'
p2669
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2670
(dp2671
g10
S'On average, 1.6 pairs of paragraphs related by edit history were foundper revision of the text. A pair related by topic similarity was onlyfound once every ten versions. Proximity relationships always exist ineach version, as most paragraphs have two neighbors.'
p2672
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2673
(dp2674
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. It is also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories. For this measure, therelationship of topic similarity still needs to be evaluated.'
p2675
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2676
(dp2677
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairsrelated by edit history and 63\\% of pairs related by topic. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions; That is, only20\\% of the paragraphs that should have been labeled as related (basedon information ten versions in the future) were not included in the setof related paragraphs predicted by edit history and topic similarity.'
p2678
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2679
(dp2680
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improvethe collaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edit andfor predicting future edits, provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p2681
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2682
(dp2683
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur. We also plan to developadditional algorithms for summarizing changes and to investigate the useof algorithms that measure text coherence (e.g.,Textiling\\cite{hearst1994multi}) for alerting authors to portions of the textthat appear to lack coherence. Finally, we plan to explore alternativeways of presenting to authors the information chosen by the algorithmsas important for them to consider. For example, the system mighthighlight changes that it deems relevant or provide a list of them withlinks to the places they appear in the text.'
p2684
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p2685
sba(iversion
Version
p2686
(dp2687
g7
g8
(S'\x07\xde\x0c\x0e\x10\x18\x13\x07\xa5\x08'
tRp2688
sg10
S". See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.\n\n\\section{Introduction}\\label{introduction}\n\nMaybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikis\n\nnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision Activity\n\nWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nThe system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.\n\nINSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.\n\nThis method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches.\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in figure\n{[}X{]}.\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p2689
sg12
(lp2690
(iversion
Paragraph
p2691
(dp2692
g10
S'. See: \\url{http://www.acm.org/about/class/1998/} for help using the ACMClassification system.'
p2693
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2694
(dp2695
g10
S'\\section{Introduction}\\label{introduction}Maybe one paragraph (previous years talk about motivation in similarwork in intro and have one-two paragraphs in a background/related worksection) about how previous work tried to come up with frameworks tosupport writers and tried to investigate the writers problems. Theydescribe the motivation and the need for such a system: * TrackingChanges in Collaborative Writing: Edits, Visibility and GroupMaintenance Old examples: * Quilt: A collaborative tool for cooperativewriting - 1988 * User-centred iterative design of collaborative software-1993 * what do co-authors use? * They try to find relevant changes: *Flexible Diff-ing in a collaborative writing system * What did they do?'
p2696
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2697
(dp2698
g10
S'Deriving High-Level edit histories in Wikisnewer examples also try to classify changes: * How a Structured DocumentModel Can Support Awareness in Collaborative Authoring * A framework forasynchronous change awareness in collaborative documents and workspaces* some try to find conflicts (different definition of conflict though):* Enabling truly collaborative writing on a computer * and some try tofind an explicit structur in texts: * A narrative-based collaborativewriting tool for constructing coherent technical documents * trying topredict: * WikiChanges - Exposing Wikipedia Revision ActivityWhen authors collaborate to write a paper, they need to communicateconstantly to ensure that they are all on the same page. Because theauthors need to make sure that their edits are coherent with the rest ofthe paper, including sections written by others, they need to read theentire paper frequently, or rely on updates communicated by theircoauthors. Even with constant communication, authors can get lost in thevolume of edits from other collaborators. Therefore, an assistive systemwith a summary of the significant changes contributed by other authorswould be helpful. We hypothesize that when an author makes a significantedit to a paragraph, it eventually triggers a series of adjustments inrelated paragraphs. Before these adjustments occur, semantic conflictsmight occur between authors. We wanted a collaborative writing system toalso predict when and where these conflicts may occur, in order to alerteven more specifically.'
p2699
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2700
(dp2701
g10
S'The system is composed of the following three components: (1) trackingparagraphs; (2) identifying significant changes to paragraphs, and (3)predicting future changes to the article. Tracking paragraphs throughpaper revisions is a core capability required for monitoring changes andpredicting them. The identification of significant content changes isimportant for a system to understand how important different changes areand whether collaborating authors should be notified. Predicting futurechanges enables the system to not only report to authors about changesthat have already been made, but also draw their attention to otherparts of the document that might require changes as a result of thechanges made.'
p2702
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2703
(dp2704
g10
S"INSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changesin related paragraphs eighty percent of the time{]}, but incollaborative writing, these resulting edits do not occurinstantaneously. Instead of waiting for other authors to discover theinconsistency caused by one author's edit, we want an assistive systemthat can alert relevant authors about paragraphs that might need anadditional look as a result of an edit."
p2705
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2706
(dp2707
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a widevariety of Wikipedia articles that undergo intense editing processes.'
p2708
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2709
(dp2710
g10
S'Wikipedia is a unique source because it presents extensive data forcollaborative writing. The findings use the complete revision revisionhistory of 41 different articles chosen from a diverse set of topics,from famous people and places to mathematical algorithms to novels. Therevision histories were downloaded as raw xml data. We removedWikipedia-specific tags that indicate formatting and other irrelevantdata, and eliminated versions of the articles under 150 characters, asthey did not contain enough information. To focus only on revisions withconsequential changes, the versions with simple typo fixes{[}1{]} wereeliminated as well. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs. Wikipediadata affords results applicable to other collaborative writing spaces,because although the average article has over 400 contributing authors,most of these authors make a one-time change. In fact, on average, 15authors make 80\\% of the edits to an article. This enables theconsideration of interactions between authors, which is crucial forlearning about collaborative behavior.'
p2711
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2712
(dp2713
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein editratio measure, which is defined in equation 1.'
p2714
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2715
(dp2716
g10
S'This method differed from previous attempts in the sense that it tracksparagraphs as a whole instead of just the longest common subsequence asused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.'
p2717
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2718
(dp2719
g10
S'A Levenshtein ratio close to one between two paragraphs indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision, we computed the Levenshtein ratio betweeneach paragraph in the old version and each paragraph in the new version.'
p2720
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2721
(dp2722
g10
S"Two paragraphs are mapped across the revision if they each had thehighest Levenshtein ratio for the other. If a paragraph in the newversion had no ``matches'', meaning that none of its ratios were above athreshold of 0.4, this paragraph was new. If a paragraph in the oldversion had no ``matches'', then it was deleted in the revision. Theimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of theold version were deleted, while the others found clear matches."
p2723
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2724
(dp2725
g10
S"\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph'stopic and content. For this calculation, the Levenshtein ratio does notprovide the right kind of information. For example, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple key words will slightly lower the Levenshtein ratio,but could drastically affect the content."
p2726
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2727
(dp2728
g10
S"As shown in figure 1, which shows the distribution of the differencesbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshteinand LSI ratios demonstrate very different statistics. {[}INSERTFIGURE{]}Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Latent Semantic Indexing is a form oftopic modeling that calculates the topic similarity between two texts."
p2729
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2730
(dp2731
g10
S"Its strengths lie in accounting for synonyms and not penalizing fortypographical errors. The process begins by composing a corpus for eachWikipedia article from all of the documents (paragraphs of the versionsof the article). It analyzes tokens (a specific instance of a word),eliminating those that only occur once, as well as stopword tokens, suchas `the' or `and'. It then creates a TF-IDF matrix, which assigns aweight to every token in each document, which indicates the importanceof that token for this document. This weight increases proportionally tothe frequency of the word in the document, but accounts for thefrequency of the word in the corpus, such that the frequent occurrenceof a usually uncommon word is given a larger weight to signify thisimportance."
p2732
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2733
(dp2734
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p2735
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2736
(dp2737
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p2738
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2739
(dp2740
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p2741
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2742
(dp2743
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p2744
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2745
(dp2746
g10
S'Therefore, in order to predict future conflicts, an assistive systemneeds to detect significant changes and then determine consequentlywhich paragraphs were most likely to change.'
p2747
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2748
(dp2749
g10
S'We looked at three possible types of inter-paragraph relationships.'
p2750
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2751
(dp2752
g10
S'Paragraphs could be related by physical proximity: perhaps theneighboring paragraphs would require adjustments, as they are likelypart of the same section. Paragraphs could also be related by topic. Forexample, in an academic paper, the discussion section and the conclusionshould present similar themes. If one changes, the other may need to beedited to reflect this change. For each significant change, we used theexisting LSI Topic Model to determine which paragraphs discussed similartopics. Lastly, paragraphs could be related because of similar edithistories. For each significant change, we evaluated the edit history ofthis paragraph with every other paragraph in the article. We labeledpairs as related if they changed or remained unchanged together overhalf the time. With a higher threshold, the sample size decreases, butwith a lower threshold, the results become less predictive of asignificant change prompting further edits. This threshold strikes abalance between these two outcomes.'
p2753
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2754
(dp2755
g10
S"To evaluate these both of these suspected relationships, we looked atthe related paragraphs' edit patterns in the ten versions following thesignificant change. If the related paragraphs changed together over halfthe time, the paragraphs with this relationship proved to be related inthe future, verifying the relationship at the time of the significantchange."
p2756
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2757
(dp2758
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutiveversions of a paper, we calculated the number of versions from theparagraphs' inception to its demise. On average, paragraphs lasted 83article revisions."
p2759
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2760
(dp2761
g10
S'\\subsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown in figure{[}X{]}.'
p2762
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2763
(dp2764
g10
S'We evaluated a random sample of these edits to determine that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p2765
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2766
(dp2767
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p2768
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2769
(dp2770
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in figure {[}X{]}, when a paragraph isedited for the first time in a while, further adjustments are triggeredin the near future.'
p2771
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2772
(dp2773
g10
S'Caption: After a significant change at version 0, consequent edits aremore frequent.'
p2774
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2775
(dp2776
g10
S'We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p2777
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2778
(dp2779
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in table {[}X{]}. They are also significantly more predictive thanrandom sample controls. For controls, we compare with the originalparagraph as well as a random sample of any ten consecutive versionswithin Wikipedia article histories.'
p2780
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2781
(dp2782
g10
S'Relationship or Control Percentage of times that paragraph experiencedat least one significant change Edit History 81\\% Topic Similarity .'
p2783
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2784
(dp2785
g10
S'Physical Proximity 24\\% Paragraph with original significant change 40\\%Random Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80Relationship Number Found Successfully Linked Ratio of SuccessfullyLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,68571\\%Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p2786
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2787
(dp2788
g10
S'The correlation coefficient was 0.99 for all numbers.'
p2789
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2790
(dp2791
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p2792
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2793
(dp2794
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p2795
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2796
(dp2797
g10
S'We imagine a couple other helpful components for an assistive systemthat our methods could provide the foundation for. Using text summaryalgorithms, the system could provide a succinct textual summary ofsignificant changes already detected. The system could also \\ldots{}.'
p2798
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2799
(dp2800
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determiningwhether a paragraph will change together in the future. Consequently, weassert that if significant edit occurs, related paragraphs should alsobe edited. A proposed assistive system will alert the relevant authorsof related paragraphs if this resulting edit does not occur. Bydetecting relationships between paragraphs in a multi-authored paper,our system can predict and alert appropriate authors if a significantchange has the potential to create a semantic conflict within the paper.'
p2801
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p2802
sba(iversion
Version
p2803
(dp2804
g7
g8
(S'\x07\xdf\x01\x03\x04/\x1f\x08\x1e '
tRp2805
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2806
sg12
(lp2807
(iversion
Paragraph
p2808
(dp2809
g10
S"Many documents (e.g., academic papers) are typically written by multiplecollaborators. While many existing tools support such collaborativeefforts (e.g., dropbox, google docs), these tools lack intelligentinformation sharing mechanisms. While capabilities such as ``trackchanges'' and ``diff'' visualize changes to authors, they do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktowards the development of a collaborative system for supportingmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits and predicting parts of the paper that arelikely to require changes as a result of previous edits. Preliminaryevaluation of the proposed methods shows promising results."
p2810
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2811
(dp2812
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceor relevance of changes to different authors and do not consider howedits might affect other parts of the document. Therefore, there iscurrently significant coordination overhead: authors need to frequentlyre-read the entire document or rely on communication from theirco-authors in order to keep track with the current state of the documentand ensure that their edits are mash with other edits."
p2813
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2814
(dp2815
g10
S'Because authors need to make sure their edits are coherent with thedocument as a whole, including sections written by others, they need toread the entire document frequently, or rely on updates from theirco-authors. Even when authors communicate with each other frequently,they can get lost in the volume of edits from other collaborators orbecome overwhelmed with too much information.'
p2816
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2817
(dp2818
g10
S'This paper presents our initial work towards the development of acollaborative system for assisting multi-author writing by drawingauthors attention to edits that are important and relevant for them, andpointing out other parts of the document that are likely to requireediting given changes they have just made.'
p2819
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2820
(dp2821
g10
S"The paper describes methods for tracking paragraphs as they are revised,for identifying paragraphs that have been significantly changed, and forpredicting which parts of the document are likely to change following aparticular edit. Systems with such capabilities have potential toimprove coherence and coordination while reducing authors' communicationburden. An empirical evaluation of the approach on a corpus of Wikipediaarticles shows promising initial results. Using these methods it ispossible to track paragraph across revisions, identify significantchanges, and predict the paragraphs that are likely to be editedfollowing a significant edit of a particular paragraph."
p2822
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2823
(dp2824
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorization of editsand interfaces for presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p2825
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2826
(dp2827
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our investigation of thelightweight use of NLP techniques and history tracking for providingthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion."
p2828
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2829
(dp2830
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,and 12 of the old version were deleted, while the others found clearmatches (e.g., paragraph 11 in the new version was mapped with paragraph9 in the old version).'
p2831
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2832
(dp2833
g10
S"\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach. Specifically, we use cosine similarity between wordvectors that represent the paragraphs, incorporating Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. If the cosine similaritybetween the new and old versions of a paragraph is below an empiricallydetermined threshold of 0.8, we consider the edit to be significant."
p2834
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2835
(dp2836
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p2837
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2838
(dp2839
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p2840
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2841
(dp2842
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p2843
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2844
(dp2845
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith high cosine similarity. For (2), we labeled pairs as related ifthey changed or remained unchanged together over half the time inprevious revisions.'
p2846
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2847
(dp2848
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p2849
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2850
(dp2851
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough information. To focus on revisions that contain some substantialchanges, the versions with simple typo fixes (Levenshtein distance\\(< 15\\) ) were eliminated.'
p2852
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2853
(dp2854
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the basis for edit prediction.'
p2855
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2856
(dp2857
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As can be seen, most edits areminor, and with the threshold ratio of 0.8 we labeled about 15\\% of theedits as significant.'
p2858
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2859
(dp2860
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits todetermine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p2861
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2862
(dp2863
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggersedits in other paragraphs in the next revisions. This is shown inFigure~{[}fig:edits{]}, where each line represents a paragraph that isedited significantly at time 0 after not being significantly edited inrecent versions, further adjustments (as represented by downward spikes)are triggered in the near future. We evaluated the three inter-paragraphrelationships (proximity, edit history, and topic similarity) todetermine which paragraphs are more likely to require further editingafter a significant change occurs in the article.'
p2864
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2865
(dp2866
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checked whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the paragraphs continue to be edited together tenversions after the significant change, that is whether they changetogether (or remain unchanged together) more than half the time. This isa stronger indication than just undergoing at least one significantchange.'
p2867
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2868
(dp2869
g10
S'On average, 1.6 pairs of paragraphs related by edit history were foundper revision of the text. A pair related by topic similarity was onlyfound once every ten versions. Proximity relationships always exist ineach version, as most paragraphs have two neighbors.'
p2870
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2871
(dp2872
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. It is also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories. For this measure, therelationship of topic similarity still needs to be evaluated.'
p2873
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2874
(dp2875
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairsrelated by edit history and 63\\% of pairs related by topic. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions; That is, only20\\% of the paragraphs that should have been labeled as related (basedon information ten versions in the future) were not included in the setof related paragraphs predicted by edit history and topic similarity.'
p2876
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2877
(dp2878
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p2879
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2880
(dp2881
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur. We also plan to developadditional algorithms for summarizing changes and to investigate the useof algorithms that measure text coherence (e.g.,Textiling\\cite{hearst1994multi}) for alerting authors to portions of the textthat appear to lack coherence. Finally, we plan to explore alternativeways of presenting to authors the information chosen by the algorithmsas important for them to consider. For example, the system mighthighlight changes that it deems relevant or provide a list of them withlinks to the places they appear in the text.'
p2882
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p2883
sba(iversion
Version
p2884
(dp2885
g7
g8
(S'\x07\xdf\x01\x03\x10\x189\x07GH'
tRp2886
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits, and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2887
sg12
(lp2888
(iversion
Paragraph
p2889
(dp2890
g10
S"Many documents (e.g., academic papers) are typically written by multiplecollaborators. While many existing tools support such collaborativeefforts (e.g., dropbox, google docs), these tools lack intelligentinformation sharing mechanisms. While capabilities such as ``trackchanges'' and ``diff'' visualize changes to authors, they do notdistinguish between minor and major edits, and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of the proposed methods shows promising results."
p2891
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2892
(dp2893
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceof changes to different authors and do not consider how edits mightaffect other parts of the document. Therefore, there is significantcoordination overhead: authors need to re-read the entire documentfrequently or rely on communication from their co-authors in order tokeep track of the current state of the document and ensure that theiredits are consistent with other edits."
p2894
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2895
(dp2896
g10
S"This paper presents our initial work toward the development of acollaborative system that assists multi-author writing by drawingauthors' attention to edits that are important and relevant for them,and by pointing out other parts of the document that are likely torequire editing given the changes they have just made."
p2897
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2898
(dp2899
g10
S"The paper describes methods for tracking paragraphs as they are revised,for identifying paragraphs that have been significantly changed, and forpredicting which parts of the document are likely to change following aparticular edit. Systems with such capabilities have the potential toimprove coherence and coordination while reducing the authors'communication burden. An empirical evaluation of the approach on acorpus of Wikipedia articles shows promising initial results. Usingthese methods, it is possible to track paragraphs across revisions,identify significant changes, and predict paragraphs likely to be editedfollowing a significant edit of a particular paragraph."
p2900
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2901
(dp2902
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing of editsand presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p2903
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2904
(dp2905
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our lightweight use of NLPtechniques and history tracking, which provide the basis for theseimportant capabilities."
p2906
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2907
(dp2908
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion.'
p2909
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2910
(dp2911
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,and 12 of the old version were deleted, while the others found clearmatches (e.g., paragraph 11 in the new version was mapped with paragraph9 in the old version).'
p2912
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2913
(dp2914
g10
S"\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach. Specifically, we use cosine similarity between wordvectors that represent the paragraphs, incorporating Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonymsand does not penalize for typographical errors. If the cosine similaritybetween the new and old versions of a paragraph is below an empiricallydetermined threshold of 0.8, we consider the edit to be significant."
p2915
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2916
(dp2917
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p2918
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2919
(dp2920
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p2921
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2922
(dp2923
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p2924
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2925
(dp2926
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith high cosine similarity. For (2), we labeled pairs as related ifthey changed or remained unchanged together over half the time inprevious revisions.'
p2927
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2928
(dp2929
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p2930
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2931
(dp2932
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough information. To focus on revisions that contain some substantialchanges, the versions with simple typo fixes (Levenshtein distance\\(< 15\\) ) were eliminated.'
p2933
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2934
(dp2935
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the basis for edit prediction.'
p2936
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2937
(dp2938
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As can be seen, most edits areminor, and with the threshold ratio of 0.8 we labeled about 15\\% of theedits as significant.'
p2939
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2940
(dp2941
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits todetermine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p2942
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2943
(dp2944
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggersedits in other paragraphs in the next revisions. This is shown inFigure~{[}fig:edits{]}, where each line represents a paragraph that isedited significantly at time 0 after not being significantly edited inrecent versions, further adjustments (as represented by downward spikes)are triggered in the near future. We evaluated the three inter-paragraphrelationships (proximity, edit history, and topic similarity) todetermine which paragraphs are more likely to require further editingafter a significant change occurs in the article.'
p2945
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2946
(dp2947
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checked whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the paragraphs continue to be edited together tenversions after the significant change, that is whether they changetogether (or remain unchanged together) more than half the time. This isa stronger indication than just undergoing at least one significantchange.'
p2948
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2949
(dp2950
g10
S'On average, 1.6 pairs of paragraphs related by edit history were foundper revision of the text. A pair related by topic similarity was onlyfound once every ten versions. Proximity relationships always exist ineach version, as most paragraphs have two neighbors.'
p2951
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2952
(dp2953
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. It is also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories. For this measure, therelationship of topic similarity still needs to be evaluated.'
p2954
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2955
(dp2956
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairsrelated by edit history and 63\\% of pairs related by topic. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions; That is, only20\\% of the paragraphs that should have been labeled as related (basedon information ten versions in the future) were not included in the setof related paragraphs predicted by edit history and topic similarity.'
p2957
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2958
(dp2959
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p2960
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2961
(dp2962
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur. We also plan to developadditional algorithms for summarizing changes and to investigate the useof algorithms that measure text coherence (e.g.,Textiling\\cite{hearst1994multi}) for alerting authors to portions of the textthat appear to lack coherence. Finally, we plan to explore alternativeways of presenting to authors the information chosen by the algorithmsas important for them to consider. For example, the system mighthighlight changes that it deems relevant or provide a list of them withlinks to the places they appear in the text.'
p2963
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p2964
sba(iversion
Version
p2965
(dp2966
g7
g8
(S"\x07\xdf\x01\x03\x10'\x03\x00\xe2\x90"
tRp2967
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits, and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2968
sg12
(lp2969
(iversion
Paragraph
p2970
(dp2971
g10
S"Many documents (e.g., academic papers) are typically written by multiplecollaborators. While many existing tools support such collaborativeefforts (e.g., dropbox, google docs), these tools lack intelligentinformation sharing mechanisms. While capabilities such as ``trackchanges'' and ``diff'' visualize changes to authors, they do notdistinguish between minor and major edits, and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of the proposed methods shows promising results."
p2972
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2973
(dp2974
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceof changes to different authors and do not consider how edits mightaffect other parts of the document. Therefore, there is significantcoordination overhead: authors need to re-read the entire documentfrequently or rely on communication from their co-authors in order tokeep track of the current state of the document and ensure that theiredits are consistent with other edits."
p2975
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2976
(dp2977
g10
S"This paper presents our initial work toward the development of acollaborative system that assists multi-author writing by drawingauthors' attention to edits that are important and relevant for them,and by pointing out other parts of the document that are likely torequire editing given the changes they have just made."
p2978
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2979
(dp2980
g10
S"The paper describes methods for tracking paragraphs as they are revised,for identifying paragraphs that have been significantly changed, and forpredicting which parts of the document are likely to change following aparticular edit. Systems with such capabilities have the potential toimprove coherence and coordination while reducing the authors'communication burden. An empirical evaluation of the approach on acorpus of Wikipedia articles shows promising initial results. Usingthese methods, it is possible to track paragraphs across revisions,identify significant changes, and predict paragraphs likely to be editedfollowing a significant edit of a particular paragraph."
p2981
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2982
(dp2983
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing of editsand presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p2984
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2985
(dp2986
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our lightweight use of NLPtechniques and history tracking, which provide the basis for theseimportant capabilities."
p2987
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2988
(dp2989
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion.'
p2990
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2991
(dp2992
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p2993
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2994
(dp2995
g10
S"\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use topicmodeling approach, specifically, Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI), which accounts forsynonyms and does not penalize for typographical errors. This approachuses the cosine similarity between word vectors that represent theparagraphs; if the cosine similarity between the new and old versions ofa paragraph is below an empirically determined threshold of 0.8, weconsider the edit significant."
p2996
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2997
(dp2998
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p2999
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3000
(dp3001
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3002
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3003
(dp3004
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p3005
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3006
(dp3007
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},i.e., paragraphs that tended to be edited together in previousrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with hightopic cosine similarity. For (2), we labeled pairs as related if theychanged or remained unchanged together over half the time in theprevious ten revisions. For (3), we labeled pairs as related if theircosine similarity was above an empirically determined threshold of 0.4.'
p3008
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3009
(dp3010
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p3011
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3012
(dp3013
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough information. To focus on revisions that contain some substantialchanges, the versions with simple typo fixes (Levenshtein distance\\(< 15\\) ) were eliminated.'
p3014
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3015
(dp3016
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Ourmain focus was the prediction of future edits, but we also conducted amanual evaluation of paragraph mapping and significant change detection,which formed the basis for edit prediction.'
p3017
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3018
(dp3019
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As can be seen, most edits areminor, and with the threshold ratio of 0.8 we labeled about 15\\% of theedits as significant.'
p3020
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3021
(dp3022
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits todetermine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p3023
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3024
(dp3025
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggersedits in other paragraphs in the next revisions. This is shown inFigure~{[}fig:edits{]}, where each line represents a paragraph that isedited significantly at time 0 after not being significantly edited inrecent versions, further adjustments (as represented by downward spikes)are triggered in the near future. We evaluated the three inter-paragraphrelationships (proximity, edit history, and topic similarity) todetermine which paragraphs are more likely to require further editingafter a significant change occurs in the article.'
p3026
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3027
(dp3028
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checked whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the paragraphs continue to be edited together tenversions after the significant change, that is whether they changetogether (or remain unchanged together) more than half the time. This isa stronger indication than just undergoing at least one significantchange.'
p3029
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3030
(dp3031
g10
S'On average, 1.6 pairs of paragraphs related by edit history were foundper revision of the text. A pair related by topic similarity was onlyfound once every ten versions. Proximity relationships always exist ineach version, as most paragraphs have two neighbors.'
p3032
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3033
(dp3034
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. It is also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories. For this measure, therelationship of topic similarity still needs to be evaluated.'
p3035
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3036
(dp3037
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairsrelated by edit history and 63\\% of pairs related by topic. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions; That is, only20\\% of the paragraphs that should have been labeled as related (basedon information ten versions in the future) were not included in the setof related paragraphs predicted by edit history and topic similarity.'
p3038
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3039
(dp3040
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p3041
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3042
(dp3043
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur. We also plan to developadditional algorithms for summarizing changes and to investigate the useof algorithms that measure text coherence (e.g.,Textiling\\cite{hearst1994multi}) for alerting authors to portions of the textthat appear to lack coherence. Finally, we plan to explore alternativeways of presenting to authors the information chosen by the algorithmsas important for them to consider. For example, the system mighthighlight changes that it deems relevant or provide a list of them withlinks to the places they appear in the text.'
p3044
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p3045
sba(iversion
Version
p3046
(dp3047
g7
g8
(S'\x07\xdf\x01\x03\x102\t\t#\xd8'
tRp3048
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits, and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p3049
sg12
(lp3050
(iversion
Paragraph
p3051
(dp3052
g10
S"Many documents (e.g., academic papers) are typically written by multiplecollaborators. While many existing tools support such collaborativeefforts (e.g., dropbox, google docs), these tools lack intelligentinformation sharing mechanisms. While capabilities such as ``trackchanges'' and ``diff'' visualize changes to authors, they do notdistinguish between minor and major edits, and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of the proposed methods shows promising results."
p3053
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3054
(dp3055
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceof changes to different authors and do not consider how edits mightaffect other parts of the document. Therefore, there is significantcoordination overhead: authors need to re-read the entire documentfrequently or rely on communication from their co-authors in order tokeep track of the current state of the document and ensure that theiredits are consistent with other edits."
p3056
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3057
(dp3058
g10
S"This paper presents our initial work toward the development of acollaborative system that assists multi-author writing by drawingauthors' attention to edits that are important and relevant for them,and by pointing out other parts of the document that are likely torequire editing given the changes they have just made."
p3059
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3060
(dp3061
g10
S"The paper describes methods for tracking paragraphs as they are revised,for identifying paragraphs that have been significantly changed, and forpredicting which parts of the document are likely to change following aparticular edit. Systems with such capabilities have the potential toimprove coherence and coordination while reducing the authors'communication burden. An empirical evaluation of the approach on acorpus of Wikipedia articles shows promising initial results. Usingthese methods, it is possible to track paragraphs across revisions,identify significant changes, and predict paragraphs likely to be editedfollowing a significant edit of a particular paragraph."
p3062
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3063
(dp3064
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing of editsand presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p3065
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3066
(dp3067
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our lightweight use of NLPtechniques and history tracking, which provide the basis for theseimportant capabilities."
p3068
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3069
(dp3070
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion.'
p3071
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3072
(dp3073
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3074
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3075
(dp3076
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use topicmodeling approach, specifically, Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI), which accounts forsynonyms and does not penalize for typographical errors. This approachuses the cosine similarity between word vectors that represent theparagraphs; if the cosine similarity between the new and old versions ofa paragraph is below an empirically determined threshold of 0.8, weconsider the edit significant."
p3077
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3078
(dp3079
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p3080
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3081
(dp3082
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3083
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3084
(dp3085
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p3086
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3087
(dp3088
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},i.e., paragraphs that tended to be edited together in previousrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with hightopic cosine similarity. For (2), we labeled pairs as related if theychanged or remained unchanged together over half the time in theprevious ten revisions. For (3), we labeled pairs as related if theircosine similarity was above an empirically determined threshold of 0.4.'
p3089
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3090
(dp3091
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p3092
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3093
(dp3094
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p3095
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3096
(dp3097
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Wefocused mostly on the prediction of future edits, but we also conducteda manual evaluation of paragraph mapping and significant changedetection, which formed the basis for edit prediction.'
p3098
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3099
(dp3100
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As can be seen, most edits areminor, and with the threshold ratio of 0.8 we labeled about 15\\% of theedits as significant.'
p3101
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3102
(dp3103
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits todetermine 1) that paragraphs were correctly mapped and 2) that thismethod successfully classifies edits. We provide an example of asignificant edit in Figure~{[}fig:pars{]}. While these paragraphs areclearly the same, the edit is significant because it contributes contentand changes the tone of the paragraph.'
p3104
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3105
(dp3106
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggersedits in other paragraphs in the next revisions. This is shown inFigure~{[}fig:edits{]}, where each line represents a paragraph that isedited significantly at time 0 after not being significantly edited inrecent versions, further adjustments (as represented by downward spikes)are triggered in the near future. We evaluated the three inter-paragraphrelationships (proximity, edit history, and topic similarity) todetermine which paragraphs are more likely to require further editingafter a significant change occurs in the article.'
p3107
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3108
(dp3109
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checked whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the paragraphs continue to be edited together tenversions after the significant change, that is whether they changetogether (or remain unchanged together) more than half the time. This isa stronger indication than just undergoing at least one significantchange.'
p3110
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3111
(dp3112
g10
S'On average, 1.6 pairs of paragraphs related by edit history were foundper revision of the text. A pair related by topic similarity was onlyfound once every ten versions. Proximity relationships always exist ineach version, as most paragraphs have two neighbors.'
p3113
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3114
(dp3115
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. It is also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories. For this measure, therelationship of topic similarity still needs to be evaluated.'
p3116
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3117
(dp3118
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times there exists at least one significantchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairsrelated by edit history and 63\\% of pairs related by topic. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions; That is, only20\\% of the paragraphs that should have been labeled as related (basedon information ten versions in the future) were not included in the setof related paragraphs predicted by edit history and topic similarity.'
p3119
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3120
(dp3121
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p3122
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3123
(dp3124
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on their context ofediting and history of revisions. For example, the paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which can be used to determine whoto alert when significant edits occur. We also plan to developadditional algorithms for summarizing changes and to investigate the useof algorithms that measure text coherence (e.g.,Textiling\\cite{hearst1994multi}) for alerting authors to portions of the textthat appear to lack coherence. Finally, we plan to explore alternativeways of presenting to authors the information chosen by the algorithmsas important for them to consider. For example, the system mighthighlight changes that it deems relevant or provide a list of them withlinks to the places they appear in the text.'
p3125
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p3126
sba(iversion
Version
p3127
(dp3128
g7
g8
(S"\x07\xdf\x01\x03\x11\x10'\nw\xb0"
tRp3129
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While many existing tools support such collaborative efforts\n(e.g., dropbox, google docs), these tools lack intelligent information\nsharing mechanisms. While capabilities such as ``track changes'' and\n``diff'' visualize changes to authors, they do not distinguish between\nminor and major edits, and do not consider the possible effects of edits\non other parts of the document. Drawing collaborators' attention to\nspecific edits and describing them remains the responsibility of\nauthors. This paper presents our initial work toward the development of\na collaborative system that supports multi-author writing. We describe\nmethods for tracking paragraphs, identifying significant edits, and\npredicting parts of the paper that are likely to require changes as a\nresult of previous edits. Preliminary evaluation of the proposed methods\nshows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made. The paper\ndescribes methods for tracking paragraphs as they are revised,\nidentifying paragraphs that have been significantly changed, and\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future(as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they change\ntogether (or remain unchanged together) more than half the time. This\nsecond measure is a stronger indication than a paragraph undergoing just\none significant change.\n\nThe frequency of the relationship occurrence was variable. On average,\n1.6 pairs of paragraphs related by edit history were found per revision\nof the text. A pair related by topic similarity was only found once\nevery ten versions. Proximity relationships always exist in each\nversion, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than controls. For these controls, we compare with the\noriginal paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions. That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) and were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alerting authors to portions of the text that could be\nimproved. Finally, we plan to explore alternative ways of presenting the\ninformation chosen by the algorithms as important for authors to\nconsider. For example, the system might highlight changes that it deems\nrelevant or provide a list of them with links to the places they appear\nin the text.\n"
p3130
sg12
(lp3131
(iversion
Paragraph
p3132
(dp3133
g10
S"Many documents (e.g., academic papers) are typically written by multipleauthors. While many existing tools support such collaborative efforts(e.g., dropbox, google docs), these tools lack intelligent informationsharing mechanisms. While capabilities such as ``track changes'' and``diff'' visualize changes to authors, they do not distinguish betweenminor and major edits, and do not consider the possible effects of editson other parts of the document. Drawing collaborators' attention tospecific edits and describing them remains the responsibility ofauthors. This paper presents our initial work toward the development ofa collaborative system that supports multi-author writing. We describemethods for tracking paragraphs, identifying significant edits, andpredicting parts of the paper that are likely to require changes as aresult of previous edits. Preliminary evaluation of the proposed methodsshows promising results."
p3134
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3135
(dp3136
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'' and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceof changes to different authors and do not consider how edits mightaffect other parts of the document. Therefore, there is significantcoordination overhead: authors need to re-read the entire documentfrequently or rely on communication from their co-authors in order tokeep track of the current state of the document and ensure that theiredits are consistent with other edits."
p3137
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3138
(dp3139
g10
S"This paper presents our initial work toward the development of acollaborative system that assists multi-author writing by drawingauthors' attention to edits that are important and relevant for them,and by pointing out other parts of the document that are likely torequire editing given the changes they have just made. The paperdescribes methods for tracking paragraphs as they are revised,identifying paragraphs that have been significantly changed, andpredicting which parts of the document are likely to change following aparticular edit. Systems with such capabilities have the potential toimprove coherence and coordination while reducing the authors'communication burden. An empirical evaluation of the approach on acorpus of Wikipedia articles shows promising initial results. Usingthese methods, it is possible to track paragraphs across revisions,identify significant changes, and predict paragraphs likely to be editedfollowing a significant edit of a particular paragraph."
p3140
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3141
(dp3142
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing of editsand presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant edits and furthermore predict futureedits, without requiring authors to specify explicitly what changes areof interest to them. These capabilities go beyond prior approaches forsupporting change awareness in that they can support authors not only infinding the changes that have been made, but also in drawing theirattention to parts of the document that are likely to require edits as aresult of those changes.'
p3143
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3144
(dp3145
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our lightweight use of NLPtechniques and history tracking, which provide the basis for theseimportant capabilities."
p3146
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3147
(dp3148
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion.'
p3149
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3150
(dp3151
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3152
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3153
(dp3154
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use topicmodeling approach, specifically, Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI), which accounts forsynonyms and does not penalize for typographical errors. This approachuses the cosine similarity between word vectors that represent theparagraphs; if the cosine similarity between the new and old versions ofa paragraph is below an empirically determined threshold of 0.8, weconsider the edit significant."
p3155
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3156
(dp3157
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p3158
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3159
(dp3160
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3161
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3162
(dp3163
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p3164
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3165
(dp3166
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},i.e., paragraphs that tended to be edited together in previousrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with hightopic cosine similarity. For (2), we labeled pairs as related if theychanged or remained unchanged together over half the time in theprevious ten revisions. For (3), we labeled pairs as related if theircosine similarity was above an empirically determined threshold of 0.4.'
p3167
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3168
(dp3169
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p3170
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3171
(dp3172
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p3173
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3174
(dp3175
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Wefocused mostly on the prediction of future edits, but we also conducteda manual evaluation of paragraph mapping and significant changedetection, which form the basis for edit prediction.'
p3176
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3177
(dp3178
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p3179
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3180
(dp3181
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits toensure that 1) paragraphs were correctly mapped and 2) this methodsuccessfully classifies edits as significant or insignificant. Weprovide an example of a significant edit in Figure~{[}fig:pars{]}. Whilethese are clearly two versions of the same paragraph, the edit issignificant because it contributes content and alters the tone of thetext.'
p3182
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3183
(dp3184
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future(as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p3185
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3186
(dp3187
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they changetogether (or remain unchanged together) more than half the time. Thissecond measure is a stronger indication than a paragraph undergoing justone significant change.'
p3188
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3189
(dp3190
g10
S'The frequency of the relationship occurrence was variable. On average,1.6 pairs of paragraphs related by edit history were found per revisionof the text. A pair related by topic similarity was only found onceevery ten versions. Proximity relationships always exist in eachversion, as most paragraphs have two neighbors.'
p3191
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3192
(dp3193
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. It is also significantly morepredictive than controls. For these controls, we compare with theoriginal paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories. For this measure, therelationship of topic similarity still needs to be evaluated.'
p3194
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3195
(dp3196
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairsrelated by edit history and 63\\% of pairs related by topic. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions. That is, only20\\% of the paragraphs that should have been labeled as related (basedon information ten versions in the future) and were not included in theset of related paragraphs predicted by edit history and topicsimilarity.'
p3197
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3198
(dp3199
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p3200
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3201
(dp3202
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alerting authors to portions of the text that could beimproved. Finally, we plan to explore alternative ways of presenting theinformation chosen by the algorithms as important for authors toconsider. For example, the system might highlight changes that it deemsrelevant or provide a list of them with links to the places they appearin the text.'
p3203
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p3204
sba(iversion
Version
p3205
(dp3206
g7
g8
(S'\x07\xdf\x01\x03\x11.%\x05\xdf\xe8'
tRp3207
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While many existing tools support such collaborative efforts\n(e.g., dropbox, google docs), these tools lack intelligent information\nsharing mechanisms. While capabilities such as ``track changes'' and\n``diff'' visualize changes to authors, they do not distinguish between\nminor and major edits, and do not consider the possible effects of edits\non other parts of the document. Drawing collaborators' attention to\nspecific edits and describing them remains the responsibility of\nauthors. This paper presents our initial work toward the development of\na collaborative system that supports multi-author writing. We describe\nmethods for tracking paragraphs, identifying significant edits, and\npredicting parts of the paper that are likely to require changes as a\nresult of previous edits. Preliminary evaluation of the proposed methods\nshows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'', and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing, given the changes they have just made. Systems with\nsuch capabilities have the potential to improve coherence and\ncoordination while reducing the amount of communication required. An\nempirical evaluation of the approach on a corpus of Wikipedia articles\nshows promising initial results. Our methods make it possible to track\nparagraphs across revisions, identify significant changes, and predict\nparagraphs likely to be edited following a significant edit of a\nparticular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant changes, without requiring authors to\nspecify explicitly what changes are of interest to them. Furthermore,\nthese capabilities go beyond prior approaches for supporting change\nawareness in that they can support authors by drawing their attention to\nparts of the document that are likely to require edits as a result of\nthose changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques, which provide the foundation for these important\ncapabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they change\ntogether (or remain unchanged together) more than half the time. This\nsecond measure is a stronger indication than a paragraph undergoing just\none significant change.\n\nThe frequency of the relationship occurrence was variable. On average,\n1.6 pairs of paragraphs related by edit history were found per revision\nof the text. A pair related by topic similarity was only found once\nevery ten versions. Proximity relationships always exist in each\nversion, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than controls. For these controls, we compare with the\noriginal paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions. That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) and were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alerting authors to portions of the text that could be\nimproved. Finally, we plan to explore alternative ways of presenting the\ninformation chosen by the algorithms as important for authors to\nconsider. For example, the system might highlight changes that it deems\nrelevant or provide a list of them with links to the places they appear\nin the text.\n"
p3208
sg12
(lp3209
(iversion
Paragraph
p3210
(dp3211
g10
S"Many documents (e.g., academic papers) are typically written by multipleauthors. While many existing tools support such collaborative efforts(e.g., dropbox, google docs), these tools lack intelligent informationsharing mechanisms. While capabilities such as ``track changes'' and``diff'' visualize changes to authors, they do not distinguish betweenminor and major edits, and do not consider the possible effects of editson other parts of the document. Drawing collaborators' attention tospecific edits and describing them remains the responsibility ofauthors. This paper presents our initial work toward the development ofa collaborative system that supports multi-author writing. We describemethods for tracking paragraphs, identifying significant edits, andpredicting parts of the paper that are likely to require changes as aresult of previous edits. Preliminary evaluation of the proposed methodsshows promising results."
p3212
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3213
(dp3214
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'', and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceof changes to different authors and do not consider how edits mightaffect other parts of the document. Therefore, there is significantcoordination overhead: authors need to re-read the entire documentfrequently or rely on communication from their co-authors in order tokeep track of the current state of the document and ensure that theiredits are consistent with other edits."
p3215
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3216
(dp3217
g10
S"This paper presents our initial work toward the development of acollaborative system that assists multi-author writing by drawingauthors' attention to edits that are important and relevant for them,and by pointing out other parts of the document that are likely torequire editing, given the changes they have just made. Systems withsuch capabilities have the potential to improve coherence andcoordination while reducing the amount of communication required. Anempirical evaluation of the approach on a corpus of Wikipedia articlesshows promising initial results. Our methods make it possible to trackparagraphs across revisions, identify significant changes, and predictparagraphs likely to be edited following a significant edit of aparticular paragraph."
p3218
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3219
(dp3220
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing of editsand presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant changes, without requiring authors tospecify explicitly what changes are of interest to them. Furthermore,these capabilities go beyond prior approaches for supporting changeawareness in that they can support authors by drawing their attention toparts of the document that are likely to require edits as a result ofthose changes.'
p3221
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3222
(dp3223
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our lightweight use of NLPtechniques, which provide the foundation for these importantcapabilities."
p3224
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3225
(dp3226
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion.'
p3227
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3228
(dp3229
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3230
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3231
(dp3232
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use topicmodeling approach, specifically, Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI), which accounts forsynonyms and does not penalize for typographical errors. This approachuses the cosine similarity between word vectors that represent theparagraphs; if the cosine similarity between the new and old versions ofa paragraph is below an empirically determined threshold of 0.8, weconsider the edit significant."
p3233
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3234
(dp3235
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p3236
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3237
(dp3238
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3239
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3240
(dp3241
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p3242
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3243
(dp3244
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},i.e., paragraphs that tended to be edited together in previousrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with hightopic cosine similarity. For (2), we labeled pairs as related if theychanged or remained unchanged together over half the time in theprevious ten revisions. For (3), we labeled pairs as related if theircosine similarity was above an empirically determined threshold of 0.4.'
p3245
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3246
(dp3247
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p3248
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3249
(dp3250
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p3251
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3252
(dp3253
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Wefocused mostly on the prediction of future edits, but we also conducteda manual evaluation of paragraph mapping and significant changedetection, which form the basis for edit prediction.'
p3254
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3255
(dp3256
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p3257
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3258
(dp3259
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits toensure that 1) paragraphs were correctly mapped and 2) this methodsuccessfully classifies edits as significant or insignificant. Weprovide an example of a significant edit in Figure~{[}fig:pars{]}. Whilethese are clearly two versions of the same paragraph, the edit issignificant because it contributes content and alters the tone of thetext.'
p3260
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3261
(dp3262
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p3263
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3264
(dp3265
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they changetogether (or remain unchanged together) more than half the time. Thissecond measure is a stronger indication than a paragraph undergoing justone significant change.'
p3266
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3267
(dp3268
g10
S'The frequency of the relationship occurrence was variable. On average,1.6 pairs of paragraphs related by edit history were found per revisionof the text. A pair related by topic similarity was only found onceevery ten versions. Proximity relationships always exist in eachversion, as most paragraphs have two neighbors.'
p3269
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3270
(dp3271
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. It is also significantly morepredictive than controls. For these controls, we compare with theoriginal paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories. For this measure, therelationship of topic similarity still needs to be evaluated.'
p3272
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3273
(dp3274
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairsrelated by edit history and 63\\% of pairs related by topic. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions. That is, only20\\% of the paragraphs that should have been labeled as related (basedon information ten versions in the future) and were not included in theset of related paragraphs predicted by edit history and topicsimilarity.'
p3275
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3276
(dp3277
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p3278
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3279
(dp3280
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alerting authors to portions of the text that could beimproved. Finally, we plan to explore alternative ways of presenting theinformation chosen by the algorithms as important for authors toconsider. For example, the system might highlight changes that it deemsrelevant or provide a list of them with links to the places they appearin the text.'
p3281
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p3282
sba(iversion
Version
p3283
(dp3284
g7
g8
(S'\x07\xdf\x01\x03\x111\x16\x0e\xcd\x10'
tRp3285
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While many existing tools support such collaborative efforts\n(e.g., dropbox, google docs), these tools lack intelligent information\nsharing mechanisms. While capabilities such as ``track changes'' and\n``diff'' visualize changes to authors, they do not distinguish between\nminor and major edits, and do not consider the possible effects of edits\non other parts of the document. Drawing collaborators' attention to\nspecific edits and describing them remains the responsibility of\nauthors. This paper presents our initial work toward the development of\na collaborative system that supports multi-author writing. We describe\nmethods for tracking paragraphs, identifying significant edits, and\npredicting parts of the paper that are likely to require changes as a\nresult of previous edits. Preliminary evaluation of the proposed methods\nshows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'', and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing, given the changes they have just made. Systems with\nsuch capabilities have the potential to improve coherence and\ncoordination while reducing the amount of communication required. An\nempirical evaluation of the approach on a corpus of Wikipedia articles\nshows promising initial results. Our methods make it possible to track\nparagraphs across revisions, identify significant changes, and predict\nparagraphs likely to be edited following a significant edit of a\nparticular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant changes, without requiring authors to\nspecify explicitly what changes are of interest to them. Furthermore,\nthese capabilities go beyond prior approaches for supporting change\nawareness in that they can support authors by drawing their attention to\nparts of the document that are likely to require edits as a result of\nthose changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques, which provide the foundation for these important\ncapabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they change\ntogether (or remain unchanged together) more than half the time. This\nsecond measure is a stronger indication than a paragraph undergoing just\none significant change.\n\nThe frequency of the relationship occurrence was variable. On average,\n1.6 pairs of paragraphs related by edit history were found per revision\nof the text. A pair related by topic similarity was only found once\nevery ten versions. Proximity relationships always exist in each\nversion, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than controls. For these controls, we compare with the\noriginal paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions. That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) and were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to portions of the text that could be improved.\nFinally, we plan to explore alternative ways of presenting the\ninformation chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n"
p3286
sg12
(lp3287
(iversion
Paragraph
p3288
(dp3289
g10
S"Many documents (e.g., academic papers) are typically written by multipleauthors. While many existing tools support such collaborative efforts(e.g., dropbox, google docs), these tools lack intelligent informationsharing mechanisms. While capabilities such as ``track changes'' and``diff'' visualize changes to authors, they do not distinguish betweenminor and major edits, and do not consider the possible effects of editson other parts of the document. Drawing collaborators' attention tospecific edits and describing them remains the responsibility ofauthors. This paper presents our initial work toward the development ofa collaborative system that supports multi-author writing. We describemethods for tracking paragraphs, identifying significant edits, andpredicting parts of the paper that are likely to require changes as aresult of previous edits. Preliminary evaluation of the proposed methodsshows promising results."
p3290
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3291
(dp3292
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'', and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceof changes to different authors and do not consider how edits mightaffect other parts of the document. Therefore, there is significantcoordination overhead: authors need to re-read the entire documentfrequently or rely on communication from their co-authors in order tokeep track of the current state of the document and ensure that theiredits are consistent with other edits."
p3293
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3294
(dp3295
g10
S"This paper presents our initial work toward the development of acollaborative system that assists multi-author writing by drawingauthors' attention to edits that are important and relevant for them,and by pointing out other parts of the document that are likely torequire editing, given the changes they have just made. Systems withsuch capabilities have the potential to improve coherence andcoordination while reducing the amount of communication required. Anempirical evaluation of the approach on a corpus of Wikipedia articlesshows promising initial results. Our methods make it possible to trackparagraphs across revisions, identify significant changes, and predictparagraphs likely to be edited following a significant edit of aparticular paragraph."
p3296
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3297
(dp3298
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing of editsand presenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing and data mining methods toautomatically detect significant changes, without requiring authors tospecify explicitly what changes are of interest to them. Furthermore,these capabilities go beyond prior approaches for supporting changeawareness in that they can support authors by drawing their attention toparts of the document that are likely to require edits as a result ofthose changes.'
p3299
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3300
(dp3301
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our lightweight use of NLPtechniques, which provide the foundation for these importantcapabilities."
p3302
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3303
(dp3304
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio for the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion.'
p3305
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3306
(dp3307
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3308
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3309
(dp3310
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use topicmodeling approach, specifically, Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI), which accounts forsynonyms and does not penalize for typographical errors. This approachuses the cosine similarity between word vectors that represent theparagraphs; if the cosine similarity between the new and old versions ofa paragraph is below an empirically determined threshold of 0.8, weconsider the edit significant."
p3311
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3312
(dp3313
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p3314
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3315
(dp3316
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3317
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3318
(dp3319
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p3320
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3321
(dp3322
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},i.e., paragraphs that tended to be edited together in previousrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with hightopic cosine similarity. For (2), we labeled pairs as related if theychanged or remained unchanged together over half the time in theprevious ten revisions. For (3), we labeled pairs as related if theircosine similarity was above an empirically determined threshold of 0.4.'
p3323
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3324
(dp3325
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p3326
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3327
(dp3328
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p3329
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3330
(dp3331
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Wefocused mostly on the prediction of future edits, but we also conducteda manual evaluation of paragraph mapping and significant changedetection, which form the basis for edit prediction.'
p3332
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3333
(dp3334
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p3335
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3336
(dp3337
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits toensure that 1) paragraphs were correctly mapped and 2) this methodsuccessfully classifies edits as significant or insignificant. Weprovide an example of a significant edit in Figure~{[}fig:pars{]}. Whilethese are clearly two versions of the same paragraph, the edit issignificant because it contributes content and alters the tone of thetext.'
p3338
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3339
(dp3340
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p3341
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3342
(dp3343
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they changetogether (or remain unchanged together) more than half the time. Thissecond measure is a stronger indication than a paragraph undergoing justone significant change.'
p3344
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3345
(dp3346
g10
S'The frequency of the relationship occurrence was variable. On average,1.6 pairs of paragraphs related by edit history were found per revisionof the text. A pair related by topic similarity was only found onceevery ten versions. Proximity relationships always exist in eachversion, as most paragraphs have two neighbors.'
p3347
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3348
(dp3349
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. It is also significantly morepredictive than controls. For these controls, we compare with theoriginal paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories. For this measure, therelationship of topic similarity still needs to be evaluated.'
p3350
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3351
(dp3352
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairsrelated by edit history and 63\\% of pairs related by topic. (Proximitywas not evaluated for this measure, as it did almost no better than therandom control for the first, less strict, measure.) Further, weobtained a recall of 80\\% for these correct predictions. That is, only20\\% of the paragraphs that should have been labeled as related (basedon information ten versions in the future) and were not included in theset of related paragraphs predicted by edit history and topicsimilarity.'
p3353
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3354
(dp3355
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p3356
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3357
(dp3358
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alert authors to portions of the text that could be improved.'
p3359
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3360
(dp3361
g10
S'Finally, we plan to explore alternative ways of presenting theinformation chosen by the algorithms for authors to consider. Forexample, the system might highlight changes that it deems relevant orprovide a list of them with links to the places they appear in the text.'
p3362
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p3363
sba(iversion
Version
p3364
(dp3365
g7
g8
(S'\x07\xdf\x01\x03\x16\x00\t\t;H'
tRp3366
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While existing tools facilitate and support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. Capabilities such as ``track changes''\nand ``diff'' visualize changes to authors, but do not distinguish\nbetween minor and major edits and do not consider the possible effects\nof edits on other parts of the document. Drawing collaborators'\nattention to specific edits and describing them remains the\nresponsibility of authors. This paper presents our initial work toward\nthe development of a collaborative system that supports multi-author\nwriting. We describe methods for tracking paragraphs, identifying\nsignificant edits, and predicting parts of the paper that are likely to\nrequire changes as a result of previous edits. Preliminary evaluation of\nthe proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'', and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attentions\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nand coordination while reducing the amount of communication required\nbetween authors. An empirical evaluation of the proposed approach on a\ncorpus of Wikipedia articles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our use of lightweight NLP\ntechniques, which provide the foundation for these important\ncapabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio with the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n"
p3367
sg12
(lp3368
(iversion
Paragraph
p3369
(dp3370
g10
S"Many documents (e.g., academic papers) are typically written by multipleauthors. While existing tools facilitate and support such collaborativeefforts (e.g., dropbox, google docs), these tools lack intelligentinformation sharing mechanisms. Capabilities such as ``track changes''and ``diff'' visualize changes to authors, but do not distinguishbetween minor and major edits and do not consider the possible effectsof edits on other parts of the document. Drawing collaborators'attention to specific edits and describing them remains theresponsibility of authors. This paper presents our initial work towardthe development of a collaborative system that supports multi-authorwriting. We describe methods for tracking paragraphs, identifyingsignificant edits, and predicting parts of the paper that are likely torequire changes as a result of previous edits. Preliminary evaluation ofthe proposed methods shows promising results."
p3371
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3372
(dp3373
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., google docs, dropbox). However,while document processors provide capabilities such as ``trackchanges'', ``diff'', and commenting, they lack intelligent informationsharing mechanisms. They do not attempt to reason about the importanceof changes to different authors and do not consider how edits mightaffect other parts of the document. Therefore, there is significantcoordination overhead: authors need to re-read the entire documentfrequently or rely on communication from their co-authors in order tokeep track of the current state of the document and ensure that theiredits are consistent with other edits."
p3374
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3375
(dp3376
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of drawing authors' attentionsto edits that are important and relevant for them, and of pointing outother parts of the document that are likely to require further editing."
p3377
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3378
(dp3379
g10
S'Systems with such capabilities have the potential to improve coherenceand coordination while reducing the amount of communication requiredbetween authors. An empirical evaluation of the proposed approach on acorpus of Wikipedia articles shows promising initial results.'
p3380
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3381
(dp3382
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p3383
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3384
(dp3385
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p3386
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3387
(dp3388
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our use of lightweight NLPtechniques, which provide the foundation for these importantcapabilities."
p3389
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3390
(dp3391
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in the new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio with the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion.'
p3392
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3393
(dp3394
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3395
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3396
(dp3397
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use topicmodeling approach, specifically, Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI), which accounts forsynonyms and does not penalize for typographical errors. This approachuses the cosine similarity between word vectors that represent theparagraphs; if the cosine similarity between the new and old versions ofa paragraph is below an empirically determined threshold of 0.8, weconsider the edit significant."
p3398
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3399
(dp3400
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of aparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p3401
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3402
(dp3403
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3404
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3405
(dp3406
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p3407
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3408
(dp3409
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},i.e., paragraphs that tended to be edited together in previousrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with hightopic cosine similarity. For (2), we labeled pairs as related if theychanged or remained unchanged together over half the time in theprevious ten revisions. For (3), we labeled pairs as related if theircosine similarity was above an empirically determined threshold of 0.4.'
p3410
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3411
(dp3412
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p3413
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3414
(dp3415
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p3416
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3417
(dp3418
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Wefocused mostly on the prediction of future edits, but we also conducteda manual evaluation of paragraph mapping and significant changedetection, which form the basis for edit prediction.'
p3419
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3420
(dp3421
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p3422
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3423
(dp3424
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 such edits toensure that 1) paragraphs were correctly mapped and 2) this methodsuccessfully classifies edits as significant or insignificant. Weprovide an example of a significant edit in Figure~{[}fig:pars{]}. Whilethese are clearly two versions of the same paragraph, the edit issignificant because it contributes content and alters the tone of thetext.'
p3425
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3426
(dp3427
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p3428
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3429
(dp3430
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they keepchanging together (or remain unchanged together) more than half thetime. This second measure is a stronger indication of a possibleinterdependency between the paragraphs than the first measure.'
p3431
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3432
(dp3433
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p3434
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3435
(dp3436
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We also computed this measurefor the original paragraph as well as randomly sampled paragraphs andfound a significantly lower likelihood than for paragraphs related byedit similarity. For this measure, the relationship of topic similaritystill needs to be evaluated.'
p3437
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3438
(dp3439
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topiccontinued being modified (or unmodified) together in the next 10versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future) were not included in the set ofrelated paragraphs predicted by edit history and topic similarity.'
p3440
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3441
(dp3442
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p3443
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3444
(dp3445
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alert authors to parts of the text that could be improved.'
p3446
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3447
(dp3448
g10
S'Finally, we plan to explore alternative interface designs for presentingthe information chosen by the algorithms for authors to consider. Forexample, the system might highlight changes that it deems relevant orprovide a list of them with links to the places they appear in the text.'
p3449
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p3450
sba(iversion
Version
p3451
(dp3452
g7
g8
(S'\x07\xdf\x01\x04\x0b\x037\x07\x14\x80'
tRp3453
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While existing tools facilitate and support such collaborative\nefforts (e.g., Dropbox, Google Docs), these tools lack intelligent\ninformation sharing mechanisms. Capabilities such as ``track changes''\nand ``diff'' visualize changes to authors, but do not distinguish\nbetween minor and major edits and do not consider the possible effects\nof edits on other parts of the document. Drawing collaborators'\nattention to specific edits and describing them remains the\nresponsibility of authors. This paper presents our initial work toward\nthe development of a collaborative system that supports multi-author\nwriting. We describe methods for tracking paragraphs, identifying\nsignificant edits, and predicting parts of the paper that are likely to\nrequire changes as a result of previous edits. Preliminary evaluation of\nthe proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our use of lightweight NLP\ntechniques, which provide the foundation for these important\ncapabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio with the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n"
p3454
sg12
(lp3455
(iversion
Paragraph
p3456
(dp3457
g10
S"Many documents (e.g., academic papers) are typically written by multipleauthors. While existing tools facilitate and support such collaborativeefforts (e.g., Dropbox, Google Docs), these tools lack intelligentinformation sharing mechanisms. Capabilities such as ``track changes''and ``diff'' visualize changes to authors, but do not distinguishbetween minor and major edits and do not consider the possible effectsof edits on other parts of the document. Drawing collaborators'attention to specific edits and describing them remains theresponsibility of authors. This paper presents our initial work towardthe development of a collaborative system that supports multi-authorwriting. We describe methods for tracking paragraphs, identifyingsignificant edits, and predicting parts of the paper that are likely torequire changes as a result of previous edits. Preliminary evaluation ofthe proposed methods shows promising results."
p3458
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3459
(dp3460
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p3461
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3462
(dp3463
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of drawing authors' attentionto edits that are important and relevant for them, and of pointing outother parts of the document that are likely to require further editing."
p3464
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3465
(dp3466
g10
S'Systems with such capabilities have the potential to improve coherenceof documents and coordination among authors while reducing the amount ofcommunication required between authors. An empirical evaluation of theproposed approach on a corpus of Wikipedia articles shows promisinginitial results.'
p3467
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3468
(dp3469
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p3470
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3471
(dp3472
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p3473
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3474
(dp3475
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our use of lightweight NLPtechniques, which provide the foundation for these importantcapabilities."
p3476
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3477
(dp3478
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in a new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio with the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion.'
p3479
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3480
(dp3481
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3482
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3483
(dp3484
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use topicmodeling approach, specifically, Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI), which accounts forsynonyms and does not penalize for typographical errors. This approachuses the cosine similarity between word vectors that represent theparagraphs; if the cosine similarity between the new and old versions ofa paragraph is below an empirically determined threshold of 0.8, weconsider the edit significant."
p3485
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3486
(dp3487
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of aparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p3488
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3489
(dp3490
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3491
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3492
(dp3493
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p3494
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3495
(dp3496
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},i.e., paragraphs that tended to be edited together in previousrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with hightopic cosine similarity. For (2), we labeled pairs as related if theychanged or remained unchanged together over half the time in theprevious ten revisions. For (3), we labeled pairs as related if theircosine similarity was above an empirically determined threshold of 0.4.'
p3497
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3498
(dp3499
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p3500
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3501
(dp3502
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of the articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p3503
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3504
(dp3505
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Wefocused mostly on the prediction of future edits, but we also conducteda manual evaluation of paragraph mapping and significant changedetection, which form the basis for edit prediction.'
p3506
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3507
(dp3508
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p3509
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3510
(dp3511
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 such edits toensure that 1) paragraphs were correctly mapped and 2) this methodsuccessfully classifies edits as significant or insignificant. Weprovide an example of a significant edit in Figure~{[}fig:pars{]}. Whilethese are clearly two versions of the same paragraph, the edit issignificant because it contributes content and alters the tone of thetext.'
p3512
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3513
(dp3514
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p3515
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3516
(dp3517
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they keepchanging together (or remain unchanged together) more than half thetime. This second measure is a stronger indication of a possibleinterdependency between the paragraphs than the first measure.'
p3518
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3519
(dp3520
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p3521
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3522
(dp3523
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We also computed this measurefor the original paragraph as well as randomly sampled paragraphs andfound a significantly lower likelihood than for paragraphs related byedit similarity. For this measure, the relationship of topic similaritystill needs to be evaluated.'
p3524
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3525
(dp3526
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topiccontinued being modified (or unmodified) together in the next 10versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future) were not included in the set ofrelated paragraphs predicted by edit history and topic similarity.'
p3527
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3528
(dp3529
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p3530
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3531
(dp3532
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alert authors to parts of the text that could be improved.'
p3533
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3534
(dp3535
g10
S'Finally, we plan to explore alternative interface designs for presentingthe information chosen by the algorithms for authors to consider. Forexample, the system might highlight changes that it deems relevant orprovide a list of them with links to the places they appear in the text.'
p3536
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p3537
sba(iversion
Version
p3538
(dp3539
g7
g8
(S'\x07\xdf\x01\x04\x0e\r\x12\x050 '
tRp3540
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While existing tools facilitate and support such collaborative\nefforts (e.g., Dropbox, Google Docs), these tools lack intelligent\ninformation sharing mechanisms. Capabilities such as ``track changes''\nand ``diff'' visualize changes to authors, but do not distinguish\nbetween minor and major edits and do not consider the possible effects\nof edits on other parts of the document. Drawing collaborators'\nattention to specific edits and describing them remains the\nresponsibility of authors. This paper presents our initial work toward\nthe development of a collaborative system that supports multi-author\nwriting. We describe methods for tracking paragraphs, identifying\nsignificant edits, and predicting parts of the paper that are likely to\nrequire changes as a result of previous edits. Preliminary evaluation of\nthe proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our use of lightweight NLP\ntechniques, which provide the foundation for these important\ncapabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio with the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize typographical errors. This approach uses\nthe cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n"
p3541
sg12
(lp3542
(iversion
Paragraph
p3543
(dp3544
g10
S"Many documents (e.g., academic papers) are typically written by multipleauthors. While existing tools facilitate and support such collaborativeefforts (e.g., Dropbox, Google Docs), these tools lack intelligentinformation sharing mechanisms. Capabilities such as ``track changes''and ``diff'' visualize changes to authors, but do not distinguishbetween minor and major edits and do not consider the possible effectsof edits on other parts of the document. Drawing collaborators'attention to specific edits and describing them remains theresponsibility of authors. This paper presents our initial work towardthe development of a collaborative system that supports multi-authorwriting. We describe methods for tracking paragraphs, identifyingsignificant edits, and predicting parts of the paper that are likely torequire changes as a result of previous edits. Preliminary evaluation ofthe proposed methods shows promising results."
p3545
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3546
(dp3547
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p3548
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3549
(dp3550
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of drawing authors' attentionto edits that are important and relevant for them, and of pointing outother parts of the document that are likely to require further editing."
p3551
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3552
(dp3553
g10
S'Systems with such capabilities have the potential to improve coherenceof documents and coordination among authors while reducing the amount ofcommunication required between authors. An empirical evaluation of theproposed approach on a corpus of Wikipedia articles shows promisinginitial results.'
p3554
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3555
(dp3556
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,~\\cite{neuwirth2001computer,kittur2007he}), as well as the socialaspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about changes made to adocument. These include flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p3557
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3558
(dp3559
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p3560
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3561
(dp3562
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the article. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help promote only themost important changes and decide whether to alert collaborating authorsof a change. Capability (3) is required in order to draw authors'attention to other parts of the document that might require changes as aresult of a recent edit. We describe our use of lightweight NLPtechniques, which provide the foundation for these importantcapabilities."
p3563
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3564
(dp3565
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in a new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates highsimilarity, while a ratio close to 0 indicates the opposite. For eachrevision of a document, the algorithm computes the Levenshtein ratiobetween each paragraph in the old version and each paragraph in the newversion. Two paragraphs are mapped across the revision if they each havethe highest Levenshtein ratio with the other. If a paragraph in the newversion has no matching paragraphs in the old version (none of itsratios were above a threshold of 0.4), we label the paragraph as anaddition. If a paragraph in the old version is not matched with anyparagraphs in the next version, then we consider it a deletion.'
p3566
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3567
(dp3568
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3569
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3570
(dp3571
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach, specifically, Latent SemanticIndexing~\\cite{deerwester1990indexing} (LSI), which accounts forsynonyms and does not penalize typographical errors. This approach usesthe cosine similarity between word vectors that represent theparagraphs; if the cosine similarity between the new and old versions ofa paragraph is below an empirically determined threshold of 0.8, weconsider the edit significant."
p3572
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3573
(dp3574
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of aparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p3575
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3576
(dp3577
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3578
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3579
(dp3580
g10
S'Therefore, we developed methods for predicting which paragraphs arelikely to change in future revisions as a result of significant edits ina particular paragraph of the document.'
p3581
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3582
(dp3583
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},i.e., paragraphs that tended to be edited together in previousrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with hightopic cosine similarity. For (2), we labeled pairs as related if theychanged or remained unchanged together over half the time in theprevious ten revisions. For (3), we labeled pairs as related if theircosine similarity was above an empirically determined threshold of 0.4.'
p3584
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3585
(dp3586
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p3587
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3588
(dp3589
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p3590
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3591
(dp3592
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Wefocused mostly on the prediction of future edits, but we also conducteda manual evaluation of paragraph mapping and significant changedetection, which form the basis for edit prediction.'
p3593
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3594
(dp3595
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p3596
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3597
(dp3598
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 such edits toensure that 1) paragraphs were correctly mapped and 2) this methodsuccessfully classifies edits as significant or insignificant. Weprovide an example of a significant edit in Figure~{[}fig:pars{]}. Whilethese are clearly two versions of the same paragraph, the edit issignificant because it contributes content and alters the tone of thetext.'
p3599
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3600
(dp3601
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p3602
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3603
(dp3604
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they keepchanging together (or remain unchanged together) more than half thetime. This second measure is a stronger indication of a possibleinterdependency between the paragraphs than the first measure.'
p3605
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3606
(dp3607
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p3608
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3609
(dp3610
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We also computed this measurefor the original paragraph as well as randomly sampled paragraphs andfound a significantly lower likelihood than for paragraphs related byedit similarity. For this measure, the relationship of topic similaritystill needs to be evaluated.'
p3611
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3612
(dp3613
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topicsimilarity continued being modified (or unmodified) together in the next10 versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future) were not included in the set ofrelated paragraphs predicted by edit history and topic similarity.'
p3614
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3615
(dp3616
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Ratio of correctly-predicted future linking byrelationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\\midrule\\endheadTopic Similarity & 63\\% & &\\tabularnewlineEdit Similarity & 71\\% & &\\tabularnewline\\bottomrule\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p3617
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3618
(dp3619
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alert authors to parts of the text that could be improved.'
p3620
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3621
(dp3622
g10
S'Finally, we plan to explore alternative interface designs for presentingthe information chosen by the algorithms for authors to consider. Forexample, the system might highlight changes that it deems relevant orprovide a list of them with links to the places they appear in the text.'
p3623
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p3624
sba(iversion
Version
p3625
(dp3626
g7
g8
(S'\x07\xde\x0c\x0e\x10;\x05\n\xb2H'
tRp3627
sg10
S". See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.\n\n\\section{Introduction}\\label{introduction}\n\nMaybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikis\n\nnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision Activity\n\nWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nThe system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.\n\nINSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.\n\nThis method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches.\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in figure\n{[}X{]}.\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p3628
sg12
(lp3629
(iversion
Paragraph
p3630
(dp3631
g10
S'. See: \\url{http://www.acm.org/about/class/1998/} for help using the ACMClassification system.'
p3632
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3633
(dp3634
g10
S'\\section{Introduction}\\label{introduction}Maybe one paragraph (previous years talk about motivation in similarwork in intro and have one-two paragraphs in a background/related worksection) about how previous work tried to come up with frameworks tosupport writers and tried to investigate the writers problems. Theydescribe the motivation and the need for such a system: * TrackingChanges in Collaborative Writing: Edits, Visibility and GroupMaintenance Old examples: * Quilt: A collaborative tool for cooperativewriting - 1988 * User-centred iterative design of collaborative software-1993 * what do co-authors use? * They try to find relevant changes: *Flexible Diff-ing in a collaborative writing system * What did they do?'
p3635
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3636
(dp3637
g10
S'Deriving High-Level edit histories in Wikisnewer examples also try to classify changes: * How a Structured DocumentModel Can Support Awareness in Collaborative Authoring * A framework forasynchronous change awareness in collaborative documents and workspaces* some try to find conflicts (different definition of conflict though):* Enabling truly collaborative writing on a computer * and some try tofind an explicit structur in texts: * A narrative-based collaborativewriting tool for constructing coherent technical documents * trying topredict: * WikiChanges - Exposing Wikipedia Revision ActivityWhen authors collaborate to write a paper, they need to communicateconstantly to ensure that they are all on the same page. Because theauthors need to make sure that their edits are coherent with the rest ofthe paper, including sections written by others, they need to read theentire paper frequently, or rely on updates communicated by theircoauthors. Even with constant communication, authors can get lost in thevolume of edits from other collaborators. Therefore, an assistive systemwith a summary of the significant changes contributed by other authorswould be helpful. We hypothesize that when an author makes a significantedit to a paragraph, it eventually triggers a series of adjustments inrelated paragraphs. Before these adjustments occur, semantic conflictsmight occur between authors. We wanted a collaborative writing system toalso predict when and where these conflicts may occur, in order to alerteven more specifically.'
p3638
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3639
(dp3640
g10
S'The system is composed of the following three components: (1) trackingparagraphs; (2) identifying significant changes to paragraphs, and (3)predicting future changes to the article. Tracking paragraphs throughpaper revisions is a core capability required for monitoring changes andpredicting them. The identification of significant content changes isimportant for a system to understand how important different changes areand whether collaborating authors should be notified. Predicting futurechanges enables the system to not only report to authors about changesthat have already been made, but also draw their attention to otherparts of the document that might require changes as a result of thechanges made.'
p3641
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3642
(dp3643
g10
S"INSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changesin related paragraphs eighty percent of the time{]}, but incollaborative writing, these resulting edits do not occurinstantaneously. Instead of waiting for other authors to discover theinconsistency caused by one author's edit, we want an assistive systemthat can alert relevant authors about paragraphs that might need anadditional look as a result of an edit."
p3644
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3645
(dp3646
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a widevariety of Wikipedia articles that undergo intense editing processes.'
p3647
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3648
(dp3649
g10
S'Wikipedia is a unique source because it presents extensive data forcollaborative writing. The findings use the complete revision revisionhistory of 41 different articles chosen from a diverse set of topics,from famous people and places to mathematical algorithms to novels. Therevision histories were downloaded as raw xml data. We removedWikipedia-specific tags that indicate formatting and other irrelevantdata, and eliminated versions of the articles under 150 characters, asthey did not contain enough information. To focus only on revisions withconsequential changes, the versions with simple typo fixes{[}1{]} wereeliminated as well. This resulted in a total of 17,199 versions acrossthe 41 articles, with an average length of 25.71 paragraphs. Wikipediadata affords results applicable to other collaborative writing spaces,because although the average article has over 400 contributing authors,most of these authors make a one-time change. In fact, on average, 15authors make 80\\% of the edits to an article. This enables theconsideration of interactions between authors, which is crucial forlearning about collaborative behavior.'
p3650
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3651
(dp3652
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein editratio measure, which is defined in equation 1.'
p3653
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3654
(dp3655
g10
S'This method differed from previous attempts in the sense that it tracksparagraphs as a whole instead of just the longest common subsequence asused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.'
p3656
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3657
(dp3658
g10
S'A Levenshtein ratio close to one between two paragraphs indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision, we computed the Levenshtein ratio betweeneach paragraph in the old version and each paragraph in the new version.'
p3659
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3660
(dp3661
g10
S"Two paragraphs are mapped across the revision if they each had thehighest Levenshtein ratio for the other. If a paragraph in the newversion had no ``matches'', meaning that none of its ratios were above athreshold of 0.4, this paragraph was new. If a paragraph in the oldversion had no ``matches'', then it was deleted in the revision. Theimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of theold version were deleted, while the others found clear matches."
p3662
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3663
(dp3664
g10
S"\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph'stopic and content. For this calculation, the Levenshtein ratio does notprovide the right kind of information. For example, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple key words will slightly lower the Levenshtein ratio,but could drastically affect the content."
p3665
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3666
(dp3667
g10
S"As shown in figure 1, which shows the distribution of the differencesbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshteinand LSI ratios demonstrate very different statistics. {[}INSERTFIGURE{]}Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Latent Semantic Indexing is a form oftopic modeling that calculates the topic similarity between two texts."
p3668
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3669
(dp3670
g10
S"Its strengths lie in accounting for synonyms and not penalizing fortypographical errors. The process begins by composing a corpus for eachWikipedia article from all of the documents (paragraphs of the versionsof the article). It analyzes tokens (a specific instance of a word),eliminating those that only occur once, as well as stopword tokens, suchas `the' or `and'. It then creates a TF-IDF matrix, which assigns aweight to every token in each document, which indicates the importanceof that token for this document. This weight increases proportionally tothe frequency of the word in the document, but accounts for thefrequency of the word in the corpus, such that the frequent occurrenceof a usually uncommon word is given a larger weight to signify thisimportance."
p3671
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3672
(dp3673
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p3674
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3675
(dp3676
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p3677
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3678
(dp3679
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p3680
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3681
(dp3682
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3683
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3684
(dp3685
g10
S'Therefore, in order to predict future conflicts, an assistive systemneeds to detect significant changes and then determine consequentlywhich paragraphs were most likely to change.'
p3686
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3687
(dp3688
g10
S'We looked at three possible types of inter-paragraph relationships.'
p3689
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3690
(dp3691
g10
S'Paragraphs could be related by physical proximity: perhaps theneighboring paragraphs would require adjustments, as they are likelypart of the same section. Paragraphs could also be related by topic. Forexample, in an academic paper, the discussion section and the conclusionshould present similar themes. If one changes, the other may need to beedited to reflect this change. For each significant change, we used theexisting LSI Topic Model to determine which paragraphs discussed similartopics. Lastly, paragraphs could be related because of similar edithistories. For each significant change, we evaluated the edit history ofthis paragraph with every other paragraph in the article. We labeledpairs as related if they changed or remained unchanged together overhalf the time. With a higher threshold, the sample size decreases, butwith a lower threshold, the results become less predictive of asignificant change prompting further edits. This threshold strikes abalance between these two outcomes.'
p3692
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3693
(dp3694
g10
S"To evaluate these both of these suspected relationships, we looked atthe related paragraphs' edit patterns in the ten versions following thesignificant change. If the related paragraphs changed together over halfthe time, the paragraphs with this relationship proved to be related inthe future, verifying the relationship at the time of the significantchange."
p3695
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3696
(dp3697
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutiveversions of a paper, we calculated the number of versions from theparagraphs' inception to its demise. On average, paragraphs lasted 83article revisions."
p3698
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3699
(dp3700
g10
S'\\subsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown in figure{[}X{]}.'
p3701
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3702
(dp3703
g10
S'We evaluated a random sample of these edits to determine that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p3704
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3705
(dp3706
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p3707
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3708
(dp3709
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in figure {[}X{]}, when a paragraph isedited for the first time in a while, further adjustments are triggeredin the near future.'
p3710
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3711
(dp3712
g10
S'Caption: After a significant change at version 0, consequent edits aremore frequent.'
p3713
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3714
(dp3715
g10
S'We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p3716
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3717
(dp3718
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in table {[}X{]}. They are also significantly more predictive thanrandom sample controls. For controls, we compare with the originalparagraph as well as a random sample of any ten consecutive versionswithin Wikipedia article histories.'
p3719
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3720
(dp3721
g10
S'Relationship or Control Percentage of times that paragraph experiencedat least one significant change Edit History 81\\% Topic Similarity .'
p3722
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3723
(dp3724
g10
S'Physical Proximity 24\\% Paragraph with original significant change 40\\%Random Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p3725
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3726
(dp3727
g10
S'Relationship Number Found Successfully Linked Ratio of SuccessfullyLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,68571\\%Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p3728
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3729
(dp3730
g10
S'The correlation coefficient was 0.99 for all numbers.'
p3731
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3732
(dp3733
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p3734
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3735
(dp3736
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p3737
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3738
(dp3739
g10
S'We imagine a couple other helpful components for an assistive systemthat our methods could provide the foundation for. Using text summaryalgorithms, the system could provide a succinct textual summary ofsignificant changes already detected. The system could also \\ldots{}.'
p3740
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3741
(dp3742
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determiningwhether a paragraph will change together in the future. Consequently, weassert that if significant edit occurs, related paragraphs should alsobe edited. A proposed assistive system will alert the relevant authorsof related paragraphs if this resulting edit does not occur. Bydetecting relationships between paragraphs in a multi-authored paper,our system can predict and alert appropriate authors if a significantchange has the potential to create a semantic conflict within the paper.'
p3743
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p3744
sba(iversion
Version
p3745
(dp3746
g7
g8
(S'\x07\xdf\x01\x04\x11\x15#\x0b\xa8`'
tRp3747
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we investigated which paragraphs are likely to change in\nfuture revisions as a result of edits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimiarlity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 such edits to\nensure that paragraphs were correctly mapped and determine that the\nmethod successfully classified edits (as significant or insignificant).\nto ensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it adds new content and alters the tone of the text.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n"
p3748
sg12
(lp3749
(iversion
Paragraph
p3750
(dp3751
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of the these methods shows promising results."
p3752
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3753
(dp3754
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p3755
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3756
(dp3757
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of drawing authors' attentionto edits that are important and relevant for them, and of pointing outother parts of the document that are likely to require further editing."
p3758
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3759
(dp3760
g10
S'Systems with such capabilities have the potential to improve coherenceof documents and coordination among authors while reducing the amount ofcommunication required between authors. An empirical evaluation of theproposed approach on a corpus of Wikipedia articles shows promisinginitial results.'
p3761
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3762
(dp3763
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p3764
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3765
(dp3766
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p3767
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3768
(dp3769
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p3770
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3771
(dp3772
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in a new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratioclose to 0 indicates the opposite. For each revision of a document, thealgorithm computes the Levenshtein ratio between each paragraph in theold version and each paragraph in the new version. Two paragraphs aremapped across the revision if they each have the highest Levenshteinratio with the other. If a paragraph in the new version has no matchingparagraphs in the old version (i.e., none of its ratios were above athreshold of 0.4), we label the paragraph as an addition. If a paragraphin the old version is not matched with any paragraphs in the nextversion, then we consider it a deletion. Figure~{[}fig:mapping{]}illustrates this algorithm: some paragraphs found clear matches (e.g.,0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,10, and 12 were added in the new version.'
p3773
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3774
(dp3775
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach which computes the cosine similarity between wordvectors that represent the two versions of a paragraph. Specifically, weuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), whichaccounts for synonyms and does not penalize typographical errors. If thecosine similarity between new and old versions of a paragraph is below athreshold of 0.8, we consider the edit significant. The threshold of 0.8was determined empirically by manually evaluating differences betweenparagraphs with varied similarity values."
p3776
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3777
(dp3778
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of aparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p3779
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3780
(dp3781
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3782
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3783
(dp3784
g10
S'Therefore, we investigated which paragraphs are likely to change infuture revisions as a result of edits to other paragraphs.'
p3785
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3786
(dp3787
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed getting ameaningful signal of correlation between edits, while not looking toofar in the past when the content might have been significantlydifferent. For (3), we labeled pairs as related if their cosinesimilarity was above an empirically determined threshold of 0.4. (Thereare rarely paragraphs with a higher similarity than 0.4, while a lowersimiarlity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p3788
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3789
(dp3790
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p3791
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3792
(dp3793
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p3794
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3795
(dp3796
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p3797
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3798
(dp3799
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p3800
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3801
(dp3802
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 such edits toensure that paragraphs were correctly mapped and determine that themethod successfully classified edits (as significant or insignificant).'
p3803
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3804
(dp3805
g10
S'to ensure that 1) paragraphs were correctly mapped and 2) this methodsuccessfully classifies edits as significant or insignificant. Weprovide an example of a significant edit in Figure~{[}fig:pars{]}. Whilethese are clearly two versions of the same paragraph, the edit issignificant because it adds new content and alters the tone of the text.'
p3806
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3807
(dp3808
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p3809
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3810
(dp3811
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they keepchanging together (or remain unchanged together) more than half thetime. This second measure is a stronger indication of a possibleinterdependency between the paragraphs than the first measure.'
p3812
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3813
(dp3814
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p3815
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3816
(dp3817
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We also computed this measurefor the original paragraph as well as randomly sampled paragraphs andfound a significantly lower likelihood than for paragraphs related byedit similarity. For this measure, the relationship of topic similaritystill needs to be evaluated.'
p3818
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3819
(dp3820
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topicsimilarity continued being modified (or unmodified) together in the next10 versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future) were not included in the set ofrelated paragraphs predicted by edit history and topic similarity.'
p3821
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3822
(dp3823
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p3824
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3825
(dp3826
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alert authors to parts of the text that could be improved.'
p3827
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3828
(dp3829
g10
S"Finally, we plan to explore alternative interface designs for presentingthe information chosen by the algorithms for authors to consider. Wealso plan to incorporate explanations for system recommendations (e.g.,``we recommend reading the introduction because it is often editedfollowing edits to the results section'')."
p3830
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p3831
sba(iversion
Version
p3832
(dp3833
g7
g8
(S'\x07\xdf\x02\x03\x11\x0f\x1f\ri\x98'
tRp3834
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we investigated which paragraphs are likely to change in\nfuture revisions as a result of edits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimiarlity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 such edits to\nensure that paragraphs were correctly mapped and whether the method\nsuccessfully classified edits as significant or insignificant. Overall,\nwe found that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further. Figure~{[}fig:pars{]} shows an\nexample of a significant edit: while the bottom paragraph is clearly a\nrevision of the same paragraph (recurring text shown in bold), the edit\nis significant because it adds new content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n"
p3835
sg12
(lp3836
(iversion
Paragraph
p3837
(dp3838
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of the these methods shows promising results."
p3839
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3840
(dp3841
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p3842
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3843
(dp3844
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of drawing authors' attentionto edits that are important and relevant for them, and of pointing outother parts of the document that are likely to require further editing."
p3845
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3846
(dp3847
g10
S'Systems with such capabilities have the potential to improve coherenceof documents and coordination among authors while reducing the amount ofcommunication required between authors. An empirical evaluation of theproposed approach on a corpus of Wikipedia articles shows promisinginitial results.'
p3848
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3849
(dp3850
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p3851
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3852
(dp3853
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p3854
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3855
(dp3856
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p3857
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3858
(dp3859
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in a new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratioclose to 0 indicates the opposite. For each revision of a document, thealgorithm computes the Levenshtein ratio between each paragraph in theold version and each paragraph in the new version. Two paragraphs aremapped across the revision if they each have the highest Levenshteinratio with the other. If a paragraph in the new version has no matchingparagraphs in the old version (i.e., none of its ratios were above athreshold of 0.4), we label the paragraph as an addition. If a paragraphin the old version is not matched with any paragraphs in the nextversion, then we consider it a deletion. Figure~{[}fig:mapping{]}illustrates this algorithm: some paragraphs found clear matches (e.g.,0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,10, and 12 were added in the new version.'
p3860
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3861
(dp3862
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach which computes the cosine similarity between wordvectors that represent the two versions of a paragraph. Specifically, weuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), whichaccounts for synonyms and does not penalize typographical errors. If thecosine similarity between new and old versions of a paragraph is below athreshold of 0.8, we consider the edit significant. The threshold of 0.8was determined empirically by manually evaluating differences betweenparagraphs with varied similarity values."
p3863
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3864
(dp3865
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of aparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p3866
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3867
(dp3868
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3869
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3870
(dp3871
g10
S'Therefore, we investigated which paragraphs are likely to change infuture revisions as a result of edits to other paragraphs.'
p3872
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3873
(dp3874
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed getting ameaningful signal of correlation between edits, while not looking toofar in the past when the content might have been significantlydifferent. For (3), we labeled pairs as related if their cosinesimilarity was above an empirically determined threshold of 0.4. (Thereare rarely paragraphs with a higher similarity than 0.4, while a lowersimiarlity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p3875
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3876
(dp3877
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p3878
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3879
(dp3880
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p3881
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3882
(dp3883
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p3884
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3885
(dp3886
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p3887
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3888
(dp3889
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 such edits toensure that paragraphs were correctly mapped and whether the methodsuccessfully classified edits as significant or insignificant. Overall,we found that paragraphs were rarely mapped incorrectly (less than\\(5\\%\\)). Similarly, we found the classification of significant edits tobe correct in most cases, however this is a more subjective measurewhich we plan to evaluate further. Figure~{[}fig:pars{]} shows anexample of a significant edit: while the bottom paragraph is clearly arevision of the same paragraph (recurring text shown in bold), the editis significant because it adds new content and alters the tone of thetext.'
p3890
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3891
(dp3892
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p3893
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3894
(dp3895
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they keepchanging together (or remain unchanged together) more than half thetime. This second measure is a stronger indication of a possibleinterdependency between the paragraphs than the first measure.'
p3896
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3897
(dp3898
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p3899
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3900
(dp3901
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We also computed this measurefor the original paragraph as well as randomly sampled paragraphs andfound a significantly lower likelihood than for paragraphs related byedit similarity. For this measure, the relationship of topic similaritystill needs to be evaluated.'
p3902
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3903
(dp3904
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topicsimilarity continued being modified (or unmodified) together in the next10 versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future) were not included in the set ofrelated paragraphs predicted by edit history and topic similarity.'
p3905
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3906
(dp3907
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p3908
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3909
(dp3910
g10
S'While the motivation for our work is supporting collaborating authors,the methods could also provide better support a single author.'
p3911
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3912
(dp3913
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alert authors to parts of the text that could be improved.'
p3914
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3915
(dp3916
g10
S"Finally, we plan to explore alternative interface designs for presentingthe information chosen by the algorithms for authors to consider. Wealso plan to incorporate explanations for system recommendations (e.g.,``we recommend reading the introduction because it is often editedfollowing edits to the results section'')."
p3917
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p3918
sba(iversion
Version
p3919
(dp3920
g7
g8
(S'\x07\xdf\x02\x03\x13#\x03\x08\x978'
tRp3921
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we investigated which paragraphs are likely to change in\nfuture revisions as a result of edits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimilarity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Edit Correlations and Prediction of Future\nEdits}\\label{edit-correlations-and-prediction-of-future-edits}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n"
p3922
sg12
(lp3923
(iversion
Paragraph
p3924
(dp3925
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of the these methods shows promising results."
p3926
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3927
(dp3928
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p3929
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3930
(dp3931
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of drawing authors' attentionto edits that are important and relevant for them, and of pointing outother parts of the document that are likely to require further editing."
p3932
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3933
(dp3934
g10
S'Systems with such capabilities have the potential to improve coherenceof documents and coordination among authors while reducing the amount ofcommunication required between authors. An empirical evaluation of theproposed approach on a corpus of Wikipedia articles shows promisinginitial results.'
p3935
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3936
(dp3937
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p3938
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3939
(dp3940
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p3941
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3942
(dp3943
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p3944
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3945
(dp3946
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in a new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratioclose to 0 indicates the opposite. For each revision of a document, thealgorithm computes the Levenshtein ratio between each paragraph in theold version and each paragraph in the new version. Two paragraphs aremapped across the revision if they each have the highest Levenshteinratio with the other. If a paragraph in the new version has no matchingparagraphs in the old version (i.e., none of its ratios were above athreshold of 0.4), we label the paragraph as an addition. If a paragraphin the old version is not matched with any paragraphs in the nextversion, then we consider it a deletion. Figure~{[}fig:mapping{]}illustrates this algorithm: some paragraphs found clear matches (e.g.,0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,10, and 12 were added in the new version.'
p3947
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3948
(dp3949
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach which computes the cosine similarity between wordvectors that represent the two versions of a paragraph. Specifically, weuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), whichaccounts for synonyms and does not penalize typographical errors. If thecosine similarity between new and old versions of a paragraph is below athreshold of 0.8, we consider the edit significant. The threshold of 0.8was determined empirically by manually evaluating differences betweenparagraphs with varied similarity values."
p3950
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3951
(dp3952
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of aparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p3953
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3954
(dp3955
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p3956
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3957
(dp3958
g10
S'Therefore, we investigated which paragraphs are likely to change infuture revisions as a result of edits to other paragraphs.'
p3959
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3960
(dp3961
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed getting ameaningful signal of correlation between edits, while not looking toofar in the past when the content might have been significantlydifferent. For (3), we labeled pairs as related if their cosinesimilarity was above an empirically determined threshold of 0.4. (Thereare rarely paragraphs with a higher similarity than 0.4, while a lowersimilarity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p3962
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3963
(dp3964
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p3965
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3966
(dp3967
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p3968
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3969
(dp3970
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p3971
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3972
(dp3973
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p3974
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3975
(dp3976
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random editedmapped paragraphs to ensure that paragraphs were correctly mapped andwhether the method successfully classified edits as significant orinsignificant. Figure~{[}fig:pars{]} shows an example of a significantedit: while the bottom paragraph is clearly a revision of the sameparagraph (recurring text shown in bold), the edit is significantbecause it adds new content and alters the tone of the text. Overall, wefound that paragraphs were rarely mapped incorrectly (less than\\(5\\%\\)). Similarly, we found the classification of significant edits tobe correct in most cases, however this is a more subjective measurewhich we plan to evaluate further in future work.'
p3977
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3978
(dp3979
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Edit Correlations and Prediction of FutureEdits}\\label{edit-correlations-and-prediction-of-future-edits}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p3980
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3981
(dp3982
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they keepchanging together (or remain unchanged together) more than half thetime. This second measure is a stronger indication of a possibleinterdependency between the paragraphs than the first measure.'
p3983
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3984
(dp3985
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p3986
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3987
(dp3988
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We also computed this measurefor the original paragraph as well as randomly sampled paragraphs andfound a significantly lower likelihood than for paragraphs related byedit similarity. For this measure, the relationship of topic similaritystill needs to be evaluated.'
p3989
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3990
(dp3991
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topicsimilarity continued being modified (or unmodified) together in the next10 versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future) were not included in the set ofrelated paragraphs predicted by edit history and topic similarity.'
p3992
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3993
(dp3994
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p3995
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3996
(dp3997
g10
S'While the motivation for our work is supporting collaborating authors,the methods could also provide better support a single author.'
p3998
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3999
(dp4000
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alert authors to parts of the text that could be improved.'
p4001
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4002
(dp4003
g10
S"Finally, we plan to explore alternative interface designs for presentingthe information chosen by the algorithms for authors to consider. Wealso plan to incorporate explanations for system recommendations (e.g.,``we recommend reading the introduction because it is often editedfollowing edits to the results section'')."
p4004
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4005
sba(iversion
Version
p4006
(dp4007
g7
g8
(S'\x07\xdf\x02\x03\x17,(\x02\x8cX'
tRp4008
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs. Therefore, we investigated\nwhich paragraphs are likely to change in future revisions as a result of\nedits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimilarity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Edit Correlations and Prediction of Future\nEdits}\\label{edit-correlations-and-prediction-of-future-edits}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4009
sg12
(lp4010
(iversion
Paragraph
p4011
(dp4012
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of the these methods shows promising results."
p4013
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4014
(dp4015
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p4016
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4017
(dp4018
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of drawing authors' attentionto edits that are important and relevant for them, and of pointing outother parts of the document that are likely to require further editing."
p4019
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4020
(dp4021
g10
S'Systems with such capabilities have the potential to improve coherenceof documents and coordination among authors while reducing the amount ofcommunication required between authors. An empirical evaluation of theproposed approach on a corpus of Wikipedia articles shows promisinginitial results.'
p4022
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4023
(dp4024
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p4025
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4026
(dp4027
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p4028
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4029
(dp4030
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p4031
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4032
(dp4033
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in a new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratioclose to 0 indicates the opposite. For each revision of a document, thealgorithm computes the Levenshtein ratio between each paragraph in theold version and each paragraph in the new version. Two paragraphs aremapped across the revision if they each have the highest Levenshteinratio with the other. If a paragraph in the new version has no matchingparagraphs in the old version (i.e., none of its ratios were above athreshold of 0.4), we label the paragraph as an addition. If a paragraphin the old version is not matched with any paragraphs in the nextversion, then we consider it a deletion. Figure~{[}fig:mapping{]}illustrates this algorithm: some paragraphs found clear matches (e.g.,0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,10, and 12 were added in the new version.'
p4034
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4035
(dp4036
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach which computes the cosine similarity between wordvectors that represent the two versions of a paragraph. Specifically, weuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), whichaccounts for synonyms and does not penalize typographical errors. If thecosine similarity between new and old versions of a paragraph is below athreshold of 0.8, we consider the edit significant. The threshold of 0.8was determined empirically by manually evaluating differences betweenparagraphs with varied similarity values."
p4037
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4038
(dp4039
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of aparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p4040
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4041
(dp4042
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould prompt edits in related paragraphs. Therefore, we investigatedwhich paragraphs are likely to change in future revisions as a result ofedits to other paragraphs.'
p4043
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4044
(dp4045
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed getting ameaningful signal of correlation between edits, while not looking toofar in the past when the content might have been significantlydifferent. For (3), we labeled pairs as related if their cosinesimilarity was above an empirically determined threshold of 0.4. (Thereare rarely paragraphs with a higher similarity than 0.4, while a lowersimilarity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p4046
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4047
(dp4048
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p4049
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4050
(dp4051
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p4052
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4053
(dp4054
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p4055
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4056
(dp4057
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p4058
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4059
(dp4060
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random editedmapped paragraphs to ensure that paragraphs were correctly mapped andwhether the method successfully classified edits as significant orinsignificant. Figure~{[}fig:pars{]} shows an example of a significantedit: while the bottom paragraph is clearly a revision of the sameparagraph (recurring text shown in bold), the edit is significantbecause it adds new content and alters the tone of the text. Overall, wefound that paragraphs were rarely mapped incorrectly (less than\\(5\\%\\)). Similarly, we found the classification of significant edits tobe correct in most cases, however this is a more subjective measurewhich we plan to evaluate further in future work.'
p4061
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4062
(dp4063
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Edit Correlations and Prediction of FutureEdits}\\label{edit-correlations-and-prediction-of-future-edits}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p4064
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4065
(dp4066
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they keepchanging together (or remain unchanged together) more than half thetime. This second measure is a stronger indication of a possibleinterdependency between the paragraphs than the first measure.'
p4067
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4068
(dp4069
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p4070
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4071
(dp4072
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We also computed this measurefor the original paragraph as well as randomly sampled paragraphs andfound a significantly lower likelihood than for paragraphs related byedit similarity. For this measure, the relationship of topic similaritystill needs to be evaluated.'
p4073
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4074
(dp4075
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topicsimilarity continued being modified (or unmodified) together in the next10 versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future) were not included in the set ofrelated paragraphs predicted by edit history and topic similarity.'
p4076
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4077
(dp4078
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p4079
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4080
(dp4081
g10
S'While the motivation for our work is supporting collaborating authors,the methods could also provide better support a single author.'
p4082
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4083
(dp4084
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alert authors to parts of the text that could be improved.'
p4085
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4086
(dp4087
g10
S"Finally, we plan to explore alternative interface designs for presentingthe information chosen by the algorithms for authors to consider. Wealso plan to incorporate explanations for system recommendations (e.g.,``we recommend reading the introduction because it is often editedfollowing edits to the results section'')."
p4088
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4089
(dp4090
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the NuanceFoundation. We thank Stuart Shieber for helpful discussions.'
p4091
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4092
sba(iversion
Version
p4093
(dp4094
g7
g8
(S'\x07\xdf\x02\x04\x01#)\x0eW\xe0'
tRp4095
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs. Therefore, we investigated\nwhich paragraphs are likely to change in future revisions as a result of\nedits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimilarity does not really capture a similarity in content.) For each of\nthe three inter-paragraph relationships, we use the edit history prior\nto revision \\(t\\) to predict which paragraphs will be likely to change\nin consequent revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. That is, we\nuse information from the revisions up to revision \\(t\\) to predict\nwhether a paragraph will change significantly in revisions \\(t+1\\) to\n\\(t+10\\). The second measure tests whether the two paragraphs are\nrelated by edit patterns ten versions after the significant change, that\nis, whether they keep changing together (or remain unchanged together)\nmore than half the time in revisions \\(t+1\\) to \\(t+10\\). This second\nmeasure is a stronger indication of a possible interdependency between\nthe paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4096
sg12
(lp4097
(iversion
Paragraph
p4098
(dp4099
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of the these methods shows promising results."
p4100
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4101
(dp4102
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p4103
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4104
(dp4105
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of drawing authors' attentionto edits that are important and relevant for them, and of pointing outother parts of the document that are likely to require further editing."
p4106
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4107
(dp4108
g10
S'Systems with such capabilities have the potential to improve coherenceof documents and coordination among authors while reducing the amount ofcommunication required between authors. An empirical evaluation of theproposed approach on a corpus of Wikipedia articles shows promisinginitial results.'
p4109
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4110
(dp4111
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p4112
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4113
(dp4114
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p4115
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4116
(dp4117
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p4118
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4119
(dp4120
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in a new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratioclose to 0 indicates the opposite. For each revision of a document, thealgorithm computes the Levenshtein ratio between each paragraph in theold version and each paragraph in the new version. Two paragraphs aremapped across the revision if they each have the highest Levenshteinratio with the other. If a paragraph in the new version has no matchingparagraphs in the old version (i.e., none of its ratios were above athreshold of 0.4), we label the paragraph as an addition. If a paragraphin the old version is not matched with any paragraphs in the nextversion, then we consider it a deletion. Figure~{[}fig:mapping{]}illustrates this algorithm: some paragraphs found clear matches (e.g.,0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,10, and 12 were added in the new version.'
p4121
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4122
(dp4123
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach which computes the cosine similarity between wordvectors that represent the two versions of a paragraph. Specifically, weuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), whichaccounts for synonyms and does not penalize typographical errors. If thecosine similarity between new and old versions of a paragraph is below athreshold of 0.8, we consider the edit significant. The threshold of 0.8was determined empirically by manually evaluating differences betweenparagraphs with varied similarity values."
p4124
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4125
(dp4126
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of aparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p4127
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4128
(dp4129
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould prompt edits in related paragraphs. Therefore, we investigatedwhich paragraphs are likely to change in future revisions as a result ofedits to other paragraphs.'
p4130
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4131
(dp4132
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed getting ameaningful signal of correlation between edits, while not looking toofar in the past when the content might have been significantlydifferent. For (3), we labeled pairs as related if their cosinesimilarity was above an empirically determined threshold of 0.4. (Thereare rarely paragraphs with a higher similarity than 0.4, while a lowersimilarity does not really capture a similarity in content.) For each ofthe three inter-paragraph relationships, we use the edit history priorto revision \\(t\\) to predict which paragraphs will be likely to changein consequent revisions.'
p4133
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4134
(dp4135
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p4136
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4137
(dp4138
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p4139
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4140
(dp4141
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p4142
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4143
(dp4144
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p4145
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4146
(dp4147
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p4148
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4149
(dp4150
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random editedmapped paragraphs to ensure that paragraphs were correctly mapped andwhether the method successfully classified edits as significant orinsignificant. Figure~{[}fig:pars{]} shows an example of a significantedit: while the bottom paragraph is clearly a revision of the sameparagraph (recurring text shown in bold), the edit is significantbecause it adds new content and alters the tone of the text. Overall, wefound that paragraphs were rarely mapped incorrectly (less than\\(5\\%\\)). Similarly, we found the classification of significant edits tobe correct in most cases, however this is a more subjective measurewhich we plan to evaluate further in future work.'
p4151
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4152
(dp4153
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p4154
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4155
(dp4156
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. That is, weuse information from the revisions up to revision \\(t\\) to predictwhether a paragraph will change significantly in revisions \\(t+1\\) to\\(t+10\\). The second measure tests whether the two paragraphs arerelated by edit patterns ten versions after the significant change, thatis, whether they keep changing together (or remain unchanged together)more than half the time in revisions \\(t+1\\) to \\(t+10\\). This secondmeasure is a stronger indication of a possible interdependency betweenthe paragraphs than the first measure.'
p4157
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4158
(dp4159
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p4160
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4161
(dp4162
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We also computed this measurefor the original paragraph as well as randomly sampled paragraphs andfound a significantly lower likelihood than for paragraphs related byedit similarity. For this measure, the relationship of topic similaritystill needs to be evaluated.'
p4163
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4164
(dp4165
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topicsimilarity continued being modified (or unmodified) together in the next10 versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future) were not included in the set ofrelated paragraphs predicted by edit history and topic similarity.'
p4166
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4167
(dp4168
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p4169
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4170
(dp4171
g10
S'While the motivation for our work is supporting collaborating authors,the methods could also provide better support a single author.'
p4172
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4173
(dp4174
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alert authors to parts of the text that could be improved.'
p4175
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4176
(dp4177
g10
S"Finally, we plan to explore alternative interface designs for presentingthe information chosen by the algorithms for authors to consider. Wealso plan to incorporate explanations for system recommendations (e.g.,``we recommend reading the introduction because it is often editedfollowing edits to the results section'')."
p4178
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4179
(dp4180
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the NuanceFoundation. We thank Stuart Shieber for helpful discussions.'
p4181
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4182
sba(iversion
Version
p4183
(dp4184
g7
g8
(S'\x07\xdf\x02\x04\x13\t\x1d\tbX'
tRp4185
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs. Therefore, we investigated\nwhich paragraphs are likely to change in future revisions as a result of\nedits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity in the was above an empirically determined threshold of 0.4.\n(There are rarely paragraphs with a higher similarity than 0.4, while a\nlower similarity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. That is, we\nuse information from the revisions up to revision \\(t\\) to predict\nwhether a paragraph will change significantly in revisions \\(t+1\\) to\n\\(t+10\\). The second measure tests whether the two paragraphs are\nrelated by edit patterns ten versions after the significant change, that\nis, whether they keep changing together (or remain unchanged together)\nmore than half the time in revisions \\(t+1\\) to \\(t+10\\). This second\nmeasure is a stronger indication of a possible interdependency between\nthe paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4186
sg12
(lp4187
(iversion
Paragraph
p4188
(dp4189
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of the these methods shows promising results."
p4190
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4191
(dp4192
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p4193
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4194
(dp4195
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of drawing authors' attentionto edits that are important and relevant for them, and of pointing outother parts of the document that are likely to require further editing."
p4196
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4197
(dp4198
g10
S'Systems with such capabilities have the potential to improve coherenceof documents and coordination among authors while reducing the amount ofcommunication required between authors. An empirical evaluation of theproposed approach on a corpus of Wikipedia articles shows promisinginitial results.'
p4199
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4200
(dp4201
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p4202
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4203
(dp4204
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p4205
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4206
(dp4207
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p4208
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4209
(dp4210
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. To track paragraphs throughout document revisions, we developeda mapping algorithm that determines which paragraph in a new versioncorresponds to each of the paragraphs in the previous version (prior toediting). The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio measure, which isdefined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratioclose to 0 indicates the opposite. For each revision of a document, thealgorithm computes the Levenshtein ratio between each paragraph in theold version and each paragraph in the new version. Two paragraphs aremapped across the revision if they each have the highest Levenshteinratio with the other. If a paragraph in the new version has no matchingparagraphs in the old version (i.e., none of its ratios were above athreshold of 0.4), we label the paragraph as an addition. If a paragraphin the old version is not matched with any paragraphs in the nextversion, then we consider it a deletion. Figure~{[}fig:mapping{]}illustrates this algorithm: some paragraphs found clear matches (e.g.,0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,10, and 12 were added in the new version.'
p4211
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4212
(dp4213
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach which computes the cosine similarity between wordvectors that represent the two versions of a paragraph. Specifically, weuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), whichaccounts for synonyms and does not penalize typographical errors. If thecosine similarity between new and old versions of a paragraph is below athreshold of 0.8, we consider the edit significant. The threshold of 0.8was determined empirically by manually evaluating differences betweenparagraphs with varied similarity values."
p4214
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4215
(dp4216
g10
S"We chose a topic modeling approach for this task because, in contrastwith the Levenshtein ratio approach used for mapping paragraphs, topicmodeling considers the content of the text. To illustrate, if two of aparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple of key words will slightly lower the Levenshteinratio, but could drastically affect the content."
p4217
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4218
(dp4219
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould prompt edits in related paragraphs. Therefore, we investigatedwhich paragraphs are likely to change in future revisions as a result ofedits to other paragraphs.'
p4220
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4221
(dp4222
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed getting ameaningful signal of correlation between edits, while not looking toofar in the past when the content might have been significantlydifferent. For (3), we labeled pairs as related if their cosinesimilarity in the was above an empirically determined threshold of 0.4.'
p4223
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4224
(dp4225
g10
S'(There are rarely paragraphs with a higher similarity than 0.4, while alower similarity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p4226
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4227
(dp4228
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p4229
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4230
(dp4231
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p4232
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4233
(dp4234
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p4235
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4236
(dp4237
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p4238
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4239
(dp4240
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random editedmapped paragraphs to ensure that paragraphs were correctly mapped andwhether the method successfully classified edits as significant orinsignificant. Figure~{[}fig:pars{]} shows an example of a significantedit: while the bottom paragraph is clearly a revision of the sameparagraph (recurring text shown in bold), the edit is significantbecause it adds new content and alters the tone of the text. Overall, wefound that paragraphs were rarely mapped incorrectly (less than\\(5\\%\\)). Similarly, we found the classification of significant edits tobe correct in most cases, however this is a more subjective measurewhich we plan to evaluate further in future work.'
p4241
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4242
(dp4243
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p4244
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4245
(dp4246
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. That is, weuse information from the revisions up to revision \\(t\\) to predictwhether a paragraph will change significantly in revisions \\(t+1\\) to\\(t+10\\). The second measure tests whether the two paragraphs arerelated by edit patterns ten versions after the significant change, thatis, whether they keep changing together (or remain unchanged together)more than half the time in revisions \\(t+1\\) to \\(t+10\\). This secondmeasure is a stronger indication of a possible interdependency betweenthe paragraphs than the first measure.'
p4247
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4248
(dp4249
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p4250
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4251
(dp4252
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We also computed this measurefor the original paragraph as well as randomly sampled paragraphs andfound a significantly lower likelihood than for paragraphs related byedit similarity. For this measure, the relationship of topic similaritystill needs to be evaluated.'
p4253
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4254
(dp4255
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topicsimilarity continued being modified (or unmodified) together in the next10 versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future) were not included in the set ofrelated paragraphs predicted by edit history and topic similarity.'
p4256
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4257
(dp4258
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p4259
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4260
(dp4261
g10
S'While the motivation for our work is supporting collaborating authors,the methods could also provide better support a single author.'
p4262
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4263
(dp4264
g10
S'In future work, we plan to incorporate information about author identityto design personalized alerts for authors depending on the edits theyhave made. For example, the paragraph tracking algorithm makes itpossible to create a list of authors who have contributed to a specificparagraph, which can be used to determine who to alert when significantedits that affect it occur. We also plan to develop additionalalgorithms for summarizing changes and investigate the use of algorithmsthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) inorder to alert authors to parts of the text that could be improved.'
p4265
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4266
(dp4267
g10
S"Finally, we plan to explore alternative interface designs for presentingthe information chosen by the algorithms for authors to consider. Wealso plan to incorporate explanations for system recommendations (e.g.,``we recommend reading the introduction because it is often editedfollowing edits to the results section'')."
p4268
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4269
(dp4270
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the NuanceFoundation. We thank Stuart Shieber for helpful discussions.'
p4271
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4272
sba(iversion
Version
p4273
(dp4274
g7
g8
(S'\x07\xdf\x02\x08\x02(\x1e\x01\x8a\x88'
tRp4275
sg10
S"af\n\nMany documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios were above a threshold of 0.4), we label the\nparagraph as an addition. If a paragraph in the old version is not\nmatched with any paragraphs in the new version, we consider it as\ndeleted. Figure~{[}fig:mapping{]} illustrates this algorithm: some\nparagraphs found clear matches (e.g., 0, 1, 2), while paragraph 11 from\nthe old version was deleted and 6, 9, 10, and 12 were added in the new\nversion.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backwards mapping of allows for more\nrobust detection of paragraph movement even when there are significant\nchanges to the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity in the was above an empirically determined threshold of 0.4.\n(There are rarely paragraphs with a higher similarity than 0.4, while a\nlower similarity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, however this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time point to predict changes in revisions \\(d_{t+1}\\) to\n\\(d_{t+10}\\).\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed this measure for the\noriginal paragraph as well as randomly sampled paragraphs and found a\nsignificantly lower likelihood than for paragraphs related by edit\nsimilarity.\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider, and ways to\nincorporate explanations for system recommendations (e.g., ``we\nrecommend reading the introduction because it is often edited following\nedits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4276
sg12
(lp4277
(iversion
Paragraph
p4278
(dp4279
g10
S"afMany documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of the these methods shows promising results."
p4280
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4281
(dp4282
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p4283
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4284
(dp4285
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of drawing authors' attentionto edits that are important and relevant for them, and of pointing outother parts of the document that are likely to require further editing."
p4286
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4287
(dp4288
g10
S'Systems with such capabilities have the potential to improve coherenceof documents and coordination among authors while reducing the amount ofcommunication required between authors. An empirical evaluation of theproposed approach on a corpus of Wikipedia articles shows promisinginitial results.'
p4289
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4290
(dp4291
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p4292
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4293
(dp4294
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p4295
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4296
(dp4297
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p4298
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4299
(dp4300
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. Thus, we developed an algorithm for tracking paragraphs acrossrevisions. The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio (LR) measure, which isdefined as follows:\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0indicates the opposite. For each revision of a document, the algorithmcomputes the LR between each paragraph in the current version and eachparagraph in the previous version. Two paragraphs are mapped across therevision if they each have the highest LR with the other. If a paragraphin the new version has no matching paragraphs in the old version (i.e.,none of its ratios were above a threshold of 0.4), we label theparagraph as an addition. If a paragraph in the old version is notmatched with any paragraphs in the new version, we consider it asdeleted. Figure~{[}fig:mapping{]} illustrates this algorithm: someparagraphs found clear matches (e.g., 0, 1, 2), while paragraph 11 fromthe old version was deleted and 6, 9, 10, and 12 were added in the newversion.'
p4301
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4302
(dp4303
g10
S'While Wikipedia provides a diff visualization using an algorithm thatmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},the use of LR with forward and backwards mapping of allows for morerobust detection of paragraph movement even when there are significantchanges to the content.'
p4304
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4305
(dp4306
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach which computes the cosine similarity between wordvectors that represent the two versions of a paragraph. Specifically, weuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), whichaccounts for synonyms and does not penalize typographical errors. If thecosine similarity between new and old versions of a paragraph is below athreshold of 0.8, we consider the edit significant. The threshold of 0.8was determined empirically by manually evaluating differences betweenparagraphs with varied similarity values."
p4307
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4308
(dp4309
g10
S"We chose a topic modeling approach for this task because, in contrastwith the LR approach used for mapping paragraphs, topic modelingconsiders the content of the text. To illustrate, if two of aparagraph's sentences switch places, the LR would decrease despite nomeaningful change in content. On the other hand, changing a couple ofkey words will slightly lower the LR, but could drastically affect thecontent."
p4310
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4311
(dp4312
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould prompt edits in related paragraphs and investigated whichparagraphs are likely to change in future revisions as a result of suchedits.'
p4313
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4314
(dp4315
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed getting ameaningful signal of correlation between edits, while not looking toofar in the past when the content might have been significantlydifferent. For (3), we labeled pairs as related if their cosinesimilarity in the was above an empirically determined threshold of 0.4.'
p4316
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4317
(dp4318
g10
S'(There are rarely paragraphs with a higher similarity than 0.4, while alower similarity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p4319
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4320
(dp4321
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p4322
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4323
(dp4324
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p4325
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4326
(dp4327
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p4328
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4329
(dp4330
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8 we labeled about 15\\% of the edits assignificant.'
p4331
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4332
(dp4333
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random editedmapped paragraphs to ensure that paragraphs were correctly mapped andwhether the method successfully classified edits as significant orinsignificant. Figure~{[}fig:pars{]} shows an example of a significantedit: while the bottom paragraph is clearly a revision of the sameparagraph (recurring text shown in bold), the edit is significantbecause it adds new content and alters the tone of the text. Overall, wefound that paragraphs were rarely mapped incorrectly (less than\\(5\\%\\)), even when their content (as measured by topic similarity)changed significantly. Similarly, we found the classification ofsignificant edits to be correct in most cases, however this is a moresubjective measure which we plan to evaluate further in future work.'
p4334
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4335
(dp4336
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p4337
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4338
(dp4339
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they keepchanging together (or remain unchanged together) more than half the timein the following 10 revisions. This second measure provides a strongerindication of a possible interdependency between the paragraphs. Tocompute these measures, we iterate over all the revisions of each of thedocuments \\(d\\), and for each revision \\(d_t\\) we use only informationknown at that time point to predict changes in revisions \\(d_{t+1}\\) to\\(d_{t+10}\\).'
p4340
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4341
(dp4342
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p4343
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4344
(dp4345
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We computed this measure for theoriginal paragraph as well as randomly sampled paragraphs and found asignificantly lower likelihood than for paragraphs related by editsimilarity.'
p4346
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4347
(dp4348
g10
S'With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topicsimilarity continued being modified (or unmodified) together in the next10 versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future) were not included in the set ofrelated paragraphs predicted by edit history and topic similarity.'
p4349
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4350
(dp4351
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p4352
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4353
(dp4354
g10
S"In future work, we will incorporate information about author identity todesign personalized alerts for authors depending on the edits they havemade. We also plan to develop additional algorithms for summarizingchanges and investigate the use of algorithms that measure textcoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alertauthors to parts of the text that could be improved. Finally, we willexplore alternative interface designs for presenting the informationchosen by the algorithms for authors to consider, and ways toincorporate explanations for system recommendations (e.g., ``werecommend reading the introduction because it is often edited followingedits to the results section'')."
p4355
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4356
(dp4357
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the NuanceFoundation. We thank Stuart Shieber for helpful discussions.'
p4358
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4359
sba(iversion
Version
p4360
(dp4361
g7
g8
(S'\x07\xdf\x02\x08\x03"(\r\xa8\x18'
tRp4362
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios were above a threshold of 0.4), we label the\nparagraph as an addition. If a paragraph in the old version is not\nmatched with any paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8, we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and whether the method\nsuccessfully classified edits as significant or insignificant.\nFigure~{[}fig:pars{]} shows an example of a significant edit: while the\nbottom paragraph is clearly a revision of the same paragraph (recurring\ntext shown in bold), the edit is significant because it adds new content\nand alters the tone of the text. Overall, we found that paragraphs were\nrarely mapped incorrectly (less than \\(5\\%\\)), even when their content\n(as measured by topic similarity) changed significantly. Similarly, we\nfound the classification of significant edits to be correct in most\ncases, though this is a more subjective measure which we plan to\nevaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time to predict changes in revisions \\(d_{t+1}\\) to\n\\(d_{t+10}\\).\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed this measure for the\noriginal paragraph as well as randomly sampled paragraphs and found a\nsignificantly lower likelihood than for paragraphs related by edit\nsimilarity.\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider, and ways to\nincorporate explanations for system recommendations (e.g., ``we\nrecommend reading the introduction because it is often edited following\nedits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4363
sg12
(lp4364
(iversion
Paragraph
p4365
(dp4366
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of these methods shows promising results."
p4367
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4368
(dp4369
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p4370
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4371
(dp4372
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of (1) drawing authors'attention to edits that are important and relevant for them, and (2)pointing out other parts of the document that are likely to requirefurther editing. Systems with such capabilities have the potential toimprove coherence of documents and coordination among authors whilereducing the amount of communication required between authors. Anempirical evaluation of the proposed approach on a corpus of Wikipediaarticles shows promising initial results."
p4373
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4374
(dp4375
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and help co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p4376
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4377
(dp4378
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p4379
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4380
(dp4381
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p4382
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4383
(dp4384
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. Thus, we developed an algorithm for tracking paragraphs acrossrevisions. The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio (LR) measure, which isdefined as follows:\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0indicates the opposite. For each revision of a document, the algorithmcomputes the LR between each paragraph in the current version and eachparagraph in the previous version. Two paragraphs are mapped across therevision if they each have the highest LR with the other. If a paragraphin the new version has no matching paragraphs in the old version (i.e.,none of its ratios were above a threshold of 0.4), we label theparagraph as an addition. If a paragraph in the old version is notmatched with any paragraphs in the new version, we consider it deleted.'
p4385
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4386
(dp4387
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p4388
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4389
(dp4390
g10
S'While Wikipedia provides a diff visualization using an algorithm thatmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},the use of LR with forward and backward mapping allows for more robustdetection of paragraph movement even when there are significant changesto the content.'
p4391
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4392
(dp4393
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in theparagraph's topic and content. To detect such changes, we use a topicmodeling approach which computes the cosine similarity between wordvectors that represent the two versions of a paragraph. Specifically, weuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), whichaccounts for synonyms and does not penalize typographical errors. If thecosine similarity between new and old versions of a paragraph is below athreshold of 0.8, we consider the edit significant. The threshold of 0.8was determined empirically by manually evaluating differences betweenparagraphs with varied similarity values."
p4394
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4395
(dp4396
g10
S"We chose a topic modeling approach for this task because, in contrastwith the LR approach used for mapping paragraphs, topic modelingconsiders the content of the text. To illustrate, if two of aparagraph's sentences switch places, the LR would decrease despite nomeaningful change in content. On the other hand, changing a couple ofkey words will slightly lower the LR, but could drastically affect thecontent."
p4397
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4398
(dp4399
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould prompt edits in related paragraphs, and investigated whichparagraphs are likely to change in future revisions as a result of suchedits.'
p4400
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4401
(dp4402
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed us to obtaina meaningful signal of correlation between edits, while not looking toofar in the past where the content might be significantly different. For(3), we labeled pairs as related if their cosine similarity was above anempirically determined threshold of 0.4. (There are rarely paragraphswith a higher similarity than 0.4, while a lower similarity does notreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p4403
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4404
(dp4405
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p4406
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4407
(dp4408
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p4409
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4410
(dp4411
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p4412
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4413
(dp4414
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8, we labeled about 15\\% of the edits assignificant.'
p4415
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4416
(dp4417
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphsto ensure that paragraphs were correctly mapped and whether the methodsuccessfully classified edits as significant or insignificant.'
p4418
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4419
(dp4420
g10
S'Figure~{[}fig:pars{]} shows an example of a significant edit: while thebottom paragraph is clearly a revision of the same paragraph (recurringtext shown in bold), the edit is significant because it adds new contentand alters the tone of the text. Overall, we found that paragraphs wererarely mapped incorrectly (less than \\(5\\%\\)), even when their content(as measured by topic similarity) changed significantly. Similarly, wefound the classification of significant edits to be correct in mostcases, though this is a more subjective measure which we plan toevaluate further in future work.'
p4421
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4422
(dp4423
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p4424
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4425
(dp4426
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they keepchanging together (or remain unchanged together) more than half the timein the following 10 revisions. This second measure provides a strongerindication of a possible interdependency between the paragraphs. Tocompute these measures, we iterate over all the revisions of each of thedocuments \\(d\\), and for each revision \\(d_t\\) we use only informationknown at that time to predict changes in revisions \\(d_{t+1}\\) to\\(d_{t+10}\\).'
p4427
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4428
(dp4429
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p4430
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4431
(dp4432
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We computed this measure for theoriginal paragraph as well as randomly sampled paragraphs and found asignificantly lower likelihood than for paragraphs related by editsimilarity.'
p4433
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4434
(dp4435
g10
S'With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topicsimilarity continued being modified (or unmodified) together in the next10 versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future) were not included in the set ofrelated paragraphs predicted by edit history and topic similarity.'
p4436
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4437
(dp4438
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p4439
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4440
(dp4441
g10
S"In future work, we will incorporate information about author identity todesign personalized alerts for authors depending on the edits they havemade. We also plan to develop additional algorithms for summarizingchanges and investigate the use of algorithms that measure textcoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alertauthors to parts of the text that could be improved. Finally, we willexplore alternative interface designs for presenting the informationchosen by the algorithms for authors to consider, and ways toincorporate explanations for system recommendations (e.g., ``werecommend reading the introduction because it is often edited followingedits to the results section'')."
p4442
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4443
(dp4444
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the NuanceFoundation. We thank Stuart Shieber for helpful discussions.'
p4445
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4446
sba(iversion
Version
p4447
(dp4448
g7
g8
(S"\x07\xde\x0c\x0e\x12\r'\x03\xdcH"
tRp4449
sg10
S"\\section{Introduction}\\label{introduction}\n\nMaybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikis\n\nnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision Activity\n\nWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nThe system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.\n\nINSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes~\\footnote{We\n  defined minor edits as having a Levenshtein distance of under fifteen.}\nwere eliminated as well. This resulted in a total of 17,199 versions\nacross the 41 articles, with an average length of 25.71 paragraphs.\nWikipedia data affords results applicable to other collaborative writing\nspaces, because although the average article has over 400 contributing\nauthors, most of these authors make a one-time change. In fact, on\naverage, 15 authors make 80\\% of the edits to an article (see\nFigure~{[}fig:authors{]}). This enables the consideration of\ninteractions between authors, which is crucial for learning about\ncollaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nThis method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}..\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Topic Similarity \\&\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p4450
sg12
(lp4451
(iversion
Paragraph
p4452
(dp4453
g10
S'\\section{Introduction}\\label{introduction}Maybe one paragraph (previous years talk about motivation in similarwork in intro and have one-two paragraphs in a background/related worksection) about how previous work tried to come up with frameworks tosupport writers and tried to investigate the writers problems. Theydescribe the motivation and the need for such a system: * TrackingChanges in Collaborative Writing: Edits, Visibility and GroupMaintenance Old examples: * Quilt: A collaborative tool for cooperativewriting - 1988 * User-centred iterative design of collaborative software-1993 * what do co-authors use? * They try to find relevant changes: *Flexible Diff-ing in a collaborative writing system * What did they do?'
p4454
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4455
(dp4456
g10
S'Deriving High-Level edit histories in Wikisnewer examples also try to classify changes: * How a Structured DocumentModel Can Support Awareness in Collaborative Authoring * A framework forasynchronous change awareness in collaborative documents and workspaces* some try to find conflicts (different definition of conflict though):* Enabling truly collaborative writing on a computer * and some try tofind an explicit structur in texts: * A narrative-based collaborativewriting tool for constructing coherent technical documents * trying topredict: * WikiChanges - Exposing Wikipedia Revision ActivityWhen authors collaborate to write a paper, they need to communicateconstantly to ensure that they are all on the same page. Because theauthors need to make sure that their edits are coherent with the rest ofthe paper, including sections written by others, they need to read theentire paper frequently, or rely on updates communicated by theircoauthors. Even with constant communication, authors can get lost in thevolume of edits from other collaborators. Therefore, an assistive systemwith a summary of the significant changes contributed by other authorswould be helpful. We hypothesize that when an author makes a significantedit to a paragraph, it eventually triggers a series of adjustments inrelated paragraphs. Before these adjustments occur, semantic conflictsmight occur between authors. We wanted a collaborative writing system toalso predict when and where these conflicts may occur, in order to alerteven more specifically.'
p4457
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4458
(dp4459
g10
S'The system is composed of the following three components: (1) trackingparagraphs; (2) identifying significant changes to paragraphs, and (3)predicting future changes to the article. Tracking paragraphs throughpaper revisions is a core capability required for monitoring changes andpredicting them. The identification of significant content changes isimportant for a system to understand how important different changes areand whether collaborating authors should be notified. Predicting futurechanges enables the system to not only report to authors about changesthat have already been made, but also draw their attention to otherparts of the document that might require changes as a result of thechanges made.'
p4460
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4461
(dp4462
g10
S"INSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changesin related paragraphs eighty percent of the time{]}, but incollaborative writing, these resulting edits do not occurinstantaneously. Instead of waiting for other authors to discover theinconsistency caused by one author's edit, we want an assistive systemthat can alert relevant authors about paragraphs that might need anadditional look as a result of an edit."
p4463
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4464
(dp4465
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a widevariety of Wikipedia articles that undergo intense editing processes.'
p4466
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4467
(dp4468
g10
S'Wikipedia is a unique source because it presents extensive data forcollaborative writing. The findings use the complete revision revisionhistory of 41 different articles chosen from a diverse set of topics,from famous people and places to mathematical algorithms to novels. Therevision histories were downloaded as raw xml data. We removedWikipedia-specific tags that indicate formatting and other irrelevantdata, and eliminated versions of the articles under 150 characters, asthey did not contain enough information. To focus only on revisions withconsequential changes, the versions with simple typo fixes~\\footnote{We  defined minor edits as having a Levenshtein distance of under fifteen.}were eliminated as well. This resulted in a total of 17,199 versionsacross the 41 articles, with an average length of 25.71 paragraphs.'
p4469
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4470
(dp4471
g10
S'Wikipedia data affords results applicable to other collaborative writingspaces, because although the average article has over 400 contributingauthors, most of these authors make a one-time change. In fact, onaverage, 15 authors make 80\\% of the edits to an article (seeFigure~{[}fig:authors{]}). This enables the consideration ofinteractions between authors, which is crucial for learning aboutcollaborative behavior.'
p4472
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4473
(dp4474
g10
S'\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein editratio measure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)This method differed from previous attempts in the sense that it tracksparagraphs as a whole instead of just the longest common subsequence asused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.'
p4475
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4476
(dp4477
g10
S'A Levenshtein ratio close to one between two paragraphs indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision, we computed the Levenshtein ratio betweeneach paragraph in the old version and each paragraph in the new version.'
p4478
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4479
(dp4480
g10
S"Two paragraphs are mapped across the revision if they each had thehighest Levenshtein ratio for the other. If a paragraph in the newversion had no ``matches'', meaning that none of its ratios were above athreshold of 0.4, this paragraph was new. If a paragraph in the oldversion had no ``matches'', then it was deleted in the revision."
p4481
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4482
(dp4483
g10
S'Figure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10and 12 of the old version were deleted, while the others found clearmatches.'
p4484
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4485
(dp4486
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph'stopic and content. For this calculation, the Levenshtein ratio does notprovide the right kind of information. For example, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple key words will slightly lower the Levenshtein ratio,but could drastically affect the content."
p4487
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4488
(dp4489
g10
S"As shown in figure 1, which shows the distribution of the differencesbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshteinand LSI ratios demonstrate very different statistics. {[}INSERTFIGURE{]}Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Latent Semantic Indexing is a form oftopic modeling that calculates the topic similarity between two texts."
p4490
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4491
(dp4492
g10
S"Its strengths lie in accounting for synonyms and not penalizing fortypographical errors. The process begins by composing a corpus for eachWikipedia article from all of the documents (paragraphs of the versionsof the article). It analyzes tokens (a specific instance of a word),eliminating those that only occur once, as well as stopword tokens, suchas `the' or `and'. It then creates a TF-IDF matrix, which assigns aweight to every token in each document, which indicates the importanceof that token for this document. This weight increases proportionally tothe frequency of the word in the document, but accounts for thefrequency of the word in the corpus, such that the frequent occurrenceof a usually uncommon word is given a larger weight to signify thisimportance."
p4493
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4494
(dp4495
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p4496
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4497
(dp4498
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p4499
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4500
(dp4501
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p4502
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4503
(dp4504
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p4505
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4506
(dp4507
g10
S'Therefore, in order to predict future conflicts, an assistive systemneeds to detect significant changes and then determine consequentlywhich paragraphs were most likely to change.'
p4508
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4509
(dp4510
g10
S'We looked at three possible types of inter-paragraph relationships.'
p4511
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4512
(dp4513
g10
S'Paragraphs could be related by physical proximity: perhaps theneighboring paragraphs would require adjustments, as they are likelypart of the same section. Paragraphs could also be related by topic. Forexample, in an academic paper, the discussion section and the conclusionshould present similar themes. If one changes, the other may need to beedited to reflect this change. For each significant change, we used theexisting LSI Topic Model to determine which paragraphs discussed similartopics. Lastly, paragraphs could be related because of similar edithistories. For each significant change, we evaluated the edit history ofthis paragraph with every other paragraph in the article. We labeledpairs as related if they changed or remained unchanged together overhalf the time. With a higher threshold, the sample size decreases, butwith a lower threshold, the results become less predictive of asignificant change prompting further edits. This threshold strikes abalance between these two outcomes.'
p4514
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4515
(dp4516
g10
S"To evaluate these both of these suspected relationships, we looked atthe related paragraphs' edit patterns in the ten versions following thesignificant change. If the related paragraphs changed together over halfthe time, the paragraphs with this relationship proved to be related inthe future, verifying the relationship at the time of the significantchange."
p4517
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4518
(dp4519
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutiveversions of a paper, we calculated the number of versions from theparagraphs' inception to its demise. On average, paragraphs lasted 83article revisions."
p4520
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4521
(dp4522
g10
S'\\subsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}..'
p4523
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4524
(dp4525
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p4526
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4527
(dp4528
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p4529
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4530
(dp4531
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, when aparagraph is edited for the first time in a while, further adjustmentsare triggered in the near future.'
p4532
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4533
(dp4534
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\Caption: After a significant change at version 0, consequent edits aremore frequent.'
p4535
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4536
(dp4537
g10
S'We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p4538
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4539
(dp4540
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p4541
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4542
(dp4543
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times of at least one significant change}\\\\EditHistory \\& 81\\%\\\\Topic Similarity \\&\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\Relationship or Control Percentage of times that paragraph experiencedat least one significant change Edit History 81\\% Topic Similarity .'
p4544
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4545
(dp4546
g10
S'Physical Proximity 24\\% Paragraph with original significant change 40\\%Random Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p4547
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4548
(dp4549
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endheadTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewlineEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewlineProximity? & ? & ? & ?\\tabularnewline\\bottomrule\\end{longtable}Relationship Number Found Successfully Linked Ratio of SuccessfullyLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,68571\\%Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p4550
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4551
(dp4552
g10
S'The correlation coefficient was 0.99 for all numbers.'
p4553
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4554
(dp4555
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p4556
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4557
(dp4558
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p4559
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4560
(dp4561
g10
S'We imagine a couple other helpful components for an assistive systemthat our methods could provide the foundation for. Using text summaryalgorithms, the system could provide a succinct textual summary ofsignificant changes already detected. The system could also \\ldots{}.'
p4562
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4563
(dp4564
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determiningwhether a paragraph will change together in the future. Consequently, weassert that if significant edit occurs, related paragraphs should alsobe edited. A proposed assistive system will alert the relevant authorsof related paragraphs if this resulting edit does not occur. Bydetecting relationships between paragraphs in a multi-authored paper,our system can predict and alert appropriate authors if a significantchange has the potential to create a semantic conflict within the paper.'
p4565
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4566
sba(iversion
Version
p4567
(dp4568
g7
g8
(S'\x07\xdf\x02\x08\x171\r\x02\x80\xa0'
tRp4569
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such changes, we\nuse a topic modeling approach which computes the cosine similarity\nbetween word vectors that represent the two versions of a paragraph.\nSpecifically, we use (LSI), which accounts for synonyms and does not\npenalize typographical errors. If the cosine similarity between new and\nold versions of a paragraph is below a threshold of 0.8, we consider the\nedit significant. The threshold of 0.8 was determined empirically by\nmanually evaluating differences between paragraphs with varied\nsimilarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8, we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time to predict changes in revisions \\(d_{t+1}\\) to\n\\(d_{t+10}\\).\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed this measure for the\noriginal paragraph as well as randomly sampled paragraphs and found a\nsignificantly lower likelihood than for paragraphs related by edit\nsimilarity.\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future){[}b{]} were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider, and ways to\nincorporate explanations for system recommendations (e.g., ``we\nrecommend reading the introduction because it is often edited following\nedits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4570
sg12
(lp4571
(iversion
Paragraph
p4572
(dp4573
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of these methods shows promising results."
p4574
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4575
(dp4576
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p4577
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4578
(dp4579
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of (1) drawing authors'attention to edits that are important and relevant for them, and (2)pointing out other parts of the document that are likely to requirefurther editing. Systems with such capabilities have the potential toimprove coherence of documents and coordination among authors whilereducing the amount of communication required between authors. Anempirical evaluation of the proposed approach on a corpus of Wikipediaarticles shows promising initial results."
p4580
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4581
(dp4582
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and helping co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p4583
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4584
(dp4585
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p4586
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4587
(dp4588
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p4589
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4590
(dp4591
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. Thus, we developed an algorithm for tracking paragraphs acrossrevisions. The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio (LR) measure, which isdefined as follows:\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0indicates the opposite. For each revision of a document, the algorithmcomputes the LR between each paragraph in the current version and eachparagraph in the previous version. Two paragraphs are mapped across therevision if they each have the highest LR with the other. If a paragraphin the new version has no matching paragraphs in the old version (i.e.,none of its ratios are above a threshold of 0.4), we label the paragraphas an addition. If a paragraph in the old version is not matched withany paragraphs in the new version, we consider it deleted.'
p4592
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4593
(dp4594
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p4595
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4596
(dp4597
g10
S'While Wikipedia provides a diff visualization using an algorithm thatmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},the use of LR with forward and backward mapping allows for more robustdetection of paragraph movement even when there are significant changesto the content.'
p4598
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4599
(dp4600
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a change to be significant if it results in a noticeablechange in the paragraph's topic and content. To detect such changes, weuse a topic modeling approach which computes the cosine similaritybetween word vectors that represent the two versions of a paragraph."
p4601
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4602
(dp4603
g10
S'Specifically, we use (LSI), which accounts for synonyms and does notpenalize typographical errors. If the cosine similarity between new andold versions of a paragraph is below a threshold of 0.8, we consider theedit significant. The threshold of 0.8 was determined empirically bymanually evaluating differences between paragraphs with variedsimilarity values.'
p4604
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4605
(dp4606
g10
S"We chose a topic modeling approach for this task because, in contrastwith the LR approach used for mapping paragraphs, topic modelingconsiders the content of the text. To illustrate, if two of aparagraph's sentences switch places, the LR would decrease despite nomeaningful change in content. On the other hand, changing a couple ofkey words will slightly lower the LR, but could drastically affect thecontent."
p4607
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4608
(dp4609
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould prompt edits in related paragraphs, and investigated whichparagraphs are likely to change in future revisions as a result of suchedits.'
p4610
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4611
(dp4612
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed us to obtaina meaningful signal of correlation between edits, while not looking toofar in the past where the content might be significantly different. For(3), we labeled pairs as related if their cosine similarity was above anempirically determined threshold of 0.4. (There are rarely paragraphswith a higher similarity than 0.4, while a lower similarity does notreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p4613
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4614
(dp4615
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p4616
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4617
(dp4618
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p4619
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4620
(dp4621
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p4622
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4623
(dp4624
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8, we labeled about 15\\% of the edits assignificant.'
p4625
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4626
(dp4627
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphsto ensure that paragraphs were correctly mapped and to determine whetherthe method successfully classified edits as significant orinsignificant. Figure~{[}fig:pars{]} shows an example of a significantedit: while the bottom paragraph is clearly a revision of the sameparagraph (recurring text shown in bold), the edit is significantbecause it adds new content and alters the tone of the text. Overall, wefound that paragraphs were rarely mapped incorrectly (less than\\(5\\%\\)), even when their content (as measured by topic similarity)changed significantly. Similarly, we found the classification ofsignificant edits to be correct in most cases, though this is a moresubjective measure which we plan to evaluate further in future work.'
p4628
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4629
(dp4630
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p4631
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4632
(dp4633
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they keepchanging together (or remain unchanged together) more than half the timein the following 10 revisions. This second measure provides a strongerindication of a possible interdependency between the paragraphs. Tocompute these measures, we iterate over all the revisions of each of thedocuments \\(d\\), and for each revision \\(d_t\\) we use only informationknown at that time to predict changes in revisions \\(d_{t+1}\\) to\\(d_{t+10}\\).'
p4634
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4635
(dp4636
g10
S'The frequency of occurrences of each type of inter-paragraphrelationship varied. On average, 1.6 pairs of paragraphs related by edithistory were found per revision of the text. A pair related by topicsimilarity was only found once every ten versions. Proximityrelationships always exist in each version, as each paragraph has atleast one neighboring paragraph (and most have two).'
p4637
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4638
(dp4639
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We computed this measure for theoriginal paragraph as well as randomly sampled paragraphs and found asignificantly lower likelihood than for paragraphs related by editsimilarity.'
p4640
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4641
(dp4642
g10
S'With respect to the second measure, we found that 71\\% of paragraphspairs related by edit history and 63\\% for pairs related by topicsimilarity continued being modified (or unmodified) together in the next10 versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related (based oninformation ten versions in the future){[}b{]} were not included in theset of related paragraphs predicted by edit history and topicsimilarity.'
p4643
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4644
(dp4645
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p4646
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4647
(dp4648
g10
S"In future work, we will incorporate information about author identity todesign personalized alerts for authors depending on the edits they havemade. We also plan to develop additional algorithms for summarizingchanges and investigate the use of algorithms that measure textcoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alertauthors to parts of the text that could be improved. Finally, we willexplore alternative interface designs for presenting the informationchosen by the algorithms for authors to consider, and ways toincorporate explanations for system recommendations (e.g., ``werecommend reading the introduction because it is often edited followingedits to the results section'')."
p4649
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4650
(dp4651
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the NuanceFoundation. We thank Stuart Shieber for helpful discussions.'
p4652
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4653
sba(iversion
Version
p4654
(dp4655
g7
g8
(S'\x07\xdf\x02\x08\x177\x15\x05\x10\xe0'
tRp4656
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such changes, we\nuse a topic modeling approach which computes the cosine similarity\nbetween word vectors that represent the two versions of a paragraph.\nSpecifically, we use (LSI), which accounts for synonyms and does not\npenalize typographical errors. If the cosine similarity between new and\nold versions of a paragraph is below a threshold of 0.8, we consider the\nedit significant. The threshold of 0.8 was determined empirically by\nmanually evaluating differences between paragraphs with varied\nsimilarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8, we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time (\\(t\\)) to predict changes in revisions \\(d_{t+1}\\)\nto \\(d_{t+10}\\).\n\nThe frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.\n\nWith respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4657
sg12
(lp4658
(iversion
Paragraph
p4659
(dp4660
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of these methods shows promising results."
p4661
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4662
(dp4663
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p4664
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4665
(dp4666
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of (1) drawing authors'attention to edits that are important and relevant for them, and (2)pointing out other parts of the document that are likely to requirefurther editing. Systems with such capabilities have the potential toimprove coherence of documents and coordination among authors whilereducing the amount of communication required between authors. Anempirical evaluation of the proposed approach on a corpus of Wikipediaarticles shows promising initial results."
p4667
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4668
(dp4669
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and helping co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p4670
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4671
(dp4672
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p4673
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4674
(dp4675
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p4676
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4677
(dp4678
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. Thus, we developed an algorithm for tracking paragraphs acrossrevisions. The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio (LR) measure, which isdefined as follows:\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0indicates the opposite. For each revision of a document, the algorithmcomputes the LR between each paragraph in the current version and eachparagraph in the previous version. Two paragraphs are mapped across therevision if they each have the highest LR with the other. If a paragraphin the new version has no matching paragraphs in the old version (i.e.,none of its ratios are above a threshold of 0.4), we label the paragraphas an addition. If a paragraph in the old version is not matched withany paragraphs in the new version, we consider it deleted.'
p4679
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4680
(dp4681
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p4682
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4683
(dp4684
g10
S'While Wikipedia provides a diff visualization using an algorithm thatmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},the use of LR with forward and backward mapping allows for more robustdetection of paragraph movement even when there are significant changesto the content.'
p4685
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4686
(dp4687
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a change to be significant if it results in a noticeablechange in the paragraph's topic and content. To detect such changes, weuse a topic modeling approach which computes the cosine similaritybetween word vectors that represent the two versions of a paragraph."
p4688
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4689
(dp4690
g10
S'Specifically, we use (LSI), which accounts for synonyms and does notpenalize typographical errors. If the cosine similarity between new andold versions of a paragraph is below a threshold of 0.8, we consider theedit significant. The threshold of 0.8 was determined empirically bymanually evaluating differences between paragraphs with variedsimilarity values.'
p4691
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4692
(dp4693
g10
S"We chose a topic modeling approach for this task because, in contrastwith the LR approach used for mapping paragraphs, topic modelingconsiders the content of the text. To illustrate, if two of aparagraph's sentences switch places, the LR would decrease despite nomeaningful change in content. On the other hand, changing a couple ofkey words will slightly lower the LR, but could drastically affect thecontent."
p4694
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4695
(dp4696
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould prompt edits in related paragraphs, and investigated whichparagraphs are likely to change in future revisions as a result of suchedits.'
p4697
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4698
(dp4699
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed us to obtaina meaningful signal of correlation between edits, while not looking toofar in the past where the content might be significantly different. For(3), we labeled pairs as related if their cosine similarity was above anempirically determined threshold of 0.4. (There are rarely paragraphswith a higher similarity than 0.4, while a lower similarity does notreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p4700
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4701
(dp4702
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p4703
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4704
(dp4705
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p4706
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4707
(dp4708
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p4709
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4710
(dp4711
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold ratio of 0.8, we labeled about 15\\% of the edits assignificant.'
p4712
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4713
(dp4714
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphsto ensure that paragraphs were correctly mapped and to determine whetherthe method successfully classified edits as significant orinsignificant. Figure~{[}fig:pars{]} shows an example of a significantedit: while the bottom paragraph is clearly a revision of the sameparagraph (recurring text shown in bold), the edit is significantbecause it adds new content and alters the tone of the text. Overall, wefound that paragraphs were rarely mapped incorrectly (less than\\(5\\%\\)), even when their content (as measured by topic similarity)changed significantly. Similarly, we found the classification ofsignificant edits to be correct in most cases, though this is a moresubjective measure which we plan to evaluate further in future work.'
p4715
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4716
(dp4717
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p4718
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4719
(dp4720
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will needattention. The first checks whether the related paragraphs underwent atleast one significant change within the next ten versions. The secondmeasure tests whether the two paragraphs are related by edit patternsten versions after the significant change, that is, whether they keepchanging together (or remain unchanged together) more than half the timein the following 10 revisions. This second measure provides a strongerindication of a possible interdependency between the paragraphs. Tocompute these measures, we iterate over all the revisions of each of thedocuments \\(d\\), and for each revision \\(d_t\\) we use only informationknown at that time (\\(t\\)) to predict changes in revisions \\(d_{t+1}\\)to \\(d_{t+10}\\).'
p4721
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4722
(dp4723
g10
S'The frequency of occurrence of each type of inter-paragraph relationshipvaried. On average, 1.6 pairs of paragraphs related by edit history werefound per revision of the text. A pair related by topic similarity wasonly found once every ten versions. Proximity relationships always existin each version, as each paragraph has at least one neighboringparagraph (and most have two).'
p4724
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4725
(dp4726
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We computed the proximitymeasure for the original paragraph as well as randomly sampledparagraphs and found a significantly lower likelihood than forparagraphs related by edit similarity.'
p4727
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4728
(dp4729
g10
S'With respect to the second measure, we found that 71\\% of paragraphpairs related by edit history and 63\\% related by topic similaritycontinued being modified (or unmodified) together in the next 10versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related were not included inthe set of related paragraphs predicted by edit history and topicsimilarity.'
p4730
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4731
(dp4732
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p4733
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4734
(dp4735
g10
S"In future work, we will incorporate information about author identity todesign personalized alerts for authors depending on the edits they havemade. We also plan to develop additional algorithms for summarizingchanges and to investigate the use of algorithms that measure textcoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alertauthors to parts of the text that could be improved. Finally, we willexplore alternative interface designs for presenting the informationchosen by the algorithms for authors to consider and ways to incorporateexplanations for system recommendations (e.g., ``we recommend readingthe introduction because it is often edited following edits to theresults section'')."
p4736
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4737
(dp4738
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the NuanceFoundation. We thank Stuart Shieber for helpful discussions.'
p4739
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4740
sba(iversion
Version
p4741
(dp4742
g7
g8
(S'\x07\xdf\x02\t\x11%)\x04\xe5\xe8'
tRp4743
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such change, we\ncompute the cosine similarity between word vectors that represent the\ntwo versions of a paragraph, using a Latent Semantic Indexing topic\nmodeling approach~\\cite{deerwester1990indexing}. If the cosine\nsimilarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of topic similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold of 0.8, we labeled about 15\\% of the edits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nTo evaluate the accuracy of the prediction, we iterate over all the\nrevisions of each of the documents \\(d\\), and for each revision \\(d_t\\)\nwe use only information known at that time (\\(t\\)) to predict changes in\nrevisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two measures that\nmight indicate that a paragraph will need attention: (1) whether\nparagraphs related to a ``triggering paragraph'' that changed\nsignificantly in revision \\(d_t\\) underwent at least one significant\nchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2) whether those\nparagraphs continue to be related by edit patterns to the triggering\nparagraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is, whether\nthey keep changing together (or remain unchanged together) more than\nhalf the time in the following 10 revisions. This second measure\nprovides a stronger indication of a possible interdependency between the\nparagraphs.\n\nThe frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.\n\nWith respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4744
sg12
(lp4745
(iversion
Paragraph
p4746
(dp4747
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of these methods shows promising results."
p4748
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4749
(dp4750
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p4751
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4752
(dp4753
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of (1) drawing authors'attention to edits that are important and relevant for them, and (2)pointing out other parts of the document that are likely to requirefurther editing. Systems with such capabilities have the potential toimprove coherence of documents and coordination among authors whilereducing the amount of communication required between authors. Anempirical evaluation of the proposed approach on a corpus of Wikipediaarticles shows promising initial results."
p4754
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4755
(dp4756
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and helping co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p4757
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4758
(dp4759
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p4760
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4761
(dp4762
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p4763
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4764
(dp4765
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. Thus, we developed an algorithm for tracking paragraphs acrossrevisions. The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio (LR) measure, which isdefined as follows:\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0indicates the opposite. For each revision of a document, the algorithmcomputes the LR between each paragraph in the current version and eachparagraph in the previous version. Two paragraphs are mapped across therevision if they each have the highest LR with the other. If a paragraphin the new version has no matching paragraphs in the old version (i.e.,none of its ratios are above a threshold of 0.4), we label the paragraphas an addition. If a paragraph in the old version is not matched withany paragraphs in the new version, we consider it deleted.'
p4766
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4767
(dp4768
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p4769
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4770
(dp4771
g10
S'While Wikipedia provides a diff visualization using an algorithm thatmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},the use of LR with forward and backward mapping allows for more robustdetection of paragraph movement even when there are significant changesto the content.'
p4772
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4773
(dp4774
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a change to be significant if it results in a noticeablechange in the paragraph's topic and content. To detect such change, wecompute the cosine similarity between word vectors that represent thetwo versions of a paragraph, using a Latent Semantic Indexing topicmodeling approach~\\cite{deerwester1990indexing}. If the cosinesimilarity between new and old versions of a paragraph is below athreshold of 0.8, we consider the edit significant. The threshold of 0.8was determined empirically by manually evaluating differences betweenparagraphs with varied similarity values."
p4775
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4776
(dp4777
g10
S"We chose a topic modeling approach for this task because, in contrastwith the LR approach used for mapping paragraphs, topic modelingconsiders the content of the text. To illustrate, if two of aparagraph's sentences switch places, the LR would decrease despite nomeaningful change in content. On the other hand, changing a couple ofkey words will slightly lower the LR, but could drastically affect thecontent."
p4778
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4779
(dp4780
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould prompt edits in related paragraphs, and investigated whichparagraphs are likely to change in future revisions as a result of suchedits.'
p4781
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4782
(dp4783
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed us to obtaina meaningful signal of correlation between edits, while not looking toofar in the past where the content might be significantly different. For(3), we labeled pairs as related if their cosine similarity was above anempirically determined threshold of 0.4. (There are rarely paragraphswith a higher similarity than 0.4, while a lower similarity does notreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p4784
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4785
(dp4786
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p4787
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4788
(dp4789
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p4790
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4791
(dp4792
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p4793
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4794
(dp4795
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of topic similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold of 0.8, we labeled about 15\\% of the edits as significant.'
p4796
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4797
(dp4798
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphsto ensure that paragraphs were correctly mapped and to determine whetherthe method successfully classified edits as significant orinsignificant. Figure~{[}fig:pars{]} shows an example of a significantedit: while the bottom paragraph is clearly a revision of the sameparagraph (recurring text shown in bold), the edit is significantbecause it adds new content and alters the tone of the text. Overall, wefound that paragraphs were rarely mapped incorrectly (less than\\(5\\%\\)), even when their content (as measured by topic similarity)changed significantly. Similarly, we found the classification ofsignificant edits to be correct in most cases, though this is a moresubjective measure which we plan to evaluate further in future work.'
p4799
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4800
(dp4801
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p4802
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4803
(dp4804
g10
S"\\includegraphics{figs/parChangesNew.pdf}\\\\To evaluate the accuracy of the prediction, we iterate over all therevisions of each of the documents \\(d\\), and for each revision \\(d_t\\)we use only information known at that time (\\(t\\)) to predict changes inrevisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two measures thatmight indicate that a paragraph will need attention: (1) whetherparagraphs related to a ``triggering paragraph'' that changedsignificantly in revision \\(d_t\\) underwent at least one significantchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2) whether thoseparagraphs continue to be related by edit patterns to the triggeringparagraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is, whetherthey keep changing together (or remain unchanged together) more thanhalf the time in the following 10 revisions. This second measureprovides a stronger indication of a possible interdependency between theparagraphs."
p4805
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4806
(dp4807
g10
S'The frequency of occurrence of each type of inter-paragraph relationshipvaried. On average, 1.6 pairs of paragraphs related by edit history werefound per revision of the text. A pair related by topic similarity wasonly found once every ten versions. Proximity relationships always existin each version, as each paragraph has at least one neighboringparagraph (and most have two).'
p4808
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4809
(dp4810
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We computed the proximitymeasure for the original paragraph as well as randomly sampledparagraphs and found a significantly lower likelihood than forparagraphs related by edit similarity.'
p4811
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4812
(dp4813
g10
S'With respect to the second measure, we found that 71\\% of paragraphpairs related by edit history and 63\\% related by topic similaritycontinued being modified (or unmodified) together in the next 10versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related were not included inthe set of related paragraphs predicted by edit history and topicsimilarity.'
p4814
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4815
(dp4816
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p4817
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4818
(dp4819
g10
S"In future work, we will incorporate information about author identity todesign personalized alerts for authors depending on the edits they havemade. We also plan to develop additional algorithms for summarizingchanges and to investigate the use of algorithms that measure textcoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alertauthors to parts of the text that could be improved. Finally, we willexplore alternative interface designs for presenting the informationchosen by the algorithms for authors to consider and ways to incorporateexplanations for system recommendations (e.g., ``we recommend readingthe introduction because it is often edited following edits to theresults section'')."
p4820
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4821
(dp4822
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the NuanceFoundation. We thank Stuart Shieber for helpful discussions.'
p4823
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4824
sba(iversion
Version
p4825
(dp4826
g7
g8
(S'\x07\xdf\x02\t\x12\n\x1b\x05\xa1h'
tRp4827
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such change, we\ncompute the cosine similarity between word vectors that represent the\ntwo versions of a paragraph, using a Latent Semantic Indexing topic\nmodeling approach~\\cite{deerwester1990indexing}. If the cosine\nsimilarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of topic similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold of 0.8, we labeled about 15\\% of the edits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nTo evaluate the accuracy of the predictions of paragraphs that will\nrequire attention following a significant edit to another paragraph, we\ncheck whether the predicted paragraphs undergo a significant change in\nconsequent revisions. Specifically, we iterate over all the revisions of\neach of the documents \\(d\\), and for each revision \\(d_t\\) we use only\ninformation known at that time (\\(t\\)) to predict paragraphs that will\nchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two\nmeasures: (1) whether paragraphs related to a ``triggering paragraph''\nthat changed significantly in revision \\(d_t\\) underwent at least one\nsignificant change in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2)\nwhether those paragraphs continue to be related by edit patterns to the\ntriggering paragraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is,\nwhether they keep changing together (or remain unchanged together) more\nthan half the time in the following 10 revisions. This second measure\nprovides a stronger indication of a possible interdependency between the\nparagraphs.\n\nThe frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.\n\nWith respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4828
sg12
(lp4829
(iversion
Paragraph
p4830
(dp4831
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of these methods shows promising results."
p4832
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4833
(dp4834
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p4835
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4836
(dp4837
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of (1) drawing authors'attention to edits that are important and relevant for them, and (2)pointing out other parts of the document that are likely to requirefurther editing. Systems with such capabilities have the potential toimprove coherence of documents and coordination among authors whilereducing the amount of communication required between authors. Anempirical evaluation of the proposed approach on a corpus of Wikipediaarticles shows promising initial results."
p4838
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4839
(dp4840
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and helping co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) and data miningmethods to automatically detect significant changes, without requiringauthors to specify explicitly what changes are of interest to them.'
p4841
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4842
(dp4843
g10
S'Furthermore, these capabilities go beyond prior approaches forsupporting change awareness in that they can predict parts of thedocument that have not changed but that are likely to require edits as aresult of other changes.'
p4844
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4845
(dp4846
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p4847
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4848
(dp4849
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. Thus, we developed an algorithm for tracking paragraphs acrossrevisions. The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio (LR) measure, which isdefined as follows:\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0indicates the opposite. For each revision of a document, the algorithmcomputes the LR between each paragraph in the current version and eachparagraph in the previous version. Two paragraphs are mapped across therevision if they each have the highest LR with the other. If a paragraphin the new version has no matching paragraphs in the old version (i.e.,none of its ratios are above a threshold of 0.4), we label the paragraphas an addition. If a paragraph in the old version is not matched withany paragraphs in the new version, we consider it deleted.'
p4850
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4851
(dp4852
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p4853
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4854
(dp4855
g10
S'While Wikipedia provides a diff visualization using an algorithm thatmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},the use of LR with forward and backward mapping allows for more robustdetection of paragraph movement even when there are significant changesto the content.'
p4856
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4857
(dp4858
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a change to be significant if it results in a noticeablechange in the paragraph's topic and content. To detect such change, wecompute the cosine similarity between word vectors that represent thetwo versions of a paragraph, using a Latent Semantic Indexing topicmodeling approach~\\cite{deerwester1990indexing}. If the cosinesimilarity between new and old versions of a paragraph is below athreshold of 0.8, we consider the edit significant. The threshold of 0.8was determined empirically by manually evaluating differences betweenparagraphs with varied similarity values."
p4859
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4860
(dp4861
g10
S"We chose a topic modeling approach for this task because, in contrastwith the LR approach used for mapping paragraphs, topic modelingconsiders the content of the text. To illustrate, if two of aparagraph's sentences switch places, the LR would decrease despite nomeaningful change in content. On the other hand, changing a couple ofkey words will slightly lower the LR, but could drastically affect thecontent."
p4862
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4863
(dp4864
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould prompt edits in related paragraphs, and investigated whichparagraphs are likely to change in future revisions as a result of suchedits.'
p4865
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4866
(dp4867
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed us to obtaina meaningful signal of correlation between edits, while not looking toofar in the past where the content might be significantly different. For(3), we labeled pairs as related if their cosine similarity was above anempirically determined threshold of 0.4. (There are rarely paragraphswith a higher similarity than 0.4, while a lower similarity does notreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p4868
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4869
(dp4870
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p4871
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4872
(dp4873
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p4874
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4875
(dp4876
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p4877
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4878
(dp4879
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of topic similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold of 0.8, we labeled about 15\\% of the edits as significant.'
p4880
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4881
(dp4882
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphsto ensure that paragraphs were correctly mapped and to determine whetherthe method successfully classified edits as significant orinsignificant. Figure~{[}fig:pars{]} shows an example of a significantedit: while the bottom paragraph is clearly a revision of the sameparagraph (recurring text shown in bold), the edit is significantbecause it adds new content and alters the tone of the text. Overall, wefound that paragraphs were rarely mapped incorrectly (less than\\(5\\%\\)), even when their content (as measured by topic similarity)changed significantly. Similarly, we found the classification ofsignificant edits to be correct in most cases, though this is a moresubjective measure which we plan to evaluate further in future work.'
p4883
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4884
(dp4885
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p4886
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4887
(dp4888
g10
S"\\includegraphics{figs/parChangesNew.pdf}\\\\To evaluate the accuracy of the predictions of paragraphs that willrequire attention following a significant edit to another paragraph, wecheck whether the predicted paragraphs undergo a significant change inconsequent revisions. Specifically, we iterate over all the revisions ofeach of the documents \\(d\\), and for each revision \\(d_t\\) we use onlyinformation known at that time (\\(t\\)) to predict paragraphs that willchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at twomeasures: (1) whether paragraphs related to a ``triggering paragraph''that changed significantly in revision \\(d_t\\) underwent at least onesignificant change in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2)whether those paragraphs continue to be related by edit patterns to thetriggering paragraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is,whether they keep changing together (or remain unchanged together) morethan half the time in the following 10 revisions. This second measureprovides a stronger indication of a possible interdependency between theparagraphs."
p4889
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4890
(dp4891
g10
S'The frequency of occurrence of each type of inter-paragraph relationshipvaried. On average, 1.6 pairs of paragraphs related by edit history werefound per revision of the text. A pair related by topic similarity wasonly found once every ten versions. Proximity relationships always existin each version, as each paragraph has at least one neighboringparagraph (and most have two).'
p4892
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4893
(dp4894
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We computed the proximitymeasure for the original paragraph as well as randomly sampledparagraphs and found a significantly lower likelihood than forparagraphs related by edit similarity.'
p4895
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4896
(dp4897
g10
S'With respect to the second measure, we found that 71\\% of paragraphpairs related by edit history and 63\\% related by topic similaritycontinued being modified (or unmodified) together in the next 10versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related were not included inthe set of related paragraphs predicted by edit history and topicsimilarity.'
p4898
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4899
(dp4900
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p4901
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4902
(dp4903
g10
S"In future work, we will incorporate information about author identity todesign personalized alerts for authors depending on the edits they havemade. We also plan to develop additional algorithms for summarizingchanges and to investigate the use of algorithms that measure textcoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alertauthors to parts of the text that could be improved. Finally, we willexplore alternative interface designs for presenting the informationchosen by the algorithms for authors to consider and ways to incorporateexplanations for system recommendations (e.g., ``we recommend readingthe introduction because it is often edited following edits to theresults section'')."
p4904
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4905
(dp4906
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the NuanceFoundation. We thank Stuart Shieber for helpful discussions.'
p4907
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4908
sba(iversion
Version
p4909
(dp4910
g7
g8
(S'\x07\xdf\x02\t\x14/\x1c\x08\xd1\xd0'
tRp4911
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) methods to\nautomatically detect significant changes, without requiring authors to\nspecify explicitly what changes are of interest to them. Furthermore,\nthese capabilities go beyond prior approaches for supporting change\nawareness in that they can predict parts of the document that have not\nchanged but that are likely to require edits as a result of other\nchanges.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such change, we\ncompute the cosine similarity between word vectors that represent the\ntwo versions of a paragraph, using a Latent Semantic Indexing topic\nmodeling approach~\\cite{deerwester1990indexing}. If the cosine\nsimilarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold was\ndetermined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of topic similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold of 0.8, we labeled about 15\\% of the edits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nTo evaluate the accuracy of the predictions of paragraphs that will\nrequire attention following a significant edit to another paragraph, we\ncheck whether the predicted paragraphs undergo a significant change in\nconsequent revisions. Specifically, we iterate over all the revisions of\neach of the documents \\(d\\), and for each revision \\(d_t\\) we use only\ninformation known at that time (\\(t\\)) to predict paragraphs that will\nchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two\nmeasures: (1) whether paragraphs related to a ``triggering paragraph''\nthat changed significantly in revision \\(d_t\\) underwent at least one\nsignificant change in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2)\nwhether those paragraphs continue to be related by edit patterns to the\ntriggering paragraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is,\nwhether they keep changing together (or remain unchanged together) more\nthan half the time in the following 10 revisions. This second measure\nprovides a stronger indication of a possible interdependency between the\nparagraphs.\n\nThe frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.\n\nWith respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4912
sg12
(lp4913
(iversion
Paragraph
p4914
(dp4915
g10
S"Many documents (e.g., academic papers, government reports) are typicallywritten by multiple authors. While existing tools facilitate and supportsuch collaborative efforts (e.g., Dropbox, Google Docs), these toolslack intelligent information sharing mechanisms. Capabilities such as``track changes'' and ``diff'' visualize changes to authors, but do notdistinguish between minor and major edits and do not consider thepossible effects of edits on other parts of the document. Drawingcollaborators' attention to specific edits and describing them remainsthe responsibility of authors. This paper presents our initial worktoward the development of a collaborative system that supportsmulti-author writing. We describe methods for tracking paragraphs,identifying significant edits, and predicting parts of the paper thatare likely to require changes as a result of previous edits. Preliminaryevaluation of these methods shows promising results."
p4916
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4917
(dp4918
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientistswrite papers and proposals together, lawyers draft contracts,legislators draft legislation. In recent years, collaborative writing ofdocuments has become even more widespread with the support of frameworksthat simplify distributed editing (e.g., Google Docs, Dropbox). Whiledocument processors provide capabilities such as ``track changes'',``diff'', and commenting, they lack intelligent information sharingmechanisms. They do not attempt to reason about the importance ofchanges to different authors and do not consider how edits might affectother parts of the document. As a result, significant coordinationoverhead remains: authors need to re-read the entire document frequentlyor rely on communication from their co-authors in order to keep track ofthe current state of the document and ensure that their edits areconsistent with other edits."
p4919
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4920
(dp4921
g10
S"This paper proposes methods for tracking paragraphs across revisions,identifying significant changes, and predicting paragraphs that arelikely to be edited following a significant edit of a particularparagraph. The development of these methods is a first step toward thedesign of a collaborative system capable of (1) drawing authors'attention to edits that are important and relevant for them, and (2)pointing out other parts of the document that are likely to requirefurther editing. Systems with such capabilities have the potential toimprove coherence of documents and coordination among authors whilereducing the amount of communication required between authors. Anempirical evaluation of the proposed approach on a corpus of Wikipediaarticles shows promising initial results."
p4922
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4923
(dp4924
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborativewriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well asthe social aspects that arise as a result of edits and comments made bycollaborators~\\cite{birnholtz2013write}, and has developed tools forsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Mostclosely related to our work are methods and tools for supportingimproved \\emph{awareness} of collaborators about document changes. Theseinclude flexible diffing for reporting significantchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits andpresenting them toauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},methods for detecting and alerting authors about mergeconflicts~\\cite{hainsworth2006enabling}, and methods for detectingstructure in text and helping co-authors create coherent documents~\\cite{de2007narrative}. Our approach differs from these prior works inthat it leverages natural language processing (NLP) methods toautomatically detect significant changes, without requiring authors tospecify explicitly what changes are of interest to them. Furthermore,these capabilities go beyond prior approaches for supporting changeawareness in that they can predict parts of the document that have notchanged but that are likely to require edits as a result of otherchanges.'
p4925
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4926
(dp4927
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)identifying significant changes to paragraphs, and (3) predicting futurechanges to the document. Capability (1) is required for both monitoringchanges and predicting them. Capability (2) can help identify importantchanges and decide whether to alert authors of a change. Capability (3)is required in order to draw authors' attention to other parts of thedocument that might require changes as a result of a recent edit. Wedescribe our use of lightweight NLP techniques, which provide thefoundation for these important capabilities."
p4928
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4929
(dp4930
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved ordeleted. Thus, we developed an algorithm for tracking paragraphs acrossrevisions. The algorithm compares paragraphs based on their Levenshteindistance, that is, the number of changed characters required to movefrom one paragraph to another, including additions, deletions, andsubstitutions. We use the Levenshtein edit ratio (LR) measure, which isdefined as follows:\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0indicates the opposite. For each revision of a document, the algorithmcomputes the LR between each paragraph in the current version and eachparagraph in the previous version. Two paragraphs are mapped across therevision if they each have the highest LR with the other. If a paragraphin the new version has no matching paragraphs in the old version (i.e.,none of its ratios are above a threshold of 0.4), we label the paragraphas an addition. If a paragraph in the old version is not matched withany paragraphs in the new version, we consider it deleted.'
p4931
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4932
(dp4933
g10
S'Figure~{[}fig:mapping{]} illustrates this algorithm: some paragraphsfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the oldversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p4934
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4935
(dp4936
g10
S'While Wikipedia provides a diff visualization using an algorithm thatmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},the use of LR with forward and backward mapping allows for more robustdetection of paragraph movement even when there are significant changesto the content.'
p4937
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4938
(dp4939
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying SignificantChanges}\\label{identifying-significant-changes}We consider a change to be significant if it results in a noticeablechange in the paragraph's topic and content. To detect such change, wecompute the cosine similarity between word vectors that represent thetwo versions of a paragraph, using a Latent Semantic Indexing topicmodeling approach~\\cite{deerwester1990indexing}. If the cosinesimilarity between new and old versions of a paragraph is below athreshold of 0.8, we consider the edit significant. The threshold wasdetermined empirically by manually evaluating differences betweenparagraphs with varied similarity values."
p4940
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4941
(dp4942
g10
S"We chose a topic modeling approach for this task because, in contrastwith the LR approach used for mapping paragraphs, topic modelingconsiders the content of the text. To illustrate, if two of aparagraph's sentences switch places, the LR would decrease despite nomeaningful change in content. On the other hand, changing a couple ofkey words will slightly lower the LR, but could drastically affect thecontent."
p4943
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4944
(dp4945
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant changewould prompt edits in related paragraphs, and investigated whichparagraphs are likely to change in future revisions as a result of suchedits.'
p4946
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4947
(dp4948
g10
S'We considered three possible types of inter-paragraph relationships: (1)\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edithistories}, i.e., paragraphs that tended to be edited together inprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphswith similar content. For (2), we labeled pairs of paragraphs thatchanged or remained unchanged together in at least 5 of the previous 10revisions. We chose a window of 10 revisions as it allowed us to obtaina meaningful signal of correlation between edits, while not looking toofar in the past where the content might be significantly different. For(3), we labeled pairs as related if their cosine similarity was above anempirically determined threshold of 0.4. (There are rarely paragraphswith a higher similarity than 0.4, while a lower similarity does notreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methodsfor tracking paragraphs, detecting significant edits, and predictingfuture changes using a corpus of Wikipedia articles and their revisionhistories.'
p4949
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4950
(dp4951
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosenfrom a diverse set of topics, ranging from famous people and places tomathematical algorithms to novels. We removed Wikipedia-specific tagsthat indicate formatting and other irrelevant data, and eliminatedversions of articles under 150 characters, as they did not containenough text. To focus on revisions that contained a substantial change,the versions with simple typo fixes (Levenshtein distance \\(< 15\\) )were eliminated.'
p4952
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4953
(dp4954
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.'
p4955
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4956
(dp4957
g10
S'We focused mostly on the prediction of future edits, but also manuallyevaluated paragraph mapping and significant change detection, which formthe basis for edit prediction.'
p4958
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4959
(dp4960
g10
S'\\subsubsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of topic similarity betweenparagraphs in consecutive versions. As shown, most edits are minor. Withthe threshold of 0.8, we labeled about 15\\% of the edits as significant.'
p4961
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4962
(dp4963
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphsto ensure that paragraphs were correctly mapped and to determine whetherthe method successfully classified edits as significant orinsignificant. Figure~{[}fig:pars{]} shows an example of a significantedit: while the bottom paragraph is clearly a revision of the sameparagraph (recurring text shown in bold), the edit is significantbecause it adds new content and alters the tone of the text. Overall, wefound that paragraphs were rarely mapped incorrectly (less than\\(5\\%\\)), even when their content (as measured by topic similarity)changed significantly. Similarly, we found the classification ofsignificant edits to be correct in most cases, though this is a moresubjective measure which we plan to evaluate further in future work.'
p4964
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4965
(dp4966
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph oftentriggers edits in other paragraphs in the next revisions. This isdemonstrated in Figure~{[}fig:edits{]}, where each line represents aparagraph that is edited significantly at time 0. After a period ofrelative inactivity, a significant edit triggers further adjustments inthe near future (as represented by downward spikes). We evaluated thethree inter-paragraph relationships (proximity, edit history, and topicsimilarity) to determine which paragraphs are more likely to requirefurther editing after a significant change occurs in the article.'
p4967
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4968
(dp4969
g10
S"\\includegraphics{figs/parChangesNew.pdf}\\\\To evaluate the accuracy of the predictions of paragraphs that willrequire attention following a significant edit to another paragraph, wecheck whether the predicted paragraphs undergo a significant change inconsequent revisions. Specifically, we iterate over all the revisions ofeach of the documents \\(d\\), and for each revision \\(d_t\\) we use onlyinformation known at that time (\\(t\\)) to predict paragraphs that willchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at twomeasures: (1) whether paragraphs related to a ``triggering paragraph''that changed significantly in revision \\(d_t\\) underwent at least onesignificant change in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2)whether those paragraphs continue to be related by edit patterns to thetriggering paragraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is,whether they keep changing together (or remain unchanged together) morethan half the time in the following 10 revisions. This second measureprovides a stronger indication of a possible interdependency between theparagraphs."
p4970
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4971
(dp4972
g10
S'The frequency of occurrence of each type of inter-paragraph relationshipvaried. On average, 1.6 pairs of paragraphs related by edit history werefound per revision of the text. A pair related by topic similarity wasonly found once every ten versions. Proximity relationships always existin each version, as each paragraph has at least one neighboringparagraph (and most have two).'
p4973
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4974
(dp4975
g10
S'With respect to the first measure, the relationship of edit history ismuch more predictive of a future significant edit than proximity, asshown in Table~{[}table:futureEdits{]}. We computed the proximitymeasure for the original paragraph as well as randomly sampledparagraphs and found a significantly lower likelihood than forparagraphs related by edit similarity.'
p4976
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4977
(dp4978
g10
S'With respect to the second measure, we found that 71\\% of paragraphpairs related by edit history and 63\\% related by topic similaritycontinued being modified (or unmodified) together in the next 10versions. (Proximity was not evaluated for this measure, as it didalmost no better than the random control for the first, less strict,measure.) Further, we obtained a recall of 80\\% with predictions basedon edit history and topic similarity. That is, only 20\\% of theparagraphs that should have been labeled as related were not included inthe set of related paragraphs predicted by edit history and topicsimilarity.'
p4979
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4980
(dp4981
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve thecollaborative writing process. The methods we developed for trackingparagraphs throughout document revisions, detecting significant edits,and predicting future edits provide the basis for such a system. Thesecapabilities can inform decisions about alerting authors to specificchanges and places in the document that are likely to require revisions.'
p4982
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4983
(dp4984
g10
S"In future work, we will incorporate information about author identity todesign personalized alerts for authors depending on the edits they havemade. We also plan to develop additional algorithms for summarizingchanges and to investigate the use of algorithms that measure textcoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alertauthors to parts of the text that could be improved. Finally, we willexplore alternative interface designs for presenting the informationchosen by the algorithms for authors to consider and ways to incorporateexplanations for system recommendations (e.g., ``we recommend readingthe introduction because it is often edited following edits to theresults section'')."
p4985
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4986
(dp4987
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the NuanceFoundation. We thank Stuart Shieber for helpful discussions.'
p4988
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p4989
sba(iversion
Version
p4990
(dp4991
g7
g8
(S'\x07\xde\x0c\x0f\x16!\x1f\x08\x978'
tRp4992
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}..\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}..\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Topic Similarity \\&\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p4993
sg12
(lp4994
(iversion
Paragraph
p4995
(dp4996
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose anintelligent assistive system with two primary tasks. First, it shoulddetect important edits and promote them to the relevant authors. Second,it should anticipate possible semantic conflicts between variousauthors' contributions, alerting when appropriate in order to ensurethat the writing process goes smoothly."
p4997
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4998
(dp4999
g10
S'When authors collaborate on a paper, they need to communicate constantlyto ensure they are on the same page. Because the authors need to makesure their edits are coherent with the rest of the paper, includingsections written by others, they need to read the entire paperfrequently, or rely on updates communicated by their co-authors. Evenwith constant communication, authors can get lost in the volume of editsfrom other collaborators. Further, Kittur et al. have shown that in acollaborative environment such as Wikipedia, the majority of edits nolonger add content but instead do maintenance work and add discussions\\cite{kittur2007he}. Therefore, an assistive system with a summary ofthe significant changes contributed by other authors would be helpful,as shown by Birnholtz et al. \\cite{birnholtz2012tracking}..'
p5000
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5001
(dp5002
g10
S"We hypothesized that when an author makes a significant edit to aparagraph, it eventually triggers a series of adjustments in relatedparagraphs. In fact, a significant edit prompted changes in relatedparagraphs eighty percent of the time. However, in collaborativewriting, these resulting edits do not occur instantaneously. Beforethese adjustments occur, semantic conflicts might occur between theauthors' content. Instead of waiting for other authors to discover theinconsistency caused by one author's edit, we want an assistive systemto predict when and where these conflicts may occur, in order to alerteven more specifically."
p5003
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5004
(dp5005
g10
S'In order to achieve this, the system is composed of the following threecomponents: (1) tracking paragraphs; (2) identifying significant changesto paragraphs, and (3) predicting future changes to the article.'
p5006
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5007
(dp5008
g10
S'Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes is helps the system promote only the mostimportant changes and decide whether to alert collaborating authors.'
p5009
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5010
(dp5011
g10
S"Predicting future changes enables the system to not only report changesthat have already been made, but also draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p5012
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5013
(dp5014
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve thewriting process, as shown by Birnholtz et al.'
p5015
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5016
(dp5017
g10
S'\\cite{birnholtz2012tracking}.There has been some research on the topicof analyzing relevant changes between two versions of a text. Neuwirthet al. use flexible diffing \\cite{neuwirth1992flexible} to detect andreport important changes. Fong et al. attempt to categorize edits\\cite{fong2010did}, which, according to Papadopoulou et al.'
p5018
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5019
(dp5020
g10
S'\\cite{papadopoulou2007structured}, can be useful for detecting importantchanges. Tam et al. developed an interface to show these categorizedchanges to users \\cite{tam2006framework}. Hainsworth et al.'
p5021
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5022
(dp5023
g10
S'\\cite{hainsworth2006enabling} detect and alert authors about mergeconflicts. De Silva uses edit histories in order to find structurewithin a text and to help co-authors write coherent documents\\cite{de2007narrative}. Nunes et al. analyze the impact of public eventson the frequency of edits in the collaborative writing environment,Wikipedia, and argue that edits are predictable\\cite{nunes2008wikichanges}.'
p5024
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5025
(dp5026
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a widevariety of Wikipedia articles that undergo intense editing processes.'
p5027
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5028
(dp5029
g10
S'Wikipedia is a unique source because it presents extensive data forcollaborative writing. The findings use the complete revision revisionhistory of 41 different articles chosen from a diverse set of topics,from famous people and places to mathematical algorithms to novels. Thisapproach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions with consequential changes, theversions with simple typo fixes~\\footnote{We defined minor edits as  having a Levenshtein distance of under fifteen.} were eliminated aswell to reduce the number of maintenance edits \\cite{kittur2007he}. Thisresulted in a total of 17,199 versions across the 41 articles, with anaverage length of 25.71 paragraphs. Wikipedia data affords resultsapplicable to other collaborative writing spaces, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In fact, on average, 15 authors make 80\\% of theedits to an article (see Figure~{[}fig:authors{]}). This enables theconsideration of interactions between authors, which is crucial forlearning about collaborative behavior.'
p5030
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5031
(dp5032
g10
S'\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein editratio measure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision, we computed the Levenshtein ratio betweeneach paragraph in the old version and each paragraph in the new version.'
p5033
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5034
(dp5035
g10
S"Two paragraphs are mapped across the revision if they each had thehighest Levenshtein ratio for the other. If a paragraph in the newversion had no ``matches'', meaning that none of its ratios were above athreshold of 0.4, this paragraph was new. If a paragraph in the oldversion had no ``matches'', then it was deleted in the revision."
p5036
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5037
(dp5038
g10
S'Figure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10and 12 of the old version were deleted, while the others found clearmatches.'
p5039
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5040
(dp5041
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph'stopic and content. For this calculation, the Levenshtein ratio does notprovide the right kind of information. For example, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple key words will slightly lower the Levenshtein ratio,but could drastically affect the content."
p5042
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5043
(dp5044
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution ofthe differences between a paragraph's Levenshtein ratios and LSI ratios,the Levenshtein and LSI ratios demonstrate very different statistics."
p5045
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5046
(dp5047
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Latent Semantic Indexing is a form oftopic modeling that calculates the topic similarity between two texts.'
p5048
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5049
(dp5050
g10
S"Its strengths lie in accounting for synonyms and not penalizing fortypographical errors. The process begins by composing a corpus for eachWikipedia article from all of the documents (paragraphs of the versionsof the article). It analyzes tokens (a specific instance of a word),eliminating those that only occur once, as well as stopword tokens, suchas `the' or `and'. It then creates a TF-IDF matrix, which assigns aweight to every token in each document, which indicates the importanceof that token for this document. This weight increases proportionally tothe frequency of the word in the document, but accounts for thefrequency of the word in the corpus, such that the frequent occurrenceof a usually uncommon word is given a larger weight to signify thisimportance."
p5051
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5052
(dp5053
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p5054
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5055
(dp5056
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p5057
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5058
(dp5059
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p5060
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5061
(dp5062
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p5063
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5064
(dp5065
g10
S'Therefore, in order to predict future conflicts, an assistive systemneeds to detect significant changes and then determine consequentlywhich paragraphs were most likely to change.'
p5066
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5067
(dp5068
g10
S'We looked at three possible types of inter-paragraph relationships.'
p5069
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5070
(dp5071
g10
S'Paragraphs could be related by physical proximity: perhaps theneighboring paragraphs would require adjustments, as they are likelypart of the same section. Paragraphs could also be related by topic. Forexample, in an academic paper, the discussion section and the conclusionshould present similar themes. If one changes, the other may need to beedited to reflect this change. For each significant change, we used theexisting LSI Topic Model to determine which paragraphs discussed similartopics. Lastly, paragraphs could be related because of similar edithistories. For each significant change, we evaluated the edit history ofthis paragraph with every other paragraph in the article. We labeledpairs as related if they changed or remained unchanged together overhalf the time. With a higher threshold, the sample size decreases, butwith a lower threshold, the results become less predictive of asignificant change prompting further edits. This threshold strikes abalance between these two outcomes.'
p5072
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5073
(dp5074
g10
S"To evaluate these both of these suspected relationships, we looked atthe related paragraphs' edit patterns in the ten versions following thesignificant change. If the related paragraphs changed together over halfthe time, the paragraphs with this relationship proved to be related inthe future, verifying the relationship at the time of the significantchange."
p5075
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5076
(dp5077
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutiveversions of a paper, we calculated the number of versions from theparagraphs' inception to its demise. On average, paragraphs lasted 83article revisions."
p5078
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5079
(dp5080
g10
S'\\subsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}..'
p5081
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5082
(dp5083
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p5084
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5085
(dp5086
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p5087
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5088
(dp5089
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, when aparagraph is edited for the first time in a while, further adjustmentsare triggered in the near future.'
p5090
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5091
(dp5092
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\Caption: After a significant change at version 0, consequent edits aremore frequent.'
p5093
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5094
(dp5095
g10
S'We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p5096
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5097
(dp5098
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p5099
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5100
(dp5101
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times of at least one significant change}\\\\EditHistory \\& 81\\%\\\\Topic Similarity \\&\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\Relationship or Control Percentage of times that paragraph experiencedat least one significant change Edit History 81\\% Topic Similarity .'
p5102
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5103
(dp5104
g10
S'Physical Proximity 24\\% Paragraph with original significant change 40\\%Random Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p5105
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5106
(dp5107
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endheadTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewlineEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewlineProximity? & ? & ? & ?\\tabularnewline\\bottomrule\\end{longtable}Relationship Number Found Successfully Linked Ratio of SuccessfullyLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,68571\\%Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p5108
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5109
(dp5110
g10
S'The correlation coefficient was 0.99 for all numbers.'
p5111
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5112
(dp5113
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p5114
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5115
(dp5116
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p5117
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5118
(dp5119
g10
S'We imagine a couple other helpful components for an assistive systemthat our methods could provide the foundation for. Using text summaryalgorithms, the system could provide a succinct textual summary ofsignificant changes already detected. The system could also \\ldots{}.'
p5120
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5121
(dp5122
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determiningwhether a paragraph will change together in the future. Consequently, weassert that if significant edit occurs, related paragraphs should alsobe edited. A proposed assistive system will alert the relevant authorsof related paragraphs if this resulting edit does not occur. Bydetecting relationships between paragraphs in a multi-authored paper,our system can predict and alert appropriate authors if a significantchange has the potential to create a semantic conflict within the paper.'
p5123
sg17
I00
sg18
Nsg19
Nsbasg137
S'SebastianGehrmann'
p5124
sba(iversion
Version
p5125
(dp5126
g7
g8
(S'\x07\xde\x0c\x0f\x16)/\x04\x9b\xb0'
tRp5127
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}..\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio, but the scores are not correlated.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}..\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\ Proximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p5128
sg12
(lp5129
(iversion
Paragraph
p5130
(dp5131
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose anintelligent assistive system with two primary tasks. First, it shoulddetect important edits and promote them to the relevant authors. Second,it should anticipate possible semantic conflicts between variousauthors' contributions, alerting when appropriate in order to ensurethat the writing process goes smoothly."
p5132
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5133
(dp5134
g10
S'When authors collaborate on a paper, they need to communicate constantlyto ensure they are on the same page. Because the authors need to makesure their edits are coherent with the rest of the paper, includingsections written by others, they need to read the entire paperfrequently, or rely on updates communicated by their co-authors. Evenwith constant communication, authors can get lost in the volume of editsfrom other collaborators. Further, Kittur et al. have shown that in acollaborative environment such as Wikipedia, the majority of edits nolonger add content but instead do maintenance work and add discussions\\cite{kittur2007he}. Therefore, an assistive system with a summary ofthe significant changes contributed by other authors would be helpful,as shown by Birnholtz et al. \\cite{birnholtz2012tracking}..'
p5135
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5136
(dp5137
g10
S"We hypothesized that when an author makes a significant edit to aparagraph, it eventually triggers a series of adjustments in relatedparagraphs. In fact, a significant edit prompted changes in relatedparagraphs eighty percent of the time. However, in collaborativewriting, these resulting edits do not occur instantaneously. Beforethese adjustments occur, semantic conflicts might occur between theauthors' content. Instead of waiting for other authors to discover theinconsistency caused by one author's edit, we want an assistive systemto predict when and where these conflicts may occur, in order to alerteven more specifically."
p5138
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5139
(dp5140
g10
S'In order to achieve this, the system is composed of the following threecomponents: (1) tracking paragraphs; (2) identifying significant changesto paragraphs, and (3) predicting future changes to the article.'
p5141
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5142
(dp5143
g10
S'Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes is helps the system promote only the mostimportant changes and decide whether to alert collaborating authors.'
p5144
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5145
(dp5146
g10
S"Predicting future changes enables the system to not only report changesthat have already been made, but also draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p5147
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5148
(dp5149
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve thewriting process, as shown by Birnholtz et al.'
p5150
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5151
(dp5152
g10
S'\\cite{birnholtz2012tracking}.There has been some research on the topicof analyzing relevant changes between two versions of a text. Neuwirthet al. use flexible diffing \\cite{neuwirth1992flexible} to detect andreport important changes. Fong et al. attempt to categorize edits\\cite{fong2010did}, which, according to Papadopoulou et al.'
p5153
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5154
(dp5155
g10
S'\\cite{papadopoulou2007structured}, can be useful for detecting importantchanges. Tam et al. developed an interface to show these categorizedchanges to users \\cite{tam2006framework}. Hainsworth et al.'
p5156
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5157
(dp5158
g10
S'\\cite{hainsworth2006enabling} detect and alert authors about mergeconflicts. De Silva uses edit histories in order to find structurewithin a text and to help co-authors write coherent documents\\cite{de2007narrative}. Nunes et al. analyze the impact of public eventson the frequency of edits in the collaborative writing environment,Wikipedia, and argue that edits are predictable\\cite{nunes2008wikichanges}.'
p5159
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5160
(dp5161
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a widevariety of Wikipedia articles that undergo intense editing processes.'
p5162
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5163
(dp5164
g10
S'Wikipedia is a unique source because it presents extensive data forcollaborative writing. The findings use the complete revision revisionhistory of 41 different articles chosen from a diverse set of topics,from famous people and places to mathematical algorithms to novels. Thisapproach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions with consequential changes, theversions with simple typo fixes~\\footnote{We defined minor edits as  having a Levenshtein distance of under fifteen.} were eliminated aswell to reduce the number of maintenance edits \\cite{kittur2007he}. Thisresulted in a total of 17,199 versions across the 41 articles, with anaverage length of 25.71 paragraphs. Wikipedia data affords resultsapplicable to other collaborative writing spaces, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In fact, on average, 15 authors make 80\\% of theedits to an article (see Figure~{[}fig:authors{]}). This enables theconsideration of interactions between authors, which is crucial forlearning about collaborative behavior.'
p5165
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5166
(dp5167
g10
S'\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein editratio measure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision, we computed the Levenshtein ratio betweeneach paragraph in the old version and each paragraph in the new version.'
p5168
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5169
(dp5170
g10
S"Two paragraphs are mapped across the revision if they each had thehighest Levenshtein ratio for the other. If a paragraph in the newversion had no ``matches'', meaning that none of its ratios were above athreshold of 0.4, this paragraph was new. If a paragraph in the oldversion had no ``matches'', then it was deleted in the revision."
p5171
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5172
(dp5173
g10
S'Figure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10and 12 of the old version were deleted, while the others found clearmatches.'
p5174
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5175
(dp5176
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph'stopic and content. For this calculation, the Levenshtein ratio does notprovide the right kind of information. For example, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple key words will slightly lower the Levenshtein ratio,but could drastically affect the content."
p5177
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5178
(dp5179
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution ofthe differences between a paragraph's Levenshtein ratios and LSI ratios,the Levenshtein and LSI ratios demonstrate very different statistics. Ingeneral, the topic similarity ratio is closer to one than thelevenshtein ratio, but the scores are not correlated."
p5180
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5181
(dp5182
g10
S"\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Latent Semantic Indexing\\cite{deerwester1990indexing} is a form of topic modeling thatcalculates the topic similarity between two texts. Its strengths lie inaccounting for synonyms and not penalizing for typographical errors. Theprocess begins by composing a corpus for each Wikipedia article from allof the documents (paragraphs of the versions of the article). Itanalyzes tokens (a specific instance of a word), eliminating those thatonly occur once, as well as stopword tokens, such as `the' or `and'. Itthen creates a TF-IDF matrix, which assigns a weight to every token ineach document, which indicates the importance of that token for thisdocument. This weight increases proportionally to the frequency of theword in the document, but accounts for the frequency of the word in thecorpus, such that the frequent occurrence of a usually uncommon word isgiven a larger weight to signify this importance."
p5183
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5184
(dp5185
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p5186
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5187
(dp5188
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p5189
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5190
(dp5191
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p5192
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5193
(dp5194
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p5195
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5196
(dp5197
g10
S'Therefore, in order to predict future conflicts, an assistive systemneeds to detect significant changes and then determine consequentlywhich paragraphs were most likely to change.'
p5198
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5199
(dp5200
g10
S'We looked at three possible types of inter-paragraph relationships.'
p5201
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5202
(dp5203
g10
S'Paragraphs could be related by physical proximity: perhaps theneighboring paragraphs would require adjustments, as they are likelypart of the same section. Paragraphs could also be related by topic. Forexample, in an academic paper, the discussion section and the conclusionshould present similar themes. If one changes, the other may need to beedited to reflect this change. For each significant change, we used theexisting LSI Topic Model to determine which paragraphs discussed similartopics. Lastly, paragraphs could be related because of similar edithistories. For each significant change, we evaluated the edit history ofthis paragraph with every other paragraph in the article. We labeledpairs as related if they changed or remained unchanged together overhalf the time. With a higher threshold, the sample size decreases, butwith a lower threshold, the results become less predictive of asignificant change prompting further edits. This threshold strikes abalance between these two outcomes.'
p5204
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5205
(dp5206
g10
S"To evaluate these both of these suspected relationships, we looked atthe related paragraphs' edit patterns in the ten versions following thesignificant change. If the related paragraphs changed together over halfthe time, the paragraphs with this relationship proved to be related inthe future, verifying the relationship at the time of the significantchange."
p5207
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5208
(dp5209
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutiveversions of a paper, we calculated the number of versions from theparagraphs' inception to its demise. On average, paragraphs lasted 83article revisions."
p5210
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5211
(dp5212
g10
S'\\subsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}..'
p5213
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5214
(dp5215
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p5216
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5217
(dp5218
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p5219
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5220
(dp5221
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, when aparagraph is edited for the first time in a while, further adjustmentsare triggered in the near future.'
p5222
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5223
(dp5224
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p5225
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5226
(dp5227
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p5228
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5229
(dp5230
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times of at least one significant change}\\\\EditHistory \\& 81\\%\\\\ Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\Relationship or Control Percentage of times that paragraph experiencedat least one significant change Edit History 81\\% Topic Similarity .'
p5231
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5232
(dp5233
g10
S'Physical Proximity 24\\% Paragraph with original significant change 40\\%Random Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p5234
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5235
(dp5236
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endheadTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewlineEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewlineProximity? & ? & ? & ?\\tabularnewline\\bottomrule\\end{longtable}Relationship Number Found Successfully Linked Ratio of SuccessfullyLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,68571\\%Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p5237
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5238
(dp5239
g10
S'The correlation coefficient was 0.99 for all numbers.'
p5240
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5241
(dp5242
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p5243
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5244
(dp5245
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p5246
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5247
(dp5248
g10
S'We imagine a couple other helpful components for an assistive systemthat our methods could provide the foundation for. Using text summaryalgorithms, the system could provide a succinct textual summary ofsignificant changes already detected. The system could also \\ldots{}.'
p5249
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5250
(dp5251
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determiningwhether a paragraph will change together in the future. Consequently, weassert that if significant edit occurs, related paragraphs should alsobe edited. A proposed assistive system will alert the relevant authorsof related paragraphs if this resulting edit does not occur. Bydetecting relationships between paragraphs in a multi-authored paper,our system can predict and alert appropriate authors if a significantchange has the potential to create a semantic conflict within the paper.'
p5252
sg17
I00
sg18
Nsg19
Nsbasg137
S'LaurenUrke'
p5253
sba(iversion
Version
p5254
(dp5255
g7
g8
(S'\x07\xde\x0c\x0f\x17\x0b\x01\x01S\xd8'
tRp5256
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio, but the scores are not correlated.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p5257
sg12
(lp5258
(iversion
Paragraph
p5259
(dp5260
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose anintelligent assistive system with two primary tasks. First, it shoulddetect important edits and promote them to the relevant authors. Second,it should anticipate possible semantic conflicts between variousauthors' contributions, alerting when appropriate in order to ensurethat the writing process goes smoothly."
p5261
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5262
(dp5263
g10
S'When authors collaborate on a paper, they need to communicate constantlyto ensure they are on the same page. Because the authors need to makesure their edits are coherent with the rest of the paper, includingsections written by others, they need to read the entire paperfrequently, or rely on updates communicated by their co-authors. Evenwith constant communication, authors can get lost in the volume of editsfrom other collaborators. Further, Kittur et al. have shown that in acollaborative environment such as Wikipedia, the majority of edits nolonger add content but instead do maintenance work and add discussions\\cite{kittur2007he}. Therefore, an assistive system with a summary ofthe significant changes contributed by other authors would be helpful,as shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p5264
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5265
(dp5266
g10
S"We hypothesized that when an author makes a significant edit to aparagraph, it eventually triggers a series of adjustments in relatedparagraphs. In fact, a significant edit prompted changes in relatedparagraphs eighty percent of the time. However, in collaborativewriting, these resulting edits do not occur instantaneously. Beforethese adjustments occur, semantic conflicts might occur between theauthors' content. Instead of waiting for other authors to discover theinconsistency caused by one author's edit, we want an assistive systemto predict when and where these conflicts may occur, in order to alerteven more specifically."
p5267
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5268
(dp5269
g10
S'In order to achieve this, the system is composed of the following threecomponents: (1) tracking paragraphs; (2) identifying significant changesto paragraphs, and (3) predicting future changes to the article.'
p5270
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5271
(dp5272
g10
S'Tracking paragraphs through paper revisions is a core capabilityrequired for monitoring changes and predicting them. The identificationof significant content changes is helps the system promote only the mostimportant changes and decide whether to alert collaborating authors.'
p5273
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5274
(dp5275
g10
S"Predicting future changes enables the system to not only report changesthat have already been made, but also draw authors' attention to otherparts of the document that might require changes as a result of a recentedit."
p5276
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5277
(dp5278
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve thewriting process, as shown by Birnholtz et al.'
p5279
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5280
(dp5281
g10
S'\\cite{birnholtz2012tracking}.There has been some research on the topicof analyzing relevant changes between two versions of a text. Neuwirthet al. use flexible diffing \\cite{neuwirth1992flexible} to detect andreport important changes. Fong et al. attempt to categorize edits\\cite{fong2010did}, which, according to Papadopoulou et al.'
p5282
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5283
(dp5284
g10
S'\\cite{papadopoulou2007structured}, can be useful for detecting importantchanges. Tam et al. developed an interface to show these categorizedchanges to users \\cite{tam2006framework}. Hainsworth et al.'
p5285
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5286
(dp5287
g10
S'\\cite{hainsworth2006enabling} detect and alert authors about mergeconflicts. De Silva uses edit histories in order to find structurewithin a text and to help co-authors write coherent documents\\cite{de2007narrative}. Nunes et al. analyze the impact of public eventson the frequency of edits in the collaborative writing environment,Wikipedia, and argue that edits are predictable\\cite{nunes2008wikichanges}.'
p5288
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5289
(dp5290
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a widevariety of Wikipedia articles that undergo intense editing processes.'
p5291
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5292
(dp5293
g10
S'Wikipedia is a unique source because it presents extensive data forcollaborative writing. The findings use the complete revision revisionhistory of 41 different articles chosen from a diverse set of topics,from famous people and places to mathematical algorithms to novels. Thisapproach was used in various other papers\\cite{wohner2009assessing, fong2010did}. The revision histories weredownloaded as raw xml data. We removed Wikipedia-specific tags thatindicate formatting and other irrelevant data, and eliminated versionsof the articles under 150 characters, as they did not contain enoughinformation. To focus only on revisions with consequential changes, theversions with simple typo fixes~\\footnote{We defined minor edits as  having a Levenshtein distance of under fifteen.} were eliminated aswell to reduce the number of maintenance edits \\cite{kittur2007he}. Thisresulted in a total of 17,199 versions across the 41 articles, with anaverage length of 25.71 paragraphs. Wikipedia data affords resultsapplicable to other collaborative writing spaces, because although theaverage article has over 400 contributing authors, most of these authorsmake a one-time change. In fact, on average, 15 authors make 80\\% of theedits to an article (see Figure~{[}fig:authors{]}). This enables theconsideration of interactions between authors, which is crucial forlearning about collaborative behavior.'
p5294
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5295
(dp5296
g10
S'\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein editratio measure, which is defined as follows:\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a highsimilarity between them, while a ratio close to zero indicates theopposite. For each revision, we computed the Levenshtein ratio betweeneach paragraph in the old version and each paragraph in the new version.'
p5297
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5298
(dp5299
g10
S"Two paragraphs are mapped across the revision if they each had thehighest Levenshtein ratio for the other. If a paragraph in the newversion had no ``matches'', meaning that none of its ratios were above athreshold of 0.4, this paragraph was new. If a paragraph in the oldversion had no ``matches'', then it was deleted in the revision."
p5300
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5301
(dp5302
g10
S'Figure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10and 12 of the old version were deleted, while the others found clearmatches.'
p5303
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5304
(dp5305
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect SignificantChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph'stopic and content. For this calculation, the Levenshtein ratio does notprovide the right kind of information. For example, if two of theparagraph's sentences switch places, the Levenshtein ratio woulddecrease despite no meaningful change in content. On the other hand,changing a couple key words will slightly lower the Levenshtein ratio,but could drastically affect the content."
p5306
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5307
(dp5308
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution ofthe differences between a paragraph's Levenshtein ratios and LSI ratios,the Levenshtein and LSI ratios demonstrate very different statistics. Ingeneral, the topic similarity ratio is closer to one than thelevenshtein ratio, but the scores are not correlated."
p5309
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5310
(dp5311
g10
S"\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit forassessing changes in content. Latent Semantic Indexing\\cite{deerwester1990indexing} is a form of topic modeling thatcalculates the topic similarity between two texts. Its strengths lie inaccounting for synonyms and not penalizing for typographical errors. Theprocess begins by composing a corpus for each Wikipedia article from allof the documents (paragraphs of the versions of the article). Itanalyzes tokens (a specific instance of a word), eliminating those thatonly occur once, as well as stopword tokens, such as `the' or `and'. Itthen creates a TF-IDF matrix, which assigns a weight to every token ineach document, which indicates the importance of that token for thisdocument. This weight increases proportionally to the frequency of theword in the document, but accounts for the frequency of the word in thecorpus, such that the frequent occurrence of a usually uncommon word isgiven a larger weight to signify this importance."
p5312
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5313
(dp5314
g10
S"The latent semantic indexing method then reduces the dimensions of thematrix, clustering synonyms, words with similar topics, and words thatusually occur together. When comparing two paragraphs, the methodcomputes the cosine similarity between each paragraph's row vector."
p5315
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5316
(dp5317
g10
S'Paragraphs that have similar topics will have a large cosine similarityvalue.'
p5318
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5319
(dp5320
g10
S'By calculating the topic similarity between two concurrent versions ofan edited paragraph, the system can detect whether a significant changehas occurred. If the cosine similarity between the two paragraphs wasbelow an empirically determined threshold of 0.8, we label the edit assignificant.'
p5321
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5322
(dp5323
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant changewould cause inconsistencies in related paragraphs, prompting edits.'
p5324
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5325
(dp5326
g10
S'Therefore, in order to predict future conflicts, an assistive systemneeds to detect significant changes and then determine consequentlywhich paragraphs were most likely to change.'
p5327
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5328
(dp5329
g10
S'We looked at three possible types of inter-paragraph relationships.'
p5330
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5331
(dp5332
g10
S'Paragraphs could be related by physical proximity: perhaps theneighboring paragraphs would require adjustments, as they are likelypart of the same section. Paragraphs could also be related by topic. Forexample, in an academic paper, the discussion section and the conclusionshould present similar themes. If one changes, the other may need to beedited to reflect this change. For each significant change, we used theexisting LSI Topic Model to determine which paragraphs discussed similartopics. Lastly, paragraphs could be related because of similar edithistories. For each significant change, we evaluated the edit history ofthis paragraph with every other paragraph in the article. We labeledpairs as related if they changed or remained unchanged together overhalf the time. With a higher threshold, the sample size decreases, butwith a lower threshold, the results become less predictive of asignificant change prompting further edits. This threshold strikes abalance between these two outcomes.'
p5333
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5334
(dp5335
g10
S"To evaluate these both of these suspected relationships, we looked atthe related paragraphs' edit patterns in the ten versions following thesignificant change. If the related paragraphs changed together over halfthe time, the paragraphs with this relationship proved to be related inthe future, verifying the relationship at the time of the significantchange."
p5336
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5337
(dp5338
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutiveversions of a paper, we calculated the number of versions from theparagraphs' inception to its demise. On average, paragraphs lasted 83article revisions."
p5339
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5340
(dp5341
g10
S'\\subsection{Detecting SignificantChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, welabeled about 15\\% of the edits as significant, as shown inFigure~{[}fig:lsi{]}.'
p5342
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5343
(dp5344
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that thismethod successfully classifies edits. We provide an example of asignificant edit below. While these paragraphs are clearly the same, theedit is significant because it contributes content and changes the toneof the paragraph.'
p5345
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5346
(dp5347
g10
S"OLD: After complaints arose during the renovation in the late 1980s ofthe early residential colleges, a swing dormitory was built in 1998 tofacilitate housing students during the massive overhaul of buildingsthat had seen only intermediate improvements in plumbing, heating,electrical and network wiring, and general maintenance over their35-to-80-year existence. The new Residence Hall is not a residentialcollege, but houses students from other colleges during renovations. Itis commonly called ``Swing Space'' by the students; it's official name``Boyd Hall'' is unused. ---------------------------------------------NEW: In 1990, Yale launched a series of massive overhauls to the olderresidential buildings, whose decades of existence had seen only routinemaintenance and incremental improvements to plumbing, heating, andelectrical and network wiring. Calhoun College was the first to seerenovation. Various unwieldy schemes were used to house displacedstudents during the yearlong projects, but complaints finally moved Yaleto build a new residence hall between the gym and the power plant. It iscommonly called ``Swing Space'' by the students; its official name``Boyd Hall'' is unused."
p5348
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5349
(dp5350
g10
S'\\subsection{Predicting FutureConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine whichparagraphs are more likely to require editing after a significant changeoccurs in the article. As seen in Figure~{[}fig:edits{]}, when aparagraph is edited for the first time in a while, further adjustmentsare triggered in the near future.'
p5351
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5352
(dp5353
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may needattention. First, the related paragraphs experience at least onesignificant change within the next ten versions, indicating that asemantic discrepancy was introduced and required fixing. Second, andmore importantly, the related paragraphs relationship was correctlypredicted; that is, they are still related ten versions after thesignificant change, meaning that they change together (or remainunchanged together) more than half the time. This is a strongerindication than just undergoing at least one significant change.'
p5354
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5355
(dp5356
g10
S'With respect to the first measure, the relationships of edit history andtopic similarity are much more predictive than physical proximity, asshown in Table~{[}table:futureEdits{]}. They are also significantly morepredictive than random sample controls. For controls, we compare withthe original paragraph as well as a random sample of any ten consecutiveversions within Wikipedia article histories.'
p5357
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5358
(dp5359
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\\textbf{Percentage of times of at least one significant change}\\\\EditHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctlypredicted 63\\% of pairs related by topic and 71\\% of pairs related byedit history. Further, we obtained a recall of 80\\% for these correctpredictions; thus, only 20\\% of the paragraphs that should have beenlabeled as related (based on information ten versions in the future)were missed.'
p5360
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5361
(dp5362
g10
S'\\begin{longtable}[c]{@{}llll@{}}\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endfirsthead\\toprule\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\\textbf{Ratio}\\tabularnewline\\midrule\\endheadTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewlineEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewlineProximity? & ? & ? & ?\\tabularnewline\\bottomrule\\end{longtable}Lastly, to ensure independence from specific articles, we calculated thecorrelation between our statistics across all of our Wikipedia articles.'
p5363
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5364
(dp5365
g10
S'The correlation coefficient was 0.99 for all numbers.'
p5366
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5367
(dp5368
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, ouralgorithm for tracking paragraphs throughout versions of an article iscapable of following paragraphs through complex edits. This provides thebasis for detecting significant changes and anticipating future semanticconflicts. Our edit evaluation method successfully detects the mostsignificant changes using the LSI Topic Similarity model. Based on thesesignificant changes, we anticipate possible semantic conflicts in linkedparagraphs. After a significant change, paragraphs related to the editedparagraph were indeed more likely to be edited in response a coupleversions later. Paragraphs linked by similar edit histories were mostlikely to need editing, with paragraphs linked by topic similarity notfar behind.'
p5369
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5370
(dp5371
g10
S"In the future, we can build an assistive system that uses our methods toimprove the collaborative writing environment. The paragraph trackingalgorithm makes it possible to create a list of authors who havecontributed to a specific paragraph, which is crucial for determiningwho to alert when significant edits occur. By labeling edits assignificant, the system can save authors time, since they will no longerneed to discern which of their peers' edits actually matter. Then, whena significant edit occurs, the system can alert authors to relatedparagraphs that will likely need adjusting, allowing authors to fixsemantic conflicts immediately, instead of discovering them later."
p5372
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5373
(dp5374
g10
S'We imagined another helpful component for an assistive system that canbe based on our foundational methods. Using text summary algorithms, thesystem could provide a succinct textual summary of significant changesalready detected, rather than just an output of the significant edits.'
p5375
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5376
(dp5377
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligentsystem that could assist in the field of collaborative writing. Wesuccessfully formulated a method to detect which edits are mostsignificant. Consequently, we discovered that if significant editoccurs, related paragraphs will probably also be edited. A proposedassistive system will alert the relevant authors of related paragraphsif this resulting edit does not occur. By detecting relationshipsbetween paragraphs in a multi-authored paper, our system could predictand alert if a significant change has the potential to create a semanticconflict within the paper.'
p5378
sg17
I00
sg18
Nsg19
Nsbasg137
S'OfraAmir'
p5379
sbasS'title'
p5380
S'colWriting'
p5381
sb.