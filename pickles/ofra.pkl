(iversion
Page
p1
(dp2
S'revisions'
p3
(lp4
(iversion
Version
p5
(dp6
S'date'
p7
cdatetime
datetime
p8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp9
sS'text'
p10
VThis section presents the MAPF problem and the iBundle auction mechanism that we use to solve MAPF. We also describe the increasing cost tree search (ICTS) algorithm as we use techniques implemented in ICTS in our auction implementation. We also compare the auction mechanism with ICTS, discussing their similarities and differences.\u000a MAPF address the problem of finding non-conflicting paths for a set of agents located on a graph~\u005cfootnote{I define the problem for grids, but any graph which agents can traverse can be used.}. MAPF has been shown to be NP-Complete~\u005ccite{surynek2010optimization} Formally, an MAPF problem is defined by: \u000aAt any time $t$, an agent can occupy a single location $l$ on the grid. When an agent moves to an adjacent square at time $t$ it will occupy the destination square at time $t+1$. It is typically assumed that only one agent can occupy a specific location at any given time. Thus, a solution to an MAPF problem needs to assign a path to each agent such that: (1) the agent reaches its goal, and (2) agents do not collide. It is assumed that agents have full knowledge of the map and that when an agent reaches its goal it remains at that location (and no other agent can occupy it). We aim to find \u005cemph{efficient} solutions, that is solutions minimize the total cost of the paths traversed by agents (i.e. minimizing the sum of time steps required for agents to reach their goals).\u000aIn combinatorial auctions, the auctioneer has items for sale, as in a regular auction. However, agents may bid on \u005cemph{bundles} of items, that is a set of items they wish to buy. Similarly, prices are assigned to bundles rather than individual items, supporting non-linear pricing of bundles.\u000aIn iterative combinatorial auctions (ICA), the auction has multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. Iterative auctions require less effort from agents as they do not need to express their entire  preferences. We used the iBundle~\u005ccite{parkes2001iterative} ICA mechanism to solve the MAPF problem. \u000aIn iBundle, each iteration includes three stages: (1) bidding; (2) winner determination, and (3) price update. \u000aIn the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, that is bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updates as follows: for each bundle that an ``unhappy'' agent (i.e. an agent that did not receive any of its bundles in the provisional allocation) bid on, the price is raised to the maximum bid received on the bundle by an unhappy agent plus $\u005cepsilon$, where $\u005cepsilon$ is the minimal increment size in the auction. Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agent who bid on them to switch to other bundles, or alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' update their bids. The auction terminates when the provisional allocation includes all of the agents, or when the same bids are submitted in two consequent rounds. In the approach section we describe how iBundle can be implemented to solve MAPF problems.\u000aThe ICTS algorithm~\u005ccite{sharon2012increasing} consists of two levels. At the high-level, the search is performed on cost nodes that specify for each agent the cost of its paths to the goal that are considered in the current ICT node.\u000aThe search starts from an ICT node with costs corresponding to the shortest paths costs for each of the agents ignoring the other agents. Then, nodes are expanded in a breadth-first manner, where each layer includes nodes with a specific sum of costs. Every time a node is expanded, the low-level search performs a goal test on the ICT node, checking whether there is a non-conflicting set of paths for the agents with the required costs. If the goal test passes, the algorithm terminates. If it does not, new ICT nodes are generated -- where each child node increases the cost for one of the agents, resulting in a total cost great by 1 then its parent node.\u000aFor example, if the initial costs were 3,5 and 6 and a non-conflicting solution did not exist at these costs, three ICT child nodes will be generated, with  costs of ${4,5,6}$; ${3,6,6}$, and ${3,5,7}$. Because the ICT is searched in a breadth-first manner, an optimal solution is guaranteed (a node with a lower sum of costs will always be searched before nodes with higher sum of costs). \u000aTo efficiently solve ICT nodes (i.e., perform a goal test), the low-level search uses multi-value decision diagrams (MDDs)~\u005ccite{srinivasan1990algorithms}. An MDD for a single agent and a given cost represents all possible paths from the starting location of the agent to its goal at the defined cost. Figure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. Note that if there are $V$ vertices in the graph representing the grid, there can be at most $V \u005ccdot C$ nodes in each level of an MDD of cost $C$. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps, as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD). \u000aIn the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. \u000aWe next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. \u000aIn the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.\u000aFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[<(0,1),t_1>,<(1,1),t_2>]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[<(0,2),t_1>,<(0,1),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(2,2),t_3,<(2,1),t_4>]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, we efficiently represent bids using multi-value decision diagrams (MDDs)~\u005ccite{srinivasan1990algorithms} which were used in the ICTS algorithm to represent paths of different costs~\u005ccite{sharon2012increasing}. \u000aAn MDD for a single agent and a given cost represents all possible paths from the starting location of the agent to its goal at the defined cost. Figure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. Note that if there are $V$ vertices in the graph representing the grid, there can be at most $V \u005ccdot C$ nodes in each level of an MDD of cost $C$. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps, as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD). Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the paths in the auction.\u000aAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. \u000aAt a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. \u000aUsing MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. \u000aFigure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). \u000aWe can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. \u000aIn the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.  \u000a Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle. \u000a We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. \u000aAs in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. \u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$ because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. \u000aICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. \u000aWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. \u000aLet $\u005cdelta_i = C^*_{i}-opt{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.\u000a$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).\u000aAssume that:\u000aIt follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.\u000aIn this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.\u000aThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. \u000aIn addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. \u000a
p11
sS'paragraphs'
p12
(lp13
(iversion
Paragraph
p14
(dp15
g10
VThis section presents the MAPF problem and the iBundle auction mechanism that we use to solve MAPF. We also describe the increasing cost tree search (ICTS) algorithm as we use techniques implemented in ICTS in our auction implementation. We also compare the auction mechanism with ICTS, discussing their similarities and differences.
p16
sS'changed'
p17
I00
sS'nextindex'
p18
NsS'lastindex'
p19
Nsba(iversion
Paragraph
p20
(dp21
g10
V MAPF address the problem of finding non-conflicting paths for a set of agents located on a graph~\u005cfootnote{I define the problem for grids, but any graph which agents can traverse can be used.}. MAPF has been shown to be NP-Complete~\u005ccite{surynek2010optimization} Formally, an MAPF problem is defined by: At any time $t$, an agent can occupy a single location $l$ on the grid. When an agent moves to an adjacent square at time $t$ it will occupy the destination square at time $t+1$. It is typically assumed that only one agent can occupy a specific location at any given time. Thus, a solution to an MAPF problem needs to assign a path to each agent such that: (1) the agent reaches its goal, and (2) agents do not collide. It is assumed that agents have full knowledge of the map and that when an agent reaches its goal it remains at that location (and no other agent can occupy it). We aim to find \u005cemph{efficient} solutions, that is solutions minimize the total cost of the paths traversed by agents (i.e. minimizing the sum of time steps required for agents to reach their goals).
p22
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p23
(dp24
g10
VIn combinatorial auctions, the auctioneer has items for sale, as in a regular auction. However, agents may bid on \u005cemph{bundles} of items, that is a set of items they wish to buy. Similarly, prices are assigned to bundles rather than individual items, supporting non-linear pricing of bundles.
p25
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p26
(dp27
g10
VIn iterative combinatorial auctions (ICA), the auction has multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. Iterative auctions require less effort from agents as they do not need to express their entire  preferences. We used the iBundle~\u005ccite{parkes2001iterative} ICA mechanism to solve the MAPF problem. In iBundle, each iteration includes three stages: (1) bidding; (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, that is bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p28
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p29
(dp30
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updates as follows: for each bundle that an ``unhappy'' agent (i.e. an agent that did not receive any of its bundles in the provisional allocation) bid on, the price is raised to the maximum bid received on the bundle by an unhappy agent plus $\u005cepsilon$, where $\u005cepsilon$ is the minimal increment size in the auction. Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agent who bid on them to switch to other bundles, or alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' update their bids. The auction terminates when the provisional allocation includes all of the agents, or when the same bids are submitted in two consequent rounds. In the approach section we describe how iBundle can be implemented to solve MAPF problems.
p31
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p32
(dp33
g10
VThe ICTS algorithm~\u005ccite{sharon2012increasing} consists of two levels. At the high-level, the search is performed on cost nodes that specify for each agent the cost of its paths to the goal that are considered in the current ICT node.
p34
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p35
(dp36
g10
VThe search starts from an ICT node with costs corresponding to the shortest paths costs for each of the agents ignoring the other agents. Then, nodes are expanded in a breadth-first manner, where each layer includes nodes with a specific sum of costs. Every time a node is expanded, the low-level search performs a goal test on the ICT node, checking whether there is a non-conflicting set of paths for the agents with the required costs. If the goal test passes, the algorithm terminates. If it does not, new ICT nodes are generated -- where each child node increases the cost for one of the agents, resulting in a total cost great by 1 then its parent node.
p37
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p38
(dp39
g10
VFor example, if the initial costs were 3,5 and 6 and a non-conflicting solution did not exist at these costs, three ICT child nodes will be generated, with  costs of ${4,5,6}$; ${3,6,6}$, and ${3,5,7}$. Because the ICT is searched in a breadth-first manner, an optimal solution is guaranteed (a node with a lower sum of costs will always be searched before nodes with higher sum of costs). To efficiently solve ICT nodes (i.e., perform a goal test), the low-level search uses multi-value decision diagrams (MDDs)~\u005ccite{srinivasan1990algorithms}. An MDD for a single agent and a given cost represents all possible paths from the starting location of the agent to its goal at the defined cost. Figure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. Note that if there are $V$ vertices in the graph representing the grid, there can be at most $V \u005ccdot C$ nodes in each level of an MDD of cost $C$. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps, as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD). In the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. We next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. In the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.
p40
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p41
(dp42
g10
VFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[<(0,1),t_1>,<(1,1),t_2>]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[<(0,2),t_1>,<(0,1),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(2,2),t_3,<(2,1),t_4>]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.
p43
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p44
(dp45
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, we efficiently represent bids using multi-value decision diagrams (MDDs)~\u005ccite{srinivasan1990algorithms} which were used in the ICTS algorithm to represent paths of different costs~\u005ccite{sharon2012increasing}. An MDD for a single agent and a given cost represents all possible paths from the starting location of the agent to its goal at the defined cost. Figure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. Note that if there are $V$ vertices in the graph representing the grid, there can be at most $V \u005ccdot C$ nodes in each level of an MDD of cost $C$. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps, as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD). Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the paths in the auction.
p46
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p47
(dp48
g10
VAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. At a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. Using MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. Figure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). We can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. In the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.   Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle.  We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. As in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.
p49
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p50
(dp51
g10
VFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. It has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$ because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. ICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. We note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. Let $\u005cdelta_i = C^*_{i}-opt{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.
p52
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p53
(dp54
g10
V$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).
p55
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p56
(dp57
g10
VAssume that:It follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.
p58
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p59
(dp60
g10
VIn this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.
p61
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p62
(dp63
g10
VThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. In addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. 
p64
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p65
(dp66
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp67
sg10
VThis section presents the MAPF problem and the iBundle auction mechanism that we use to solve MAPF. We also describe the increasing cost tree search (ICTS) algorithm as we use techniques implemented in ICTS in our auction implementation. We also compare the auction mechanism with ICTS, discussing their similarities and differences.\u000a MAPF address the problem of finding non-conflicting paths for a set of agents located on a graph~\u005cfootnote{I define the problem for grids, but any graph which agents can traverse can be used.}. MAPF has been shown to be NP-Complete~\u005ccite{surynek2010optimization} Formally, an MAPF problem is defined by: \u000aAt any time $t$, an agent can occupy a single location $l$ on the grid. When an agent moves to an adjacent square at time $t$ it will occupy the destination square at time $t+1$. It is typically assumed that only one agent can occupy a specific location at any given time. Thus, a solution to an MAPF problem needs to assign a path to each agent such that: (1) the agent reaches its goal, and (2) agents do not collide. It is assumed that agents have full knowledge of the map and that when an agent reaches its goal it remains at that location (and no other agent can occupy it). We aim to find \u005cemph{efficient} solutions, that is solutions minimize the total cost of the paths traversed by agents (i.e. minimizing the sum of time steps required for agents to reach their goals).\u000aIn combinatorial auctions, the auctioneer has items for sale, as in a regular auction. However, agents may bid on \u005cemph{bundles} of items, that is a set of items they wish to buy. Similarly, prices are assigned to bundles rather than individual items, supporting non-linear pricing of bundles.\u000aIn iterative combinatorial auctions (ICA), the auction has multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. Iterative auctions require less effort from agents as they do not need to express their entire  preferences. We used the iBundle~\u005ccite{parkes2001iterative} ICA mechanism to solve the MAPF problem. \u000aIn iBundle, each iteration includes three stages: (1) bidding; (2) winner determination, and (3) price update. \u000aIn the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, that is bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updates as follows: for each bundle that an ``unhappy'' agent (i.e. an agent that did not receive any of its bundles in the provisional allocation) bid on, the price is raised to the maximum bid received on the bundle by an unhappy agent plus $\u005cepsilon$, where $\u005cepsilon$ is the minimal increment size in the auction. Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agent who bid on them to switch to other bundles, or alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' update their bids. The auction terminates when the provisional allocation includes all of the agents, or when the same bids are submitted in two consequent rounds. In the approach section we describe how iBundle can be implemented to solve MAPF problems.\u000aThe ICTS algorithm~\u005ccite{sharon2012increasing} consists of two levels. At the high-level, the search is performed on cost nodes that specify for each agent the cost of its paths to the goal that are considered in the current ICT node.\u000aThe search starts from an ICT node with costs corresponding to the shortest paths costs for each of the agents ignoring the other agents. Then, nodes are expanded in a breadth-first manner, where each layer includes nodes with a specific sum of costs. Every time a node is expanded, the low-level search performs a goal test on the ICT node, checking whether there is a non-conflicting set of paths for the agents with the required costs. If the goal test passes, the algorithm terminates. If it does not, new ICT nodes are generated -- where each child node increases the cost for one of the agents, resulting in a total cost great by 1 then its parent node.\u000aFor example, if the initial costs were 3,5 and 6 and a non-conflicting solution did not exist at these costs, three ICT child nodes will be generated, with  costs of ${4,5,6}$; ${3,6,6}$, and ${3,5,7}$. Because the ICT is searched in a breadth-first manner, an optimal solution is guaranteed (a node with a lower sum of costs will always be searched before nodes with higher sum of costs). \u000aTo efficiently solve ICT nodes (i.e., perform a goal test), the low-level search uses multi-value decision diagrams (MDDs)~\u005ccite{srinivasan1990algorithms}. An MDD for a single agent and a given cost represents all possible paths from the starting location of the agent to its goal at the defined cost. Figure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. Note that if there are $V$ vertices in the graph representing the grid, there can be at most $V \u005ccdot C$ nodes in each level of an MDD of cost $C$. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps, as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD). \u000aIn the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. \u000aWe next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. \u000aIn the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.\u000aFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[<(0,1),t_1>,<(1,1),t_2>]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[<(0,2),t_1>,<(0,1),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(2,2),t_3,<(2,1),t_4>]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, we efficiently represent bids using multi-value decision diagrams (MDDs)~\u005ccite{srinivasan1990algorithms} which were used in the ICTS algorithm to represent paths of different costs~\u005ccite{sharon2012increasing}. \u000aAn MDD for a single agent and a given cost represents all possible paths from the starting location of the agent to its goal at the defined cost. Figure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. Note that if there are $V$ vertices in the graph representing the grid, there can be at most $V \u005ccdot C$ nodes in each level of an MDD of cost $C$. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps, as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD). Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the paths in the auction.\u000aAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. \u000aAt a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. \u000aUsing MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. \u000aFigure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). \u000aWe can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. \u000aIn the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.  \u000a Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle. \u000a We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. \u000aAs in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. \u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$ because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. \u000aICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. \u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.\u000a$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).\u000aAssume that:\u000aIt follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.\u000aWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. \u000aIn this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.\u000aThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. \u000aIn addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. \u000a
p68
sg12
(lp69
(iversion
Paragraph
p70
(dp71
g10
VThis section presents the MAPF problem and the iBundle auction mechanism that we use to solve MAPF. We also describe the increasing cost tree search (ICTS) algorithm as we use techniques implemented in ICTS in our auction implementation. We also compare the auction mechanism with ICTS, discussing their similarities and differences.
p72
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p73
(dp74
g10
V MAPF address the problem of finding non-conflicting paths for a set of agents located on a graph~\u005cfootnote{I define the problem for grids, but any graph which agents can traverse can be used.}. MAPF has been shown to be NP-Complete~\u005ccite{surynek2010optimization} Formally, an MAPF problem is defined by: At any time $t$, an agent can occupy a single location $l$ on the grid. When an agent moves to an adjacent square at time $t$ it will occupy the destination square at time $t+1$. It is typically assumed that only one agent can occupy a specific location at any given time. Thus, a solution to an MAPF problem needs to assign a path to each agent such that: (1) the agent reaches its goal, and (2) agents do not collide. It is assumed that agents have full knowledge of the map and that when an agent reaches its goal it remains at that location (and no other agent can occupy it). We aim to find \u005cemph{efficient} solutions, that is solutions minimize the total cost of the paths traversed by agents (i.e. minimizing the sum of time steps required for agents to reach their goals).
p75
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p76
(dp77
g10
VIn combinatorial auctions, the auctioneer has items for sale, as in a regular auction. However, agents may bid on \u005cemph{bundles} of items, that is a set of items they wish to buy. Similarly, prices are assigned to bundles rather than individual items, supporting non-linear pricing of bundles.
p78
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p79
(dp80
g10
VIn iterative combinatorial auctions (ICA), the auction has multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. Iterative auctions require less effort from agents as they do not need to express their entire  preferences. We used the iBundle~\u005ccite{parkes2001iterative} ICA mechanism to solve the MAPF problem. In iBundle, each iteration includes three stages: (1) bidding; (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, that is bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p81
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p82
(dp83
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updates as follows: for each bundle that an ``unhappy'' agent (i.e. an agent that did not receive any of its bundles in the provisional allocation) bid on, the price is raised to the maximum bid received on the bundle by an unhappy agent plus $\u005cepsilon$, where $\u005cepsilon$ is the minimal increment size in the auction. Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agent who bid on them to switch to other bundles, or alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' update their bids. The auction terminates when the provisional allocation includes all of the agents, or when the same bids are submitted in two consequent rounds. In the approach section we describe how iBundle can be implemented to solve MAPF problems.
p84
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p85
(dp86
g10
VThe ICTS algorithm~\u005ccite{sharon2012increasing} consists of two levels. At the high-level, the search is performed on cost nodes that specify for each agent the cost of its paths to the goal that are considered in the current ICT node.
p87
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p88
(dp89
g10
VThe search starts from an ICT node with costs corresponding to the shortest paths costs for each of the agents ignoring the other agents. Then, nodes are expanded in a breadth-first manner, where each layer includes nodes with a specific sum of costs. Every time a node is expanded, the low-level search performs a goal test on the ICT node, checking whether there is a non-conflicting set of paths for the agents with the required costs. If the goal test passes, the algorithm terminates. If it does not, new ICT nodes are generated -- where each child node increases the cost for one of the agents, resulting in a total cost great by 1 then its parent node.
p90
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p91
(dp92
g10
VFor example, if the initial costs were 3,5 and 6 and a non-conflicting solution did not exist at these costs, three ICT child nodes will be generated, with  costs of ${4,5,6}$; ${3,6,6}$, and ${3,5,7}$. Because the ICT is searched in a breadth-first manner, an optimal solution is guaranteed (a node with a lower sum of costs will always be searched before nodes with higher sum of costs). To efficiently solve ICT nodes (i.e., perform a goal test), the low-level search uses multi-value decision diagrams (MDDs)~\u005ccite{srinivasan1990algorithms}. An MDD for a single agent and a given cost represents all possible paths from the starting location of the agent to its goal at the defined cost. Figure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. Note that if there are $V$ vertices in the graph representing the grid, there can be at most $V \u005ccdot C$ nodes in each level of an MDD of cost $C$. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps, as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD). In the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. We next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. In the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.
p93
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p94
(dp95
g10
VFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[<(0,1),t_1>,<(1,1),t_2>]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[<(0,2),t_1>,<(0,1),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(2,2),t_3,<(2,1),t_4>]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.
p96
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p97
(dp98
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, we efficiently represent bids using multi-value decision diagrams (MDDs)~\u005ccite{srinivasan1990algorithms} which were used in the ICTS algorithm to represent paths of different costs~\u005ccite{sharon2012increasing}. An MDD for a single agent and a given cost represents all possible paths from the starting location of the agent to its goal at the defined cost. Figure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. Note that if there are $V$ vertices in the graph representing the grid, there can be at most $V \u005ccdot C$ nodes in each level of an MDD of cost $C$. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps, as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD). Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the paths in the auction.
p99
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p100
(dp101
g10
VAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. At a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. Using MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. Figure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). We can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. In the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.   Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle.  We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. As in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.
p102
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p103
(dp104
g10
VFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. It has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$ because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. ICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. Let $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.
p105
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p106
(dp107
g10
V$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).
p108
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p109
(dp110
g10
VAssume that:It follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.
p111
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p112
(dp113
g10
VWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. In this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.
p114
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p115
(dp116
g10
VThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. In addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. 
p117
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p118
(dp119
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp120
sg10
VThis section presents and defines the MAPF problem and the iBundle auction mechanism. We also describe the increasing cost tree search (ICTS) algorithm for solving MAPF.\u000aIn iterative combinatorial auctions (ICA), the auction has multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An happy agent is defined as an agent that receives one of the items it bids on. The auction will terminate if (a) all agents are happy (this is the solution), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists)\u005cnote{Guni}{ Am I right?}. Iterative auctions require less effort from agents as they do not need to express their entire preferences. We used the iBundle~\u005ccite{parkes2001iterative} ICA mechanism to solve the MAPF problem.\u000aIn iBundle, each iteration includes three stages: (1) bidding; (2) winner determination, and (3) price update.\u000aIn the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, that is bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on the bundle by an unhappy agent plus $\u005cepsilon$, where $\u005cepsilon$ is the minimal increment size in the auction \u005cnote{Guni}{ I didnt understand this last (long) sentence?}. Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agent who bid on them to switch to other bundles, or alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' update their bids. \u005cnote{Guni}{ The new approach is conceptually different, we do not update prices we update revenue. This might cause confusion later on.}\u000aIn the approach section we describe how iBundle can be implemented to solve MAPF problems.\u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}.\u000aThe ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings; it is consists of two levels.\u000aThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.\u000aThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.\u000aFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aIn the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. \u000aWe next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. \u000aIn the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.\u000aFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[<(0,1),t_1>,<(1,1),t_2>]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[<(0,2),t_1>,<(0,1),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(2,2),t_3,<(2,1),t_4>]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, we efficiently represent bids using multi-value decision diagrams (MDDs)~\u005ccite{srinivasan1990algorithms} which were used in the ICTS algorithm to represent paths of different costs~\u005ccite{sharon2012increasing}. \u000aAn MDD for a single agent and a given cost represents all possible paths from the starting location of the agent to its goal at the defined cost. Figure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. Note that if there are $V$ vertices in the graph representing the grid, there can be at most $V \u005ccdot C$ nodes in each level of an MDD of cost $C$. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps, as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD). Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the paths in the auction.\u000aAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. \u000aAt a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. \u000aUsing MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. \u000aFigure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). \u000aWe can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. \u000aIn the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.  \u000a Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle. \u000a We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. \u000aAs in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. \u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$ because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. \u000aICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. \u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.\u000a$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).\u000aAssume that:\u000aIt follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.\u000aWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. \u000aIn this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.\u000aThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. \u000aIn addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. \u000a
p121
sg12
(lp122
(iversion
Paragraph
p123
(dp124
g10
VThis section presents and defines the MAPF problem and the iBundle auction mechanism. We also describe the increasing cost tree search (ICTS) algorithm for solving MAPF.
p125
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p126
(dp127
g10
VIn iterative combinatorial auctions (ICA), the auction has multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An happy agent is defined as an agent that receives one of the items it bids on. The auction will terminate if (a) all agents are happy (this is the solution), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists)\u005cnote{Guni}{ Am I right?}. Iterative auctions require less effort from agents as they do not need to express their entire preferences. We used the iBundle~\u005ccite{parkes2001iterative} ICA mechanism to solve the MAPF problem.
p128
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p129
(dp130
g10
VIn iBundle, each iteration includes three stages: (1) bidding; (2) winner determination, and (3) price update.
p131
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p132
(dp133
g10
VIn the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, that is bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p134
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p135
(dp136
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on the bundle by an unhappy agent plus $\u005cepsilon$, where $\u005cepsilon$ is the minimal increment size in the auction \u005cnote{Guni}{ I didnt understand this last (long) sentence?}. Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agent who bid on them to switch to other bundles, or alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' update their bids. \u005cnote{Guni}{ The new approach is conceptually different, we do not update prices we update revenue. This might cause confusion later on.}In the approach section we describe how iBundle can be implemented to solve MAPF problems.
p137
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p138
(dp139
g10
VIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}.
p140
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p141
(dp142
g10
VThe ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings; it is consists of two levels.
p143
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p144
(dp145
g10
VThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.
p146
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p147
(dp148
g10
VThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.
p149
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p150
(dp151
g10
VFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p152
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p153
(dp154
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p155
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p156
(dp157
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p158
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p159
(dp160
g10
VIn the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. We next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. In the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.
p161
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p162
(dp163
g10
VFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[<(0,1),t_1>,<(1,1),t_2>]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[<(0,2),t_1>,<(0,1),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(1,1),t_3,<(2,1),t_4>]$; $[<(0,2),t_1>,<(1,2),t_2,<(2,2),t_3,<(2,1),t_4>]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.
p164
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p165
(dp166
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, we efficiently represent bids using multi-value decision diagrams (MDDs)~\u005ccite{srinivasan1990algorithms} which were used in the ICTS algorithm to represent paths of different costs~\u005ccite{sharon2012increasing}. An MDD for a single agent and a given cost represents all possible paths from the starting location of the agent to its goal at the defined cost. Figure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. Note that if there are $V$ vertices in the graph representing the grid, there can be at most $V \u005ccdot C$ nodes in each level of an MDD of cost $C$. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps, as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD). Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the paths in the auction.
p167
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p168
(dp169
g10
VAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. At a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. Using MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. Figure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). We can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. In the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.   Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle.  We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. As in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.
p170
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p171
(dp172
g10
VFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. It has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$ because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. ICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. Let $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.
p173
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p174
(dp175
g10
V$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).
p176
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p177
(dp178
g10
VAssume that:It follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.
p179
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p180
(dp181
g10
VWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. In this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.
p182
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p183
(dp184
g10
VThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. In addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. 
p185
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p186
(dp187
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp188
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIterative combinatorial auction (ICA) is an auction mechanism composed of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is defined as an agent that receives one of the items it bids on. The auction will terminate if (a) all agents are happy (a solution was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists)\u005cnote{Guni}{ Am I right?}\u005cnote{Roni}{I assume there's another term for {\u005cem happy} that we should use, but have no clue what it is}. Iterative auctions require less effort from agents as they do not need to express their entire preferences. \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. \u000aIn iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on the bundle by an unhappy agent plus $\u005cepsilon$, where $\u005cepsilon$ is the minimal increment size in the auction \u005cnote{Guni}{ I didnt understand this last (long) sentence?}. Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agent who bid on them to switch to other bundles, or alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' update their bids. \u005cnote{Guni}{ The new approach is conceptually different, we do not update prices we update revenue. This might cause confusion later on.}\u005cnote{Roni}{We updated prices and the agents then update their bids to match the prices, resulting in more revenue.}\u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}.\u000aThe ICTS algorithm~\u005ccite{sharon2013increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it is consists of two levels.\u000aThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.\u000aThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.\u000aFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aIn the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. \u000aWe next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. \u000aIn the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.\u000aFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction.\u000aAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. \u000aAt a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. \u000aUsing MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. \u000aFigure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). \u000aWe can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. \u000aIn the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.  \u000a Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle. \u000a We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}\u005cnote{Roni}{Not necessarily.}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. \u000aAs in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. \u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$ and therefore will not change their bids until an increment of 1. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. \u000aICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. \u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.\u000a$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).\u000aAssume that:\u000aIt follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.\u000aWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. \u000aIn this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.\u000aThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. \u000aIn addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. \u000a
p189
sg12
(lp190
(iversion
Paragraph
p191
(dp192
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. Iterative combinatorial auction (ICA) is an auction mechanism composed of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is defined as an agent that receives one of the items it bids on. The auction will terminate if (a) all agents are happy (a solution was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists)\u005cnote{Guni}{ Am I right?}\u005cnote{Roni}{I assume there's another term for {\u005cem happy} that we should use, but have no clue what it is}. Iterative auctions require less effort from agents as they do not need to express their entire preferences. iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p193
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p194
(dp195
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on the bundle by an unhappy agent plus $\u005cepsilon$, where $\u005cepsilon$ is the minimal increment size in the auction \u005cnote{Guni}{ I didnt understand this last (long) sentence?}. Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agent who bid on them to switch to other bundles, or alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' update their bids. \u005cnote{Guni}{ The new approach is conceptually different, we do not update prices we update revenue. This might cause confusion later on.}\u005cnote{Roni}{We updated prices and the agents then update their bids to match the prices, resulting in more revenue.}In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}.
p196
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p197
(dp198
g10
VThe ICTS algorithm~\u005ccite{sharon2013increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it is consists of two levels.
p199
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p200
(dp201
g10
VThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.
p202
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p203
(dp204
g10
VThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.
p205
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p206
(dp207
g10
VFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p208
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p209
(dp210
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p211
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p212
(dp213
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p214
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p215
(dp216
g10
VIn the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. We next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. In the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.
p217
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p218
(dp219
g10
VFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.
p220
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p221
(dp222
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction.
p223
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p224
(dp225
g10
VAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. At a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. Using MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. Figure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). We can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. In the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.   Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle.  We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}\u005cnote{Roni}{Not necessarily.}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. As in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.
p226
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p227
(dp228
g10
VFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. It has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$ and therefore will not change their bids until an increment of 1. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. ICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. Let $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.
p229
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p230
(dp231
g10
V$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).
p232
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p233
(dp234
g10
VAssume that:It follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.
p235
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p236
(dp237
g10
VWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. In this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.
p238
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p239
(dp240
g10
VThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. In addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. 
p241
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p242
(dp243
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp244
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is defined as an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. \u000aIn iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction \u000aIntuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. \u000aThe ICTS algorithm~\u005ccite{sharon2013increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it is consists of two levels.\u000aThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.\u000aThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.\u000aFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aIn the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. \u000aWe next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. \u000aIn the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.\u000aFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction.\u000aAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. \u000aAt a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. \u000aUsing MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. \u000aFigure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). \u000aWe can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. \u000aIn the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.  \u000a Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle. \u000a We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}\u005cnote{Roni}{Not necessarily.}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. \u000aAs in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. \u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$ and therefore will not change their bids until an increment of 1. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. \u000aICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. \u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.\u000a$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).\u000aAssume that:\u000aIt follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.\u000aWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. \u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents strategy-proofness is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf an iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) ***add citation** then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, the existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex prefrences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. \u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative settings  is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) It results in an optimal allocation of paths, and (2) In contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict, sharon2012meta}. All algorithms were run as the low level search within the indpendence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents such that there is not interference between the different groups, leading to a lower effective size of problems. We limited the time allotted to the algorithms to 5 minutes. If no solution was found within 5 minute we consider it as a failure.\u000aThe top rows of table~\u005cref{tab:grids} show the runtime of the algorithms when solving problems on $3 \u005ctimes 3$ grids, with the number of agents ranging between 4 and 8. For each number of agents, we randomly generated 50 instances and averaged their results. The $k'$ column shows the average effective number of agents after ID. As can be seen in the table, ICTS performs best, followed by iBundle and CBS. The three algorithms were always successful at finding solutions to problems with up to 6 agents in the alloted time. With 7 agent, CBS succeeded in $92\u005c%$ of the instances while iBundle and CBS solved all instances successfully. With 8 agents, ICTS successfuly solved $94\u005c%$ of the instances, followed by iBundle with $84\u005c%$ and CBS with only $52\u005c%$. Overall, iBundle scales well with the number of agents and outperforms CBS in these grids. \u000aResults for $8 \u005ctimes 8$ grids are similar (bottom lines of table~\u005cref{tab:grids}) show a similar trend. \u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10.3     & 9.3     & 9.7      \u005c\u005c\u000a5 & 2.7 & 18.7     & 11.2    & 15.9     \u005c\u005c\u000a6 & 4.6 & 143.9    & 39.7    & 1297.6   \u005c\u005c\u000a7 & 6.4 & 3851.6   & 796.8   & 55979.4  \u005c\u005c\u000a8 & 7.6 & 108996.7 & 41943.6 & 168523.7 \u005c\u005c \u005chline\u000a8  & 1.7 & 18.4    & 15.3   & 19.1   \u005c\u005c\u000a9  & 2     & 29.1    & 17   & 35.3    \u005c\u005c\u000a10 & 2.3     & 243.3   & 22.4   & 32.8    \u005c\u005c\u000a11 & 2.4 & 45.2     & 27.1   & 114.3   \u005c\u005c\u000a12 & 3.4 & 6271.9  & 42.4   & 6132.8  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6350.8  \u005c\u005c\u000a14 & 4.8     & 16964.8 & 2186.5 & 42874\u000aWe also ran the algorithms on two ``Dragon Age'' maps  taken from Sturtevant's repository~\u005ccite{NATHANS} with the number of agents ranging between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (avergade over 50 randomly generated problem instances each). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5.0  & 1.0 & 262.4   & 41.4    & 72.7    \u005c\u005c\u000a10.0 & 1.1 & 455.5   & 177.8   & 12270.5 \u005c\u005c\u000a15.0 & 1.3 & 1263.9  & 319.2   & 5504.6  \u005c\u005c\u000a20.0 & 1.4 & 25037.9 & 18288.5 & 11750.5 \u005c\u005c\u000a25.0 & 1.5 & 4839.8  & 1298.2  & 27570.1 \u005c\u005c\u000a30.0 & 1.8 & 20321.9 & 7181.4  & 66519.5 \u005c\u005c \u005chline\u000a5  & 1.1     & 195.6   & 95.2    & 243.4    \u005c\u005c\u000a10 & 1.3 & 999.9   & 320.8    & 648      \u005c\u005c\u000a15 & 1.6 & 13122.5 & 7007.4  & 13415.6 \u005c\u005c\u000a20 & 1.7 & 13653.2 & 6759.2   & 23087.6 \u005c\u005c\u000a25 & 2 & 37646.1 & 14916.7 & 18246.2  \u005c\u005c\u000a30 & 2.5 & 73489.56 & 25048.2 & 6334 \u000aIn this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.\u000aThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. \u000aIn addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. \u000a
p245
sg12
(lp246
(iversion
Paragraph
p247
(dp248
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p249
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p250
(dp251
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is defined as an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p252
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p253
(dp254
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. The ICTS algorithm~\u005ccite{sharon2013increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it is consists of two levels.
p255
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p256
(dp257
g10
VThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.
p258
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p259
(dp260
g10
VThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.
p261
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p262
(dp263
g10
VFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p264
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p265
(dp266
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p267
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p268
(dp269
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p270
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p271
(dp272
g10
VIn the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. We next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. In the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.
p273
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p274
(dp275
g10
VFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.
p276
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p277
(dp278
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction.
p279
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p280
(dp281
g10
VAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. At a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. Using MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. Figure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). We can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. In the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.   Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle.  We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}\u005cnote{Roni}{Not necessarily.}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. As in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.
p282
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p283
(dp284
g10
VFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. It has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$ and therefore will not change their bids until an increment of 1. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. ICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. Let $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.
p285
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p286
(dp287
g10
V$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).
p288
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p289
(dp290
g10
VAssume that:It follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.
p291
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p292
(dp293
g10
VWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. Multi-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents making it non-beneficial for agents.
p294
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p295
(dp296
g10
VIn designing mechanisms for coordinating self-interested agents strategy-proofness is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If an iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) ***add citation** then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, the existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex prefrences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p297
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p298
(dp299
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p300
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p301
(dp302
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. To the best of our knowledge, the only mechanism proposed for non-cooperative settings  is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) It results in an optimal allocation of paths, and (2) In contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p303
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p304
(dp305
g10
VWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict, sharon2012meta}. All algorithms were run as the low level search within the indpendence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents such that there is not interference between the different groups, leading to a lower effective size of problems. We limited the time allotted to the algorithms to 5 minutes. If no solution was found within 5 minute we consider it as a failure.
p306
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p307
(dp308
g10
VThe top rows of table~\u005cref{tab:grids} show the runtime of the algorithms when solving problems on $3 \u005ctimes 3$ grids, with the number of agents ranging between 4 and 8. For each number of agents, we randomly generated 50 instances and averaged their results. The $k'$ column shows the average effective number of agents after ID. As can be seen in the table, ICTS performs best, followed by iBundle and CBS. The three algorithms were always successful at finding solutions to problems with up to 6 agents in the alloted time. With 7 agent, CBS succeeded in $92\u005c%$ of the instances while iBundle and CBS solved all instances successfully. With 8 agents, ICTS successfuly solved $94\u005c%$ of the instances, followed by iBundle with $84\u005c%$ and CBS with only $52\u005c%$. Overall, iBundle scales well with the number of agents and outperforms CBS in these grids. Results for $8 \u005ctimes 8$ grids are similar (bottom lines of table~\u005cref{tab:grids}) show a similar trend. {$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10.3     & 9.3     & 9.7      \u005c\u005c5 & 2.7 & 18.7     & 11.2    & 15.9     \u005c\u005c6 & 4.6 & 143.9    & 39.7    & 1297.6   \u005c\u005c7 & 6.4 & 3851.6   & 796.8   & 55979.4  \u005c\u005c8 & 7.6 & 108996.7 & 41943.6 & 168523.7 \u005c\u005c \u005chline8  & 1.7 & 18.4    & 15.3   & 19.1   \u005c\u005c9  & 2     & 29.1    & 17   & 35.3    \u005c\u005c10 & 2.3     & 243.3   & 22.4   & 32.8    \u005c\u005c11 & 2.4 & 45.2     & 27.1   & 114.3   \u005c\u005c12 & 3.4 & 6271.9  & 42.4   & 6132.8  \u005c\u005c13 & 3.7 & 331   & 54  & 6350.8  \u005c\u005c14 & 4.8     & 16964.8 & 2186.5 & 42874We also ran the algorithms on two ``Dragon Age'' maps  taken from Sturtevant's repository~\u005ccite{NATHANS} with the number of agents ranging between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (avergade over 50 randomly generated problem instances each). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p309
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p310
(dp311
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5.0  & 1.0 & 262.4   & 41.4    & 72.7    \u005c\u005c10.0 & 1.1 & 455.5   & 177.8   & 12270.5 \u005c\u005c15.0 & 1.3 & 1263.9  & 319.2   & 5504.6  \u005c\u005c20.0 & 1.4 & 25037.9 & 18288.5 & 11750.5 \u005c\u005c25.0 & 1.5 & 4839.8  & 1298.2  & 27570.1 \u005c\u005c30.0 & 1.8 & 20321.9 & 7181.4  & 66519.5 \u005c\u005c \u005chline5  & 1.1     & 195.6   & 95.2    & 243.4    \u005c\u005c10 & 1.3 & 999.9   & 320.8    & 648      \u005c\u005c15 & 1.6 & 13122.5 & 7007.4  & 13415.6 \u005c\u005c20 & 1.7 & 13653.2 & 6759.2   & 23087.6 \u005c\u005c25 & 2 & 37646.1 & 14916.7 & 18246.2  \u005c\u005c30 & 2.5 & 73489.56 & 25048.2 & 6334 In this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.
p312
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p313
(dp314
g10
VThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. In addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. 
p315
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p316
(dp317
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp318
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is defined as an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. \u000aIn iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction \u000aIntuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. \u000aThe ICTS algorithm~\u005ccite{sharon2013increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it is consists of two levels.\u000aThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.\u000aThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.\u000aFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aIn the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. \u000aWe next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. \u000aIn the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.\u000aFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction.\u000aAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. \u000aAt a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. \u000aUsing MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. \u000aFigure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). \u000aWe can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. \u000aIn the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.  \u000a Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle. \u000a We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}\u005cnote{Roni}{Not necessarily.}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. \u000aAs in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. \u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$ and therefore will not change their bids until an increment of 1. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. \u000aICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. \u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.\u000a$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).\u000aAssume that:\u000aIt follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.\u000aWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. \u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents strategy-proofness is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf an iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) ***add citation** then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, the existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex prefrences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. \u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative settings  is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) It results in an optimal allocation of paths, and (2) In contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.\u000ak & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chline\u000aCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chline\u000aTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.\u000ak & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chline\u000aCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chline\u000aNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10     & 9     & 10      \u005c\u005c\u000a5 & 2.7 & 19     & 11    & 16     \u005c\u005c\u000a6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c\u000a7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c\u000a8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline\u000a8  & 1.7 & 18    & 15   & 19   \u005c\u005c\u000a9  & 2   & 29    & 17   & 35    \u005c\u005c\u000a10 & 2.3 & 243   & 22   & 33    \u005c\u005c\u000a11 & 2.4 & 45     & 27   & 114   \u005c\u005c\u000a12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c\u000a14 & 4.8 & 16,965 & 2,187 & 42,874\u000aWe also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5  & 1.0 & 262   & 41    & 73    \u005c\u005c\u000a10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c\u000a15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c\u000a20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c\u000a25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c\u000a30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline\u000a5  & 1.1     & 196   & 95    & 243    \u005c\u005c\u000a10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c\u000a15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c\u000a20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c\u000a25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c\u000a30 & 2.5 & 73,490 & 25,048 & 6,334 \u000aIn this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.\u000aThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. \u000aIn addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. \u000a
p319
sg12
(lp320
(iversion
Paragraph
p321
(dp322
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p323
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p324
(dp325
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is defined as an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p326
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p327
(dp328
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. The ICTS algorithm~\u005ccite{sharon2013increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it is consists of two levels.
p329
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p330
(dp331
g10
VThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.
p332
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p333
(dp334
g10
VThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.
p335
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p336
(dp337
g10
VFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p338
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p339
(dp340
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p341
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p342
(dp343
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p344
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p345
(dp346
g10
VIn the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. Each item in the auction corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times which constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). It terminates when the provisional allocation includes all agents. We next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. In the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit. Agents' valuations for bundles, or paths, are relative -- if there is a path $A$ with cost $C$ and a path $B$ of cost $C+1$, an agent should be willing to pay up to one unit more on path $A$. However, there is no absolute limit to the amount the agent is willing to pay for a particular path.
p347
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p348
(dp349
g10
VFollowing a myopic best response bidding strategy~\u005ccite{parkes1999bundle}, agents bid at each round on paths that minimize the sum of travel cost, denoted $c$ and the current price of the path, denoted $p$. For example, given the problem shown in Figure~\u005cref{fig:mapf}, in the first round of the auction $a_1$ would bid on its shortest path, that is $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ would bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some other agent's paths, we extend their paths to match the longest paths by adding their last location to the next time steps\u005cfootnote{When agents reach their goals, they are assumed to stay there, such that other agents cannot occupy these locations.}.
p350
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p351
(dp352
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ would bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent at each cost. For example, the set of paths of cost 4 for agent $a_2$ includes waiting at each of the location in any of the paths of cost 3. As the auction progresses agents bid on paths of higher costs. This increase in the number of bundles (paths) agents bid on poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction.
p353
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p354
(dp355
g10
VAt the end of each round, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. The winner determination procedure requires costly computation: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. At a high-level, the winner determination has the following components: (1) generating the possible allocations; (2) checking whether the allocation is feasible, and (3) compute the revenue of each allocation and choose the one that gives the highest revenue. In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. Using MDDs, we reduce the complexity by solving save the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use the algorithm used by Sharon et al.~\u005ccite{sharon2012increasing} for solving an ICT node. Figure\u005cref{fig:mapf}(d) shows the resulting MDD of merging the MDDs for $a_1$ and $a_2$. In this merged MDD, each node includes two locations, one for each agent. While merging the MDDs, we delete nodes in which both agents occupy the same location. For example, the node marked in red in the figure will be deleted as both agents need to occupy location $(1,1)$. Paths that traverse through conflicting nodes are also deleted (shown in dashed lines in the figure). We can see that an allocation that includes $MDD^3_2$ and $MDD^1_1$ is valid, as there is one remaining path in the merged $MDD^{3,1}_{2,1}$ that gets both agents to their goals at the desired cost and without conflicting. This merging approach can be trivially extended to more than two agents, and a path on the merged MDD can be found using any search algorithm. Merging the MDDs is done using a matching and pruning algorithm from Sharon et al.~\u005ccite{sharon2012increasing}. Merged MDDs are then solved using the $A^*$ algorithm with a pre-computed perfect heuristic for individual agents' paths.  Importantly, this search is performed on a small subset of the entire search space for the given agents as it only considered paths of a given cost. In addition, prior to the search, the merged MDD is pruned for illegal paths. In the example problem shown in Figure~\u005cref{fig:mapf}, the provisional allocation at the end of the first round will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths and therefore one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation, while the third agent will remain ``unhappy''.   Interestingly, in typical auction applications the number of items is limited and can be decided by the auctioneer. In the pathfinding domain, because of the time dimension, the number of items is high. In addition, because agents have relative valuations, they submit many bids. In particular, they always keep bidding on paths that they bid on in previous rounds, whereas in typical auctions agents stop bidding on bundles when their price exceeds the agent's valuation of the bundle.  We implemented two different approaches to efficiently iterate candidate allocation. The first approach used a branch and bound algorithm in searching the space of possible allocations similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm}. The second approach utilizes the structure in agents' bids. We note that at each round of the auction, all candidate allocations from previous rounds that were not found to be infeasible will remain candidate allocation in all future rounds. Their revenue increases according to the number of agents in the allocation that were ``unhappy'' in the last round. In addition, each agent that was unhappy in the last round submits a bid on one new MDD. This MDD can potentially be added to any allocation that does not yet include another MDD of the same agent, and also forms a new candidate with only that MDD. We thus maintain a sorted list of these candidate allocations and update it at each round based on the changes described above (making sure to place the new candidates in the appropriate location based on their revenue). Then, we iterate the list in decreasing order of revenue, checking whether the candidate allocation is feasible. If it is not feasible, we prune it (because there is no point to consider it in the future with additional MDDs) and move to the next candidate allocation. If the allocation is feasible, it is the winner of that round. Because the list is sorted by revenue, we do not have to keep solving the remaining candidates. \u005cnote{Ofra}{do we need a pseudo-code for this?}\u005cnote{Roni}{Not necessarily.}. We found this approach to be more efficient than branch and bound.  Yet, the winner determination stage of the algorithm remains a major computational bottleneck. As in the iBundle auction, at the end of each iteration we increase the prices for bundles (paths) that agents who were not included in the provisional allocation (``unhappy agents'') bid on. Since we know that if an agent bid on an MDD and did not receive it, all the paths in that MDD conflicted with other agents, we increase prices for MDDs, rather than for each path separately. The price is incremented by $\u005cepsilon$ which is a parameter of the algorithm  \u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and are therefore not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If it happened to be the case that a path of an agent is a subset of a path of another agent, then pricing of these paths can be viewed as discriminatory, where the price for each agent is determined according to the price of its MDD.}.
p356
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p357
(dp358
g10
VFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}, the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional. Therefore, the price for the paths $a_3$ bid on, namely $MDD^4_3$, increases by $\u005cepsilon$. Assuming $\u005cepsilon=1$, this means that the price of $MDD^4_3$ is now 1, while the prices of  $MDD^3_2$ and $MDD^1_1$, as well as prices for any other MDDs that were not bid on yet, remain 0. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with an optimal (most efficient) allocation when agents bid according to myopic best response. However, decreasing the $\u005cepsilon$ leads to more rounds of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer rounds, each round requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, the agent will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are withing $\u005cepsilon$ of its best price and will thus bid on more MDDs (e.g. MDD of travel cost 5, 6, 7 and 8). This requires more computation at each iteration and therefore does not reduce complexity. It has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$ and therefore will not change their bids until an increment of 1. Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. ICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. Let $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.
p359
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p360
(dp361
g10
V$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).
p362
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p363
(dp364
g10
VAssume that:It follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.
p365
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p366
(dp367
g10
VWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. Multi-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents making it non-beneficial for agents.
p368
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p369
(dp370
g10
VIn designing mechanisms for coordinating self-interested agents strategy-proofness is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If an iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) ***add citation** then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, the existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex prefrences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p371
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p372
(dp373
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p374
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p375
(dp376
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. To the best of our knowledge, the only mechanism proposed for non-cooperative settings  is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) It results in an optimal allocation of paths, and (2) In contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p377
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p378
(dp379
g10
VWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.
p380
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p381
(dp382
g10
Vk & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chlineCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chlineTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.
p383
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p384
(dp385
g10
Vk & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chlineCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chlineNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.
p386
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p387
(dp388
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10     & 9     & 10      \u005c\u005c5 & 2.7 & 19     & 11    & 16     \u005c\u005c6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline8  & 1.7 & 18    & 15   & 19   \u005c\u005c9  & 2   & 29    & 17   & 35    \u005c\u005c10 & 2.3 & 243   & 22   & 33    \u005c\u005c11 & 2.4 & 45     & 27   & 114   \u005c\u005c12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c14 & 4.8 & 16,965 & 2,187 & 42,874We also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p389
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p390
(dp391
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5  & 1.0 & 262   & 41    & 73    \u005c\u005c10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline5  & 1.1     & 196   & 95    & 243    \u005c\u005c10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c30 & 2.5 & 73,490 & 25,048 & 6,334 In this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.
p392
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p393
(dp394
g10
VThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. In addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. 
p395
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p396
(dp397
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp398
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is defined as an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. \u000aIn iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction \u000aIntuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. \u000aThe ICTS algorithm~\u005ccite{sharon2013increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it is consists of two levels.\u000aThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.\u000aThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.\u000aFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aThis section describes how to implement iBundle in the MAPF domaim drawing on insights and techniques from both the MAPF and auction literatures. \u000aIn the auction, each item corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. I.e. waiting for one time step corresponds to spending one budget unit. These assumption are made in typical MAPF algorithms and are fitting with fully cooperative settings. We discuss extensions to more general settings later.\u000aWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$. \u000a Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$). \u000a % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.\u000aWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. \u000aFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.\u000aThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.\u000aFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).\u000aAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  \u000aThe winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. \u000aAt a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. \u000aThe pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.\u000aWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).\u000aPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the acution. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.\u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. \u000aICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. \u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.\u000a$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).\u000aAssume that:\u000aIt follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.\u000aWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. \u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents strategy-proofness is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf an iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) ***add citation** then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, the existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex prefrences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. \u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative settings  is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) It results in an optimal allocation of paths, and (2) In contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.\u000ak & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chline\u000aCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chline\u000aTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.\u000ak & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chline\u000aCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chline\u000aNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10     & 9     & 10      \u005c\u005c\u000a5 & 2.7 & 19     & 11    & 16     \u005c\u005c\u000a6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c\u000a7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c\u000a8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline\u000a8  & 1.7 & 18    & 15   & 19   \u005c\u005c\u000a9  & 2   & 29    & 17   & 35    \u005c\u005c\u000a10 & 2.3 & 243   & 22   & 33    \u005c\u005c\u000a11 & 2.4 & 45     & 27   & 114   \u005c\u005c\u000a12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c\u000a14 & 4.8 & 16,965 & 2,187 & 42,874\u000aWe also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5  & 1.0 & 262   & 41    & 73    \u005c\u005c\u000a10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c\u000a15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c\u000a20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c\u000a25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c\u000a30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline\u000a5  & 1.1     & 196   & 95    & 243    \u005c\u005c\u000a10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c\u000a15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c\u000a20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c\u000a25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c\u000a30 & 2.5 & 73,490 & 25,048 & 6,334 \u000aIn this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.\u000aThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. \u000aIn addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. \u000a
p399
sg12
(lp400
(iversion
Paragraph
p401
(dp402
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p403
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p404
(dp405
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is defined as an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p406
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p407
(dp408
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. The ICTS algorithm~\u005ccite{sharon2013increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it is consists of two levels.
p409
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p410
(dp411
g10
VThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.
p412
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p413
(dp414
g10
VThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.
p415
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p416
(dp417
g10
VFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p418
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p419
(dp420
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p421
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p422
(dp423
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p424
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p425
(dp426
g10
VThis section describes how to implement iBundle in the MAPF domaim drawing on insights and techniques from both the MAPF and auction literatures. In the auction, each item corresponds to a pair of grid location and time step, while bundles correspond to a set of locations and times that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. I.e. waiting for one time step corresponds to spending one budget unit. These assumption are made in typical MAPF algorithms and are fitting with fully cooperative settings. We discuss extensions to more general settings later.
p427
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p428
(dp429
g10
VWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$.  Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$).  % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.
p430
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p431
(dp432
g10
VWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. For example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.
p433
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p434
(dp435
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.
p436
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p437
(dp438
g10
VThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.
p439
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p440
(dp441
g10
VFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).
p442
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p443
(dp444
g10
VAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  The winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\u005cref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. At a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.
p445
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p446
(dp447
g10
VWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).
p448
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p449
(dp450
g10
VPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the acution. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}For example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.
p451
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p452
(dp453
g10
VIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. ICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. Let $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.
p454
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p455
(dp456
g10
V$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).
p457
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p458
(dp459
g10
VAssume that:It follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.
p460
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p461
(dp462
g10
VWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. Multi-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents making it non-beneficial for agents.
p463
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p464
(dp465
g10
VIn designing mechanisms for coordinating self-interested agents strategy-proofness is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If an iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) ***add citation** then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, the existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex prefrences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p466
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p467
(dp468
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p469
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p470
(dp471
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. To the best of our knowledge, the only mechanism proposed for non-cooperative settings  is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) It results in an optimal allocation of paths, and (2) In contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p472
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p473
(dp474
g10
VWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.
p475
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p476
(dp477
g10
Vk & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chlineCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chlineTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.
p478
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p479
(dp480
g10
Vk & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chlineCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chlineNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.
p481
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p482
(dp483
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10     & 9     & 10      \u005c\u005c5 & 2.7 & 19     & 11    & 16     \u005c\u005c6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline8  & 1.7 & 18    & 15   & 19   \u005c\u005c9  & 2   & 29    & 17   & 35    \u005c\u005c10 & 2.3 & 243   & 22   & 33    \u005c\u005c11 & 2.4 & 45     & 27   & 114   \u005c\u005c12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c14 & 4.8 & 16,965 & 2,187 & 42,874We also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p484
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p485
(dp486
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5  & 1.0 & 262   & 41    & 73    \u005c\u005c10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline5  & 1.1     & 196   & 95    & 243    \u005c\u005c10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c30 & 2.5 & 73,490 & 25,048 & 6,334 In this paper I have shown how an iterative combinatorial auction mechanism can be used to find efficient path allocations in multi-agent pathfinding problems. Several properties of the structure of MAPF problems raise challenges for implementing the auction mechanism, such as the large number of items and possible bundles. I have shown how efficient representations used in prior MAPF works can be used to efficiently represent bids and implemented a tractable winner determination procedure, using a cache and a branch and bound approach and verifying that allocations are not conflicting using prior MAPF state-of-the-art approaches. In addition, the auction mechanism was used within an independence-dependence algorithm that decomposes the problem to reduce the required computation.
p487
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p488
(dp489
g10
VThese preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. With additional improvements to the auction mechanism and the winner determination algorithm such as re-using more of the partial solutions that were already computed, I believe it would be possible to perform at least as well as the state-of-the-art algorithms. In addition to improving the auction mechanism for the MAPF problem, there are several additional interesting directions for future research. First, more investigations are needed to determine which MAPF algorithm is preferable based on the structure of the problem (e.g. number of agents, open vs. constrained grids etc.). Second, since the auction mechanism is a market-based mechanism in its essence, it can be used in self-interested multi-agent settings without modifications, assuming that agents will have real budgets. This relates to recent work on self-interested multi-agent pathfinding~\u005ccite{bnaya2013multi}. In addition, making the connection between the auction mechanisms and multi-agent planning allows further integration of known results and algorithms from the auctions literature to the MAPF domain. For example, we can explore using approximate winner determination algorithms to tradeoff optimality with computation time.  Finally, it would be interesting to consider ICTS as a possible mechanism for combinatorial auctions, where at each round prices are increased for all agents, but the actual payments are determined according to the solution found. 
p490
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p491
(dp492
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp493
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. \u000aIn iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction \u000aIntuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. \u000aThe ICTS algorithm~\u005ccite{sharon2013increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.\u000aThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.\u000aThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.\u000aFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both the MAPF and auction literature\u05d3. We use the term MAPF-iBundle to refer to this iBundle implementation. \u000aThe items in MAPF-iBundle are pairs of grid location and time step. A bundles correspond to a set of location-times pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. I.e. waiting for one time step corresponds to spending one budget unit. These assumption are made in typical MAPF algorithms and are fitting with fully cooperative settings. We discuss extensions to more general settings later.\u000aWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$. \u000a Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$). \u000a % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.\u000aWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. \u000aFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.\u000aThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.\u000aFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).\u000aAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  \u000aAt a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. \u000aWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).\u000aPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the acution. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.\u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. \u000aICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. \u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.\u000a$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).\u000aAssume that:\u000aIt follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.\u000aWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. \u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf an iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) ***add citation** then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, the existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. \u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) It results in an optimal allocation of paths, and (2) In contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.\u000ak & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chline\u000aCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chline\u000aTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.\u000ak & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chline\u000aCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chline\u000aNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10     & 9     & 10      \u005c\u005c\u000a5 & 2.7 & 19     & 11    & 16     \u005c\u005c\u000a6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c\u000a7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c\u000a8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline\u000a8  & 1.7 & 18    & 15   & 19   \u005c\u005c\u000a9  & 2   & 29    & 17   & 35    \u005c\u005c\u000a10 & 2.3 & 243   & 22   & 33    \u005c\u005c\u000a11 & 2.4 & 45     & 27   & 114   \u005c\u005c\u000a12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c\u000a14 & 4.8 & 16,965 & 2,187 & 42,874\u000aWe also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5  & 1.0 & 262   & 41    & 73    \u005c\u005c\u000a10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c\u000a15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c\u000a20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c\u000a25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c\u000a30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline\u000a5  & 1.1     & 196   & 95    & 243    \u005c\u005c\u000a10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c\u000a15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c\u000a20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c\u000a25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c\u000a30 & 2.5 & 73,490 & 25,048 & 6,334 \u000aIn this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agets are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. \u000a
p494
sg12
(lp495
(iversion
Paragraph
p496
(dp497
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p498
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p499
(dp500
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p501
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p502
(dp503
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. The ICTS algorithm~\u005ccite{sharon2013increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.
p504
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p505
(dp506
g10
VThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.
p507
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p508
(dp509
g10
VThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.
p510
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p511
(dp512
g10
VFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p513
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p514
(dp515
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p516
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p517
(dp518
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p519
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p520
(dp521
g10
VThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both the MAPF and auction literature\u05d3. We use the term MAPF-iBundle to refer to this iBundle implementation. The items in MAPF-iBundle are pairs of grid location and time step. A bundles correspond to a set of location-times pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. I.e. waiting for one time step corresponds to spending one budget unit. These assumption are made in typical MAPF algorithms and are fitting with fully cooperative settings. We discuss extensions to more general settings later.
p522
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p523
(dp524
g10
VWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$.  Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$).  % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.
p525
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p526
(dp527
g10
VWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. For example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.
p528
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p529
(dp530
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.
p531
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p532
(dp533
g10
VThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.
p534
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p535
(dp536
g10
VFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).
p537
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p538
(dp539
g10
VAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  At a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. We used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).
p540
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p541
(dp542
g10
VPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the acution. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}For example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.
p543
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p544
(dp545
g10
VIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$, however unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. ICTS and $iBundle$ differ in that ICTS performs a breadth-first search on the ICT, where for each node it only needs to check whether there is a feasible solution that includes \u005cemph{all} agents. This requires ICTS to solve all ICT nodes with $c<=c^*$, where $c^*$ is the cost of the optimal solution. In contrast, each round of the auction might examine several ICT nodes, including nodes with only subsets of the agents and chooses the allocation with the maximal revenue. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve, but at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. Let $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{delta_i}$. ICTS will need to expand $k^{\u005cDelta}$ until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$.
p546
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p547
(dp548
g10
V$iBundle$ might need to exand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that $iBundle$  will not expand ICT nodes with $C>\u005cDelta \u005ccdot k$. To show this we prove that if for every agent $i$, $m_i>=\u005csum\u005climits_{i=1}^k{\u005cdelta_j}$, then the bidding iteration will find a solution (i.e. the provisional allocation will include all agents and the auction will terminate).
p549
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p550
(dp551
g10
VAssume that:It follows from (2) that $\u005cexists i$ such that $i \u005cnotin PA$, where $PA$ is the set of agents in the provisional allocation.
p552
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p553
(dp554
g10
VWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. Multi-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.
p555
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p556
(dp557
g10
VIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If an iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) ***add citation** then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, the existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p558
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p559
(dp560
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p561
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p562
(dp563
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. To the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) It results in an optimal allocation of paths, and (2) In contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p564
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p565
(dp566
g10
VWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.
p567
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p568
(dp569
g10
Vk & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chlineCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chlineTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.
p570
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p571
(dp572
g10
Vk & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chlineCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chlineNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.
p573
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p574
(dp575
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10     & 9     & 10      \u005c\u005c5 & 2.7 & 19     & 11    & 16     \u005c\u005c6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline8  & 1.7 & 18    & 15   & 19   \u005c\u005c9  & 2   & 29    & 17   & 35    \u005c\u005c10 & 2.3 & 243   & 22   & 33    \u005c\u005c11 & 2.4 & 45     & 27   & 114   \u005c\u005c12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c14 & 4.8 & 16,965 & 2,187 & 42,874We also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p576
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p577
(dp578
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5  & 1.0 & 262   & 41    & 73    \u005c\u005c10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline5  & 1.1     & 196   & 95    & 243    \u005c\u005c10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c30 & 2.5 & 73,490 & 25,048 & 6,334 In this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agets are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. 
p579
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p580
(dp581
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp582
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. \u000aIn iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction \u000aIntuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. \u000aThe ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.\u000aThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.\u000aThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.\u000aFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both the MAPF and auction literature\u05d3. We use the term MAPF-iBundle to refer to this iBundle implementation. \u000aThe items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. I.e. waiting for one time step corresponds to spending one budget unit. These assumption are made in typical MAPF algorithms and are fitting with fully cooperative settings. Similar principles can be used if agents have different costs and different budgets.\u000aWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$. \u000a Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$). \u000a % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.\u000aWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. \u000aFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.\u000aThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.\u000aFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).\u000aAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  \u000aAt a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. \u000aThe winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.\u000aWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).\u000aPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the acution. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.\u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. \u000aICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node to (searching for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this prunning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. \u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$. \u000aMAPF-iBundle might need to expand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$. This also bounds the number of iterations in the auction to $\u005cDelta \u005ccdot k$. \u000aMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aTo prove this theorem we show that if for every agent $i$, $m_i>=\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$, then the bidding iteration will find a solution (i.e., the provisional allocation will include all agents and the auction will terminate). The proof is given in the attached Supplemental Materials.\u000aWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. \u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.\u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.\u000ak & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chline\u000aCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chline\u000aTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.\u000ak & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chline\u000aCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chline\u000aNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10     & 9     & 10      \u005c\u005c\u000a5 & 2.7 & 19     & 11    & 16     \u005c\u005c\u000a6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c\u000a7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c\u000a8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline\u000a8  & 1.7 & 18    & 15   & 19   \u005c\u005c\u000a9  & 2   & 29    & 17   & 35    \u005c\u005c\u000a10 & 2.3 & 243   & 22   & 33    \u005c\u005c\u000a11 & 2.4 & 45     & 27   & 114   \u005c\u005c\u000a12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c\u000a14 & 4.8 & 16,965 & 2,187 & 42,874\u000aWe also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5  & 1.0 & 262   & 41    & 73    \u005c\u005c\u000a10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c\u000a15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c\u000a20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c\u000a25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c\u000a30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline\u000a5  & 1.1     & 196   & 95    & 243    \u005c\u005c\u000a10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c\u000a15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c\u000a20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c\u000a25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c\u000a30 & 2.5 & 73,490 & 25,048 & 6,334 \u000aIn this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agets are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. \u000a
p583
sg12
(lp584
(iversion
Paragraph
p585
(dp586
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p587
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p588
(dp589
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p590
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p591
(dp592
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. The ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.
p593
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p594
(dp595
g10
VThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.
p596
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p597
(dp598
g10
VThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.
p599
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p600
(dp601
g10
VFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p602
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p603
(dp604
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p605
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p606
(dp607
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p608
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p609
(dp610
g10
VThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both the MAPF and auction literature\u05d3. We use the term MAPF-iBundle to refer to this iBundle implementation. The items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. I.e. waiting for one time step corresponds to spending one budget unit. These assumption are made in typical MAPF algorithms and are fitting with fully cooperative settings. Similar principles can be used if agents have different costs and different budgets.
p611
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p612
(dp613
g10
VWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$.  Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$).  % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.
p614
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p615
(dp616
g10
VWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. For example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.
p617
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p618
(dp619
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.
p620
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p621
(dp622
g10
VThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.
p623
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p624
(dp625
g10
VFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).
p626
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p627
(dp628
g10
VAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  At a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. The winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.
p629
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p630
(dp631
g10
VWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).
p632
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p633
(dp634
g10
VPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the acution. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}For example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.
p635
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p636
(dp637
g10
VIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. ICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node to (searching for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this prunning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. Let $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to exapnd nodes with $C>\u005cDelta$. MAPF-iBundle might need to expand deeper ICT nodes but it might not need to exand all ICT nodes at each level. We show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$. This also bounds the number of iterations in the auction to $\u005cDelta \u005ccdot k$. MAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.
p638
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p639
(dp640
g10
VTo prove this theorem we show that if for every agent $i$, $m_i>=\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$, then the bidding iteration will find a solution (i.e., the provisional allocation will include all agents and the auction will terminate). The proof is given in the attached Supplemental Materials.
p641
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p642
(dp643
g10
VWe note that ICTS can be viewed as a type of auction, where at each iteration the price is incremented by 1 to \u005cemph{all} agents (i.e. an iteration corresponds to expanding all ICT nodes of a certain cost). Then, it is possible to implement a price adjustment process based on the solution. That is, although agents were told that the price had increased, based on the solution we could adjust their price to a possibly lower price based on the actual solution that was found. Multi-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.
p644
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p645
(dp646
g10
VIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p647
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p648
(dp649
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p650
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p651
(dp652
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.
p653
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p654
(dp655
g10
VTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p656
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p657
(dp658
g10
VWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.
p659
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p660
(dp661
g10
Vk & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chlineCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chlineTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.
p662
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p663
(dp664
g10
Vk & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chlineCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chlineNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.
p665
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p666
(dp667
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10     & 9     & 10      \u005c\u005c5 & 2.7 & 19     & 11    & 16     \u005c\u005c6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline8  & 1.7 & 18    & 15   & 19   \u005c\u005c9  & 2   & 29    & 17   & 35    \u005c\u005c10 & 2.3 & 243   & 22   & 33    \u005c\u005c11 & 2.4 & 45     & 27   & 114   \u005c\u005c12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c14 & 4.8 & 16,965 & 2,187 & 42,874We also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p668
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p669
(dp670
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5  & 1.0 & 262   & 41    & 73    \u005c\u005c10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline5  & 1.1     & 196   & 95    & 243    \u005c\u005c10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c30 & 2.5 & 73,490 & 25,048 & 6,334 In this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agets are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. 
p671
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p672
(dp673
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp674
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. \u000aIn iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction \u000aIntuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. \u000aThe ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.\u000aThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.\u000aThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.\u000aFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. \u000aThe items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in typical MAPF algorithms. % and are fitting with fully cooperative settings. \u000aSimilar principles can be used if agents have different costs and different budgets.\u000aWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$. \u000a Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$). \u000a % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.\u000aWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. \u000aFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.\u000aThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.\u000aFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).\u000aAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  \u000aAt a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. \u000aThe winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.\u000aWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).\u000aPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the acution. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.\u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. \u000aICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node to (searching for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. \u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$. \u000aMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. We show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$. This also bounds the number of iterations in the auction to $\u005cDelta \u005ccdot k$. \u000aMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aTo prove this theorem we show that if for every agent $i$, $m_i>=\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$, then the bidding iteration will find a solution (i.e., the provisional allocation will include all agents and the auction will terminate). The proof is given in the attached supplement materials.\u000aA direct result of Theorem~\u005cref{the:delta} is the that number of iBundle-MAPF iterations is at most $k^2\u005ccdot\u005cDelta$.\u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.\u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.\u000ak & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chline\u000aCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chline\u000aTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.\u000ak & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chline\u000aCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chline\u000aNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10     & 9     & 10      \u005c\u005c\u000a5 & 2.7 & 19     & 11    & 16     \u005c\u005c\u000a6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c\u000a7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c\u000a8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline\u000a8  & 1.7 & 18    & 15   & 19   \u005c\u005c\u000a9  & 2   & 29    & 17   & 35    \u005c\u005c\u000a10 & 2.3 & 243   & 22   & 33    \u005c\u005c\u000a11 & 2.4 & 45     & 27   & 114   \u005c\u005c\u000a12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c\u000a14 & 4.8 & 16,965 & 2,187 & 42,874\u000aWe also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5  & 1.0 & 262   & 41    & 73    \u005c\u005c\u000a10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c\u000a15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c\u000a20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c\u000a25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c\u000a30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline\u000a5  & 1.1     & 196   & 95    & 243    \u005c\u005c\u000a10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c\u000a15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c\u000a20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c\u000a25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c\u000a30 & 2.5 & 73,490 & 25,048 & 6,334 \u000aIn this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agets are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. \u000a
p675
sg12
(lp676
(iversion
Paragraph
p677
(dp678
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p679
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p680
(dp681
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p682
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p683
(dp684
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. The ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.
p685
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p686
(dp687
g10
VThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.
p688
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p689
(dp690
g10
VThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.
p691
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p692
(dp693
g10
VFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p694
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p695
(dp696
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p697
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p698
(dp699
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p700
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p701
(dp702
g10
VThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. The items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in typical MAPF algorithms. % and are fitting with fully cooperative settings. Similar principles can be used if agents have different costs and different budgets.
p703
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p704
(dp705
g10
VWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$.  Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$).  % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.
p706
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p707
(dp708
g10
VWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. For example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.
p709
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p710
(dp711
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.
p712
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p713
(dp714
g10
VThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.
p715
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p716
(dp717
g10
VFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).
p718
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p719
(dp720
g10
VAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  At a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. The winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.
p721
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p722
(dp723
g10
VWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).
p724
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p725
(dp726
g10
VPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the acution. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}For example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.
p727
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p728
(dp729
g10
VIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. ICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node to (searching for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. Let $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$. MAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. We show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$. This also bounds the number of iterations in the auction to $\u005cDelta \u005ccdot k$. MAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.
p730
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p731
(dp732
g10
VTo prove this theorem we show that if for every agent $i$, $m_i>=\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$, then the bidding iteration will find a solution (i.e., the provisional allocation will include all agents and the auction will terminate). The proof is given in the attached supplement materials.
p733
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p734
(dp735
g10
VA direct result of Theorem~\u005cref{the:delta} is the that number of iBundle-MAPF iterations is at most $k^2\u005ccdot\u005cDelta$.
p736
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p737
(dp738
g10
VMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.
p739
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p740
(dp741
g10
VIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p742
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p743
(dp744
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p745
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p746
(dp747
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.
p748
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p749
(dp750
g10
VTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p751
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p752
(dp753
g10
VWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.
p754
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p755
(dp756
g10
Vk & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chlineCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chlineTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.
p757
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p758
(dp759
g10
Vk & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chlineCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chlineNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.
p760
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p761
(dp762
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10     & 9     & 10      \u005c\u005c5 & 2.7 & 19     & 11    & 16     \u005c\u005c6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline8  & 1.7 & 18    & 15   & 19   \u005c\u005c9  & 2   & 29    & 17   & 35    \u005c\u005c10 & 2.3 & 243   & 22   & 33    \u005c\u005c11 & 2.4 & 45     & 27   & 114   \u005c\u005c12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c14 & 4.8 & 16,965 & 2,187 & 42,874We also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p763
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p764
(dp765
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5  & 1.0 & 262   & 41    & 73    \u005c\u005c10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline5  & 1.1     & 196   & 95    & 243    \u005c\u005c10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c30 & 2.5 & 73,490 & 25,048 & 6,334 In this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agets are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. 
p766
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p767
(dp768
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp769
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. \u000aIn iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction \u000aIntuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. \u000aThe ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.\u000aThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.\u000aThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.\u000aFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. \u000aThe items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. \u000aSimilar principles can be used if agents have different costs and different budgets.\u000aWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$. \u000a Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$). \u000a % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.\u000aWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.\u000aFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.\u000aThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.\u000aFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).\u000aAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  \u000aAt a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. \u000aThe winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.\u000aWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).\u000aPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.\u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. \u000aICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node to (searching for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. \u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$. \u000aMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. We show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$. \u000aMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aTo prove this theorem we show that if for every agent $i$, $m_i>=\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$, then the bidding iteration will find a solution (i.e., the provisional allocation will include all agents and the auction will terminate). The proof is given in the attached supplement materials.\u000aA direct result of Theorem~\u005cref{the:delta} is the that number of iBundle-MAPF iterations is at most $k^2\u005ccdot\u005cDelta$.\u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.\u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.\u000ak & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chline\u000aCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chline\u000aTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.\u000ak & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chline\u000aCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chline\u000aNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10     & 9     & 10      \u005c\u005c\u000a5 & 2.7 & 19     & 11    & 16     \u005c\u005c\u000a6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c\u000a7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c\u000a8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline\u000a8  & 1.7 & 18    & 15   & 19   \u005c\u005c\u000a9  & 2   & 29    & 17   & 35    \u005c\u005c\u000a10 & 2.3 & 243   & 22   & 33    \u005c\u005c\u000a11 & 2.4 & 45     & 27   & 114   \u005c\u005c\u000a12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c\u000a14 & 4.8 & 16,965 & 2,187 & 42,874\u000aWe also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5  & 1.0 & 262   & 41    & 73    \u005c\u005c\u000a10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c\u000a15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c\u000a20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c\u000a25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c\u000a30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline\u000a5  & 1.1     & 196   & 95    & 243    \u005c\u005c\u000a10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c\u000a15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c\u000a20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c\u000a25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c\u000a30 & 2.5 & 73,490 & 25,048 & 6,334 \u000aIn this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. \u000a
p770
sg12
(lp771
(iversion
Paragraph
p772
(dp773
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p774
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p775
(dp776
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p777
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p778
(dp779
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. The ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.
p780
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p781
(dp782
g10
VThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.
p783
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p784
(dp785
g10
VThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.
p786
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p787
(dp788
g10
VFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p789
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p790
(dp791
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p792
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p793
(dp794
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p795
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p796
(dp797
g10
VThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. The items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. Similar principles can be used if agents have different costs and different budgets.
p798
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p799
(dp800
g10
VWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$.  Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$).  % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.
p801
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p802
(dp803
g10
VWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.
p804
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p805
(dp806
g10
VFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.
p807
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p808
(dp809
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.
p810
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p811
(dp812
g10
VThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.
p813
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p814
(dp815
g10
VFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).
p816
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p817
(dp818
g10
VAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  At a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. The winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.
p819
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p820
(dp821
g10
VWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).
p822
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p823
(dp824
g10
VPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}For example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.
p825
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p826
(dp827
g10
VIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1<m_1,...,c_k<m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS. ICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node to (searching for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation. Let $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the cost of the path for agent $i$ in the optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$. MAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. We show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$. MAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.
p828
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p829
(dp830
g10
VTo prove this theorem we show that if for every agent $i$, $m_i>=\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$, then the bidding iteration will find a solution (i.e., the provisional allocation will include all agents and the auction will terminate). The proof is given in the attached supplement materials.
p831
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p832
(dp833
g10
VA direct result of Theorem~\u005cref{the:delta} is the that number of iBundle-MAPF iterations is at most $k^2\u005ccdot\u005cDelta$.
p834
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p835
(dp836
g10
VMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.
p837
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p838
(dp839
g10
VIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p840
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p841
(dp842
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p843
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p844
(dp845
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.
p846
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p847
(dp848
g10
VTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p849
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p850
(dp851
g10
VWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.
p852
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p853
(dp854
g10
Vk & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chlineCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chlineTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.
p855
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p856
(dp857
g10
Vk & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chlineCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chlineNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.
p858
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p859
(dp860
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10     & 9     & 10      \u005c\u005c5 & 2.7 & 19     & 11    & 16     \u005c\u005c6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline8  & 1.7 & 18    & 15   & 19   \u005c\u005c9  & 2   & 29    & 17   & 35    \u005c\u005c10 & 2.3 & 243   & 22   & 33    \u005c\u005c11 & 2.4 & 45     & 27   & 114   \u005c\u005c12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c14 & 4.8 & 16,965 & 2,187 & 42,874We also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p861
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p862
(dp863
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5  & 1.0 & 262   & 41    & 73    \u005c\u005c10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline5  & 1.1     & 196   & 95    & 243    \u005c\u005c10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c30 & 2.5 & 73,490 & 25,048 & 6,334 In this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. 
p864
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p865
(dp866
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp867
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. \u000aIn iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction \u000aIntuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. \u000aThe ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.\u000aThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.\u000aThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.\u000aFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. \u000aThe items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. \u000aSimilar principles can be used if agents have different costs and different budgets.\u000aWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$. \u000a Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$). \u000a % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.\u000aWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.\u000aFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.\u000aThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.\u000aFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).\u000aAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  \u000aAt a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. \u000aThe winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.\u000aWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).\u000aPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.\u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1 \u005cleq m_1,...,c_k \u005cleq m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS.\u000aICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node, the goal test searches for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation.\u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the maximal cost of the path for agent $i$ over all possible optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$.\u000aMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. Next, we show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aTo prove this theorem we show that no agent $i$ can reach $m_i>\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$.\u000aThe proof is given in the attached supplement materials.\u000aA direct result of Theorem~\u005cref{the:delta} is the that number of MAPF-iBundle iterations is at most $k^2\u005ccdot\u005cDelta$.\u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.\u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.\u000ak & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chline\u000aCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chline\u000aTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.\u000ak & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chline\u000aCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chline\u000aiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chline\u000aNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10     & 9     & 10      \u005c\u005c\u000a5 & 2.7 & 19     & 11    & 16     \u005c\u005c\u000a6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c\u000a7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c\u000a8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline\u000a8  & 1.7 & 18    & 15   & 19   \u005c\u005c\u000a9  & 2   & 29    & 17   & 35    \u005c\u005c\u000a10 & 2.3 & 243   & 22   & 33    \u005c\u005c\u000a11 & 2.4 & 45     & 27   & 114   \u005c\u005c\u000a12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c\u000a14 & 4.8 & 16,965 & 2,187 & 42,874\u000aWe also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5  & 1.0 & 262   & 41    & 73    \u005c\u005c\u000a10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c\u000a15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c\u000a20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c\u000a25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c\u000a30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline\u000a5  & 1.1     & 196   & 95    & 243    \u005c\u005c\u000a10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c\u000a15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c\u000a20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c\u000a25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c\u000a30 & 2.5 & 73,490 & 25,048 & 6,334 \u000aIn this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. \u000a
p868
sg12
(lp869
(iversion
Paragraph
p870
(dp871
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p872
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p873
(dp874
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p875
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p876
(dp877
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. The ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.
p878
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p879
(dp880
g10
VThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.
p881
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p882
(dp883
g10
VThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.
p884
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p885
(dp886
g10
VFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p887
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p888
(dp889
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p890
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p891
(dp892
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p893
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p894
(dp895
g10
VThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. The items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. Similar principles can be used if agents have different costs and different budgets.
p896
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p897
(dp898
g10
VWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$.  Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$).  % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.
p899
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p900
(dp901
g10
VWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.
p902
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p903
(dp904
g10
VFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.
p905
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p906
(dp907
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.
p908
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p909
(dp910
g10
VThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.
p911
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p912
(dp913
g10
VFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).
p914
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p915
(dp916
g10
VAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  At a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. The winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.
p917
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p918
(dp919
g10
VWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).
p920
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p921
(dp922
g10
VPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}For example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.
p923
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p924
(dp925
g10
VIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1 \u005cleq m_1,...,c_k \u005cleq m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS.
p926
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p927
(dp928
g10
VICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node, the goal test searches for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation.
p929
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p930
(dp931
g10
VLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the maximal cost of the path for agent $i$ over all possible optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$.
p932
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p933
(dp934
g10
VMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. Next, we show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$.
p935
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p936
(dp937
g10
VMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.
p938
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p939
(dp940
g10
VTo prove this theorem we show that no agent $i$ can reach $m_i>\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$.
p941
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p942
(dp943
g10
VThe proof is given in the attached supplement materials.
p944
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p945
(dp946
g10
VA direct result of Theorem~\u005cref{the:delta} is the that number of MAPF-iBundle iterations is at most $k^2\u005ccdot\u005cDelta$.
p947
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p948
(dp949
g10
VMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.
p950
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p951
(dp952
g10
VIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p953
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p954
(dp955
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p956
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p957
(dp958
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.
p959
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p960
(dp961
g10
VTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p962
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p963
(dp964
g10
VWe evaluated iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.
p965
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p966
(dp967
g10
Vk & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chlineCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chlineTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.
p968
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p969
(dp970
g10
Vk & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chlineCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chlineiBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chlineNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to iBundle. Moreover, as discussed earlier, iBundle allows more flexibility.
p971
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p972
(dp973
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10     & 9     & 10      \u005c\u005c5 & 2.7 & 19     & 11    & 16     \u005c\u005c6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline8  & 1.7 & 18    & 15   & 19   \u005c\u005c9  & 2   & 29    & 17   & 35    \u005c\u005c10 & 2.3 & 243   & 22   & 33    \u005c\u005c11 & 2.4 & 45     & 27   & 114   \u005c\u005c12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c14 & 4.8 & 16,965 & 2,187 & 42,874We also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, iBundle performed slower than both ICTS and CBS for most sizes of agents.  iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p974
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p975
(dp976
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5  & 1.0 & 262   & 41    & 73    \u005c\u005c10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline5  & 1.1     & 196   & 95    & 243    \u005c\u005c10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c30 & 2.5 & 73,490 & 25,048 & 6,334 In this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. 
p977
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p978
(dp979
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp980
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. \u000aIn iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.\u000aIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction \u000aIntuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. \u000aThe ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.\u000aThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.\u000aThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.\u000aFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. \u000aThe items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. \u000aSimilar principles can be used if agents have different costs and different budgets.\u000aWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$. \u000a Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$). \u000a % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.\u000aWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.\u000aFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.\u000aThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.\u000aFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).\u000aAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  \u000aAt a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. \u000aThe winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.\u000aWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).\u000aPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.\u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1 \u005cleq m_1,...,c_k \u005cleq m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS.\u000aICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node, the goal test searches for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation.\u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the maximal cost of the path for agent $i$ over all possible optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$.\u000aMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. Next, we show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aTo prove this theorem we show that no agent $i$ can reach $m_i>\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$.\u000aThe proof is given in the attached supplement materials.\u000aA direct result of Theorem~\u005cref{the:delta} is the that number of MAPF-iBundle iterations is at most $k^2\u005ccdot\u005cDelta$.\u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.\u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated MAPF-iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.\u000a \u005cresizebox{8cm}{!}{%\u000ak & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chline\u000aCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chline\u000aMAPF-iBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chline\u000aTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, MAPF-iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents MAPF-iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.\u000ak & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chline\u000aCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chline\u000aMAPF-iBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chline\u000aNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, MAPF-iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while MAPF-iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to MAPF-iBundle. Moreover, as discussed earlier, MAPF-iBundle allows more flexibility.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10     & 9     & 10      \u005c\u005c\u000a5 & 2.7 & 19     & 11    & 16     \u005c\u005c\u000a6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c\u000a7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c\u000a8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline\u000a8  & 1.7 & 18    & 15   & 19   \u005c\u005c\u000a9  & 2   & 29    & 17   & 35    \u005c\u005c\u000a10 & 2.3 & 243   & 22   & 33    \u005c\u005c\u000a11 & 2.4 & 45     & 27   & 114   \u005c\u005c\u000a12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c\u000a14 & 4.8 & 16,965 & 2,187 & 42,874\u000aWe also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, MAPF-iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, MAPF-iBundle performed slower than both ICTS and CBS for most sizes of agents.  MAPF-iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5  & 1.0 & 262   & 41    & 73    \u005c\u005c\u000a10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c\u000a15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c\u000a20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c\u000a25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c\u000a30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline\u000a5  & 1.1     & 196   & 95    & 243    \u005c\u005c\u000a10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c\u000a15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c\u000a20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c\u000a25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c\u000a30 & 2.5 & 73,490 & 25,048 & 6,334 \u000aIn this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. \u000a
p981
sg12
(lp982
(iversion
Paragraph
p983
(dp984
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sell a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p985
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p986
(dp987
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bids on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the bidding stage, agents bid on bundles based on the current ask prices. Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles.
p988
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p989
(dp990
g10
VIn the winner determination process, the auctioneer determines a provisional allocation that maximizes revenue based on the current bids. An item can only be included in one bundle in the provisional allocation (that is, we cannot assign the same item to two different agents). Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$.  $\u005cepsilon$ is a parameter of the auction defining the minimal increment size in the auction Intuitively, this means that prices for bundles that include items with higher demand are raised as the auction progresses. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to ``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start position $s_i \u005cin V$ and goal position $g_i \u005cin V$. At each time step an agent can either {\u005cem move} to a neighboring location or can {\u005cem wait} in its current location. The task is to return the least-cost set of actions for all agents that will move each of the agents to its goal without {\u005cem conflicting} with other agents (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). MAPF has practical applications in robotics, video games, vehicle routing, and other domains~\u005ccite{silver2005coopeartive,dresner2008aMultiagent}. Optimally solving MAPF in its general form is NP-complete \u005ccite{surynek2010anOptimization}. The ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two levels.
p991
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p992
(dp993
g10
VThe high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$.
p994
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p995
(dp996
g10
VThe ICT is structured in such a way that there is a unique node in the tree for each possible combination of costs. The high-level phase searches the tree in an order that guarantees that the first solution found (i.e., ICT node whose $k$-vector corresponds to a valid solution) is optimal.
p997
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p998
(dp999
g10
VFor each ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p1000
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1001
(dp1002
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p1003
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1004
(dp1005
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p1006
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1007
(dp1008
g10
VThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. The items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. Similar principles can be used if agents have different costs and different budgets.
p1009
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1010
(dp1011
g10
VWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$.  Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$).  % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.
p1012
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1013
(dp1014
g10
VWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.
p1015
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1016
(dp1017
g10
VFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.
p1018
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1019
(dp1020
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.
p1021
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1022
(dp1023
g10
VThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.
p1024
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1025
(dp1026
g10
VFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).
p1027
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1028
(dp1029
g10
VAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  At a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. The winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.
p1030
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1031
(dp1032
g10
VWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).
p1033
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1034
(dp1035
g10
VPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}For example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.
p1036
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1037
(dp1038
g10
VIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1 \u005cleq m_1,...,c_k \u005cleq m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS.
p1039
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1040
(dp1041
g10
VICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node, the goal test searches for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation.
p1042
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1043
(dp1044
g10
VLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the maximal cost of the path for agent $i$ over all possible optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$.
p1045
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1046
(dp1047
g10
VMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. Next, we show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$.
p1048
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1049
(dp1050
g10
VMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.
p1051
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1052
(dp1053
g10
VTo prove this theorem we show that no agent $i$ can reach $m_i>\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$.
p1054
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1055
(dp1056
g10
VThe proof is given in the attached supplement materials.
p1057
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1058
(dp1059
g10
VA direct result of Theorem~\u005cref{the:delta} is the that number of MAPF-iBundle iterations is at most $k^2\u005ccdot\u005cDelta$.
p1060
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1061
(dp1062
g10
VMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily need to have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.
p1063
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1064
(dp1065
g10
VIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p1066
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1067
(dp1068
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p1069
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1070
(dp1071
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.
p1072
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1073
(dp1074
g10
VTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p1075
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1076
(dp1077
g10
VWe evaluated MAPF-iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.
p1078
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1079
(dp1080
g10
V \u005cresizebox{8cm}{!}{%k & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chlineCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chlineMAPF-iBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chlineTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, MAPF-iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents MAPF-iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.
p1081
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1082
(dp1083
g10
Vk & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chlineCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chlineMAPF-iBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chlineNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, MAPF-iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while MAPF-iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to MAPF-iBundle. Moreover, as discussed earlier, MAPF-iBundle allows more flexibility.
p1084
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1085
(dp1086
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10     & 9     & 10      \u005c\u005c5 & 2.7 & 19     & 11    & 16     \u005c\u005c6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline8  & 1.7 & 18    & 15   & 19   \u005c\u005c9  & 2   & 29    & 17   & 35    \u005c\u005c10 & 2.3 & 243   & 22   & 33    \u005c\u005c11 & 2.4 & 45     & 27   & 114   \u005c\u005c12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c14 & 4.8 & 16,965 & 2,187 & 42,874We also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, MAPF-iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, MAPF-iBundle performed slower than both ICTS and CBS for most sizes of agents.  MAPF-iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p1087
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1088
(dp1089
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5  & 1.0 & 262   & 41    & 73    \u005c\u005c10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline5  & 1.1     & 196   & 95    & 243    \u005c\u005c10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c30 & 2.5 & 73,490 & 25,048 & 6,334 In this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. 
p1090
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p1091
(dp1092
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp1093
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sale a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bid on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the {\u005cem bidding} stage, agents bid on bundles based on the current ask prices (this is the current pricing of items). Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles. \u000aIn the {\u005cem winner determination} process, the auctioneer determines an  allocation that maximizes revenue based on the current bids. This allocation is referred to as the provisional allocation. An item can only be included in one bundle in the provisional allocation. Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$, a parameter of the auction defining the minimal increment size in the auction. Intuitively, this means that as the auction progresses, prices are raised for bundles that include items with higher demand. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to give up and bid on other bundles instead.%``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start and goal positions $s_i,g_i \u005cin V$. At each time step an agent  either {\u005cem moves} to a neighboring location or {\u005cem waits} in its current location. A {\u005cem valid} solution is a set of paths, one for each agent, such that these paths leads the agents to their goals without conflicting (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). The task is to find least-cost set of actions that forms a valid solution.  See Figure~\u005cref{fig:mapf} for an example of a MAPF problem. \u000aThe ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two phases. The high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$. A goal ICT node contains a valid solution.\u000aThe high-level phase searches the ICT for a goal node in an order that guarantees that the first goal node that is found contains the optimal solution.\u000aFor every ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. \u000aThe items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. \u000aSimilar principles can be used if agents have different costs and different budgets.\u000aWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$. \u000a Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$). \u000a % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.\u000aWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.\u000aFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.\u000aThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.\u000aFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).\u000aAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  \u000aAt a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. \u000aThe winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.\u000aWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).\u000aPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.\u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1 \u005cleq m_1,...,c_k \u005cleq m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS.\u000aICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node, the goal test searches for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation.\u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the maximal cost of the path for agent $i$ over all possible optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$.\u000aMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. Next, we show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aTo prove this theorem we show that no agent $i$ can reach $m_i>\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$.\u000aThe proof is given in the attached supplement materials.\u000aA direct result of Theorem~\u005cref{the:delta} is the that number of MAPF-iBundle iterations is at most $k^2\u005ccdot\u005cDelta$.\u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.\u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated MAPF-iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.\u000a \u005cresizebox{8cm}{!}{%\u000ak & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chline\u000aCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chline\u000aMAPF-iBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chline\u000aTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, MAPF-iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents MAPF-iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.\u000ak & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chline\u000aCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chline\u000aMAPF-iBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chline\u000aNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, MAPF-iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while MAPF-iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to MAPF-iBundle. Moreover, as discussed earlier, MAPF-iBundle allows more flexibility.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10     & 9     & 10      \u005c\u005c\u000a5 & 2.7 & 19     & 11    & 16     \u005c\u005c\u000a6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c\u000a7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c\u000a8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline\u000a8  & 1.7 & 18    & 15   & 19   \u005c\u005c\u000a9  & 2   & 29    & 17   & 35    \u005c\u005c\u000a10 & 2.3 & 243   & 22   & 33    \u005c\u005c\u000a11 & 2.4 & 45     & 27   & 114   \u005c\u005c\u000a12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c\u000a14 & 4.8 & 16,965 & 2,187 & 42,874\u000aWe also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, MAPF-iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, MAPF-iBundle performed slower than both ICTS and CBS for most sizes of agents.  MAPF-iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5  & 1.0 & 262   & 41    & 73    \u005c\u005c\u000a10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c\u000a15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c\u000a20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c\u000a25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c\u000a30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline\u000a5  & 1.1     & 196   & 95    & 243    \u005c\u005c\u000a10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c\u000a15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c\u000a20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c\u000a25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c\u000a30 & 2.5 & 73,490 & 25,048 & 6,334 \u000aIn this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. \u000aBridging between auctions and MAPF opens the door for further integration of ideas. Insights and techniques from the auction literature can be adopted to the MAPF domain, for example using heuristics or approximate auction mechanisms. Similarly, techniques for reducing the complexity of MAPF problems might also be useful for auction mechanisms, and interpreting algorithms such as ICTS from an auction perspective might lead to novel auction mechanisms.\u000a
p1094
sg12
(lp1095
(iversion
Paragraph
p1096
(dp1097
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sale a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p1098
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1099
(dp1100
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bid on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the {\u005cem bidding} stage, agents bid on bundles based on the current ask prices (this is the current pricing of items). Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles. In the {\u005cem winner determination} process, the auctioneer determines an  allocation that maximizes revenue based on the current bids. This allocation is referred to as the provisional allocation. An item can only be included in one bundle in the provisional allocation. Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$, a parameter of the auction defining the minimal increment size in the auction. Intuitively, this means that as the auction progresses, prices are raised for bundles that include items with higher demand. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to give up and bid on other bundles instead.%``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start and goal positions $s_i,g_i \u005cin V$. At each time step an agent  either {\u005cem moves} to a neighboring location or {\u005cem waits} in its current location. A {\u005cem valid} solution is a set of paths, one for each agent, such that these paths leads the agents to their goals without conflicting (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). The task is to find least-cost set of actions that forms a valid solution.  See Figure~\u005cref{fig:mapf} for an example of a MAPF problem. The ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two phases. The high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$. A goal ICT node contains a valid solution.
p1101
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1102
(dp1103
g10
VThe high-level phase searches the ICT for a goal node in an order that guarantees that the first goal node that is found contains the optimal solution.
p1104
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1105
(dp1106
g10
VFor every ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p1107
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1108
(dp1109
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p1110
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1111
(dp1112
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p1113
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1114
(dp1115
g10
VThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. The items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. Similar principles can be used if agents have different costs and different budgets.
p1116
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1117
(dp1118
g10
VWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$.  Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$).  % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.
p1119
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1120
(dp1121
g10
VWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.
p1122
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1123
(dp1124
g10
VFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.
p1125
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1126
(dp1127
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.
p1128
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1129
(dp1130
g10
VThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.
p1131
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1132
(dp1133
g10
VFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).
p1134
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1135
(dp1136
g10
VAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  At a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. The winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.
p1137
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1138
(dp1139
g10
VWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).
p1140
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1141
(dp1142
g10
VPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}For example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.
p1143
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1144
(dp1145
g10
VIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1 \u005cleq m_1,...,c_k \u005cleq m_k$. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS.
p1146
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1147
(dp1148
g10
VICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node, the goal test searches for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation.
p1149
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1150
(dp1151
g10
VLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the maximal cost of the path for agent $i$ over all possible optimal allocation and $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$.
p1152
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1153
(dp1154
g10
VMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. Next, we show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$.
p1155
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1156
(dp1157
g10
VMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.
p1158
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1159
(dp1160
g10
VTo prove this theorem we show that no agent $i$ can reach $m_i>\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$.
p1161
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1162
(dp1163
g10
VThe proof is given in the attached supplement materials.
p1164
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1165
(dp1166
g10
VA direct result of Theorem~\u005cref{the:delta} is the that number of MAPF-iBundle iterations is at most $k^2\u005ccdot\u005cDelta$.
p1167
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1168
(dp1169
g10
VMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.
p1170
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1171
(dp1172
g10
VIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p1173
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1174
(dp1175
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p1176
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1177
(dp1178
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.
p1179
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1180
(dp1181
g10
VTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p1182
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1183
(dp1184
g10
VWe evaluated MAPF-iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.
p1185
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1186
(dp1187
g10
V \u005cresizebox{8cm}{!}{%k & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chlineCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chlineMAPF-iBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chlineTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, MAPF-iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents MAPF-iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.
p1188
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1189
(dp1190
g10
Vk & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chlineCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chlineMAPF-iBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chlineNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, MAPF-iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while MAPF-iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to MAPF-iBundle. Moreover, as discussed earlier, MAPF-iBundle allows more flexibility.
p1191
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1192
(dp1193
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10     & 9     & 10      \u005c\u005c5 & 2.7 & 19     & 11    & 16     \u005c\u005c6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline8  & 1.7 & 18    & 15   & 19   \u005c\u005c9  & 2   & 29    & 17   & 35    \u005c\u005c10 & 2.3 & 243   & 22   & 33    \u005c\u005c11 & 2.4 & 45     & 27   & 114   \u005c\u005c12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c14 & 4.8 & 16,965 & 2,187 & 42,874We also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, MAPF-iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, MAPF-iBundle performed slower than both ICTS and CBS for most sizes of agents.  MAPF-iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p1194
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1195
(dp1196
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5  & 1.0 & 262   & 41    & 73    \u005c\u005c10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline5  & 1.1     & 196   & 95    & 243    \u005c\u005c10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c30 & 2.5 & 73,490 & 25,048 & 6,334 In this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. Bridging between auctions and MAPF opens the door for further integration of ideas. Insights and techniques from the auction literature can be adopted to the MAPF domain, for example using heuristics or approximate auction mechanisms. Similarly, techniques for reducing the complexity of MAPF problems might also be useful for auction mechanisms, and interpreting algorithms such as ICTS from an auction perspective might lead to novel auction mechanisms.
p1197
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p1198
(dp1199
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp1200
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sale a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bid on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the {\u005cem bidding} stage, agents bid on bundles based on the current ask prices (this is the current pricing of items). Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles. \u000aIn the {\u005cem winner determination} process, the auctioneer determines an  allocation that maximizes revenue based on the current bids. This allocation is referred to as the provisional allocation. An item can only be included in one bundle in the provisional allocation. Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$, a parameter of the auction defining the minimal increment size in the auction. Intuitively, this means that as the auction progresses, prices are raised for bundles that include items with higher demand. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to give up and bid on other bundles instead.%``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start and goal positions $s_i,g_i \u005cin V$. At each time step an agent  either {\u005cem moves} to a neighboring location or {\u005cem waits} in its current location. A {\u005cem valid} solution is a set of paths, one for each agent, such that these paths leads the agents to their goals without conflicting (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). The task is to find least-cost set of actions that forms a valid solution.  See Figure~\u005cref{fig:mapf} for an example of a MAPF problem. \u000aThe ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two phases. The high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$. A goal ICT node contains a valid solution.\u000aThe high-level phase searches the ICT for a goal node in an order that guarantees that the first goal node that is found contains the optimal solution.\u000aFor every ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. \u000aThe items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. \u000aSimilar principles can be used if agents have different costs and different budgets.\u000aWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$. \u000a Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$). \u000a % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.\u000aWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.\u000aFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.\u000aThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.\u000aFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).\u000aAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  \u000aAt a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. \u000aThe winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.\u000aWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).\u000aPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.\u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1 \u005cleq opt_{1}+m_1,...,c_k \u005cleq opt_{k}+m_k$, where $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS.\u000aICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node, the goal test searches for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation.\u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the maximal cost of the path for agent $i$ over all possible optimal allocation. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$.\u000aMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. Next, we show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aTo prove this theorem we show that no agent $i$ can reach $m_i>\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$.\u000aThe proof is given in the attached supplement materials.\u000aA direct result of Theorem~\u005cref{the:delta} is the that number of MAPF-iBundle iterations is at most $k^2\u005ccdot\u005cDelta$.\u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.\u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated MAPF-iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.\u000a \u005cresizebox{8cm}{!}{%\u000ak & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chline\u000aCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chline\u000aMAPF-iBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chline\u000aTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, MAPF-iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents MAPF-iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.\u000ak & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chline\u000aCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chline\u000aMAPF-iBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chline\u000aNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, MAPF-iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while MAPF-iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to MAPF-iBundle. Moreover, as discussed earlier, MAPF-iBundle allows more flexibility.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10     & 9     & 10      \u005c\u005c\u000a5 & 2.7 & 19     & 11    & 16     \u005c\u005c\u000a6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c\u000a7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c\u000a8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline\u000a8  & 1.7 & 18    & 15   & 19   \u005c\u005c\u000a9  & 2   & 29    & 17   & 35    \u005c\u005c\u000a10 & 2.3 & 243   & 22   & 33    \u005c\u005c\u000a11 & 2.4 & 45     & 27   & 114   \u005c\u005c\u000a12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c\u000a14 & 4.8 & 16,965 & 2,187 & 42,874\u000aWe also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, MAPF-iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, MAPF-iBundle performed slower than both ICTS and CBS for most sizes of agents.  MAPF-iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5  & 1.0 & 262   & 41    & 73    \u005c\u005c\u000a10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c\u000a15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c\u000a20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c\u000a25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c\u000a30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline\u000a5  & 1.1     & 196   & 95    & 243    \u005c\u005c\u000a10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c\u000a15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c\u000a20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c\u000a25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c\u000a30 & 2.5 & 73,490 & 25,048 & 6,334 \u000aIn this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. \u000aBridging between auctions and MAPF opens the door for further integration of ideas. Insights and techniques from the auction literature can be adopted to the MAPF domain, for example using heuristics or approximate auction mechanisms. Similarly, techniques for reducing the complexity of MAPF problems might also be useful for auction mechanisms, and interpreting algorithms such as ICTS from an auction perspective might lead to novel auction mechanisms.\u000a
p1201
sg12
(lp1202
(iversion
Paragraph
p1203
(dp1204
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sale a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p1205
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1206
(dp1207
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bid on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the {\u005cem bidding} stage, agents bid on bundles based on the current ask prices (this is the current pricing of items). Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles. In the {\u005cem winner determination} process, the auctioneer determines an  allocation that maximizes revenue based on the current bids. This allocation is referred to as the provisional allocation. An item can only be included in one bundle in the provisional allocation. Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$, a parameter of the auction defining the minimal increment size in the auction. Intuitively, this means that as the auction progresses, prices are raised for bundles that include items with higher demand. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to give up and bid on other bundles instead.%``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start and goal positions $s_i,g_i \u005cin V$. At each time step an agent  either {\u005cem moves} to a neighboring location or {\u005cem waits} in its current location. A {\u005cem valid} solution is a set of paths, one for each agent, such that these paths leads the agents to their goals without conflicting (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). The task is to find least-cost set of actions that forms a valid solution.  See Figure~\u005cref{fig:mapf} for an example of a MAPF problem. The ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two phases. The high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$. A goal ICT node contains a valid solution.
p1208
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1209
(dp1210
g10
VThe high-level phase searches the ICT for a goal node in an order that guarantees that the first goal node that is found contains the optimal solution.
p1211
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1212
(dp1213
g10
VFor every ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p1214
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1215
(dp1216
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p1217
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1218
(dp1219
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p1220
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1221
(dp1222
g10
VThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. The items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. Similar principles can be used if agents have different costs and different budgets.
p1223
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1224
(dp1225
g10
VWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$.  Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$).  % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.
p1226
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1227
(dp1228
g10
VWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.
p1229
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1230
(dp1231
g10
VFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.
p1232
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1233
(dp1234
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.
p1235
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1236
(dp1237
g10
VThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.
p1238
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1239
(dp1240
g10
VFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).
p1241
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1242
(dp1243
g10
VAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  At a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. The winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.
p1244
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1245
(dp1246
g10
VWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).
p1247
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1248
(dp1249
g10
VPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}For example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.
p1250
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1251
(dp1252
g10
VIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1 \u005cleq opt_{1}+m_1,...,c_k \u005cleq opt_{k}+m_k$, where $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS.
p1253
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1254
(dp1255
g10
VICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node, the goal test searches for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation.
p1256
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1257
(dp1258
g10
VLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the maximal cost of the path for agent $i$ over all possible optimal allocation. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$.
p1259
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1260
(dp1261
g10
VMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. Next, we show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$.
p1262
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1263
(dp1264
g10
VMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cDelta \u005ccdot k$.
p1265
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1266
(dp1267
g10
VTo prove this theorem we show that no agent $i$ can reach $m_i>\u005csum\u005climits_{j=1}^k{\u005cdelta_{j}}$.
p1268
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1269
(dp1270
g10
VThe proof is given in the attached supplement materials.
p1271
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1272
(dp1273
g10
VA direct result of Theorem~\u005cref{the:delta} is the that number of MAPF-iBundle iterations is at most $k^2\u005ccdot\u005cDelta$.
p1274
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1275
(dp1276
g10
VMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.
p1277
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1278
(dp1279
g10
VIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p1280
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1281
(dp1282
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p1283
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1284
(dp1285
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.
p1286
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1287
(dp1288
g10
VTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p1289
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1290
(dp1291
g10
VWe evaluated MAPF-iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.
p1292
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1293
(dp1294
g10
V \u005cresizebox{8cm}{!}{%k & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chlineCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chlineMAPF-iBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chlineTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, MAPF-iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents MAPF-iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.
p1295
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1296
(dp1297
g10
Vk & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chlineCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chlineMAPF-iBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chlineNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, MAPF-iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while MAPF-iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to MAPF-iBundle. Moreover, as discussed earlier, MAPF-iBundle allows more flexibility.
p1298
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1299
(dp1300
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10     & 9     & 10      \u005c\u005c5 & 2.7 & 19     & 11    & 16     \u005c\u005c6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline8  & 1.7 & 18    & 15   & 19   \u005c\u005c9  & 2   & 29    & 17   & 35    \u005c\u005c10 & 2.3 & 243   & 22   & 33    \u005c\u005c11 & 2.4 & 45     & 27   & 114   \u005c\u005c12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c14 & 4.8 & 16,965 & 2,187 & 42,874We also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, MAPF-iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, MAPF-iBundle performed slower than both ICTS and CBS for most sizes of agents.  MAPF-iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p1301
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1302
(dp1303
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5  & 1.0 & 262   & 41    & 73    \u005c\u005c10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline5  & 1.1     & 196   & 95    & 243    \u005c\u005c10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c30 & 2.5 & 73,490 & 25,048 & 6,334 In this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. Bridging between auctions and MAPF opens the door for further integration of ideas. Insights and techniques from the auction literature can be adopted to the MAPF domain, for example using heuristics or approximate auction mechanisms. Similarly, techniques for reducing the complexity of MAPF problems might also be useful for auction mechanisms, and interpreting algorithms such as ICTS from an auction perspective might lead to novel auction mechanisms.
p1304
sg17
I00
sg18
Nsg19
Nsbasba(iversion
Version
p1305
(dp1306
g7
g8
(S'\x07\xd5\x08\x1a\x12/\x18\x00\x00\x00'
tRp1307
sg10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. \u000aIn combinatorial auction the auctioneer puts up for sale a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.\u000aIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bid on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). \u000aiBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the {\u005cem bidding} stage, agents bid on bundles based on the current ask prices (this is the current pricing of items). Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles. \u000aIn the {\u005cem winner determination} process, the auctioneer determines an  allocation that maximizes revenue based on the current bids. This allocation is referred to as the provisional allocation. An item can only be included in one bundle in the provisional allocation. Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$, a parameter of the auction defining the minimal increment size in the auction. Intuitively, this means that as the auction progresses, prices are raised for bundles that include items with higher demand. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to give up and bid on other bundles instead.%``lose'' and update their bids. \u000aIn the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start and goal positions $s_i,g_i \u005cin V$. At each time step an agent  either {\u005cem moves} to a neighboring location or {\u005cem waits} in its current location. A {\u005cem valid} solution is a set of paths, one for each agent, such that these paths leads the agents to their goals without conflicting (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). The task is to find least-cost set of actions that forms a valid solution.  See Figure~\u005cref{fig:mapf} for an example of a MAPF problem. \u000aThe ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two phases. The high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$. A goal ICT node contains a valid solution.\u000aThe high-level phase searches the ICT for a goal node in an order that guarantees that the first goal node that is found contains the optimal solution.\u000aFor every ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.\u000aThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.\u000aICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.\u000aThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. \u000aThe items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. \u000aSimilar principles can be used if agents have different costs and different budgets.\u000aWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$. \u000a Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$). \u000a % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.\u000aWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.\u000aFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.\u000aAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). \u000aImportantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.\u000aThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.\u000aFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).\u000aAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  \u000aAt a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. \u000aThe winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.\u000aWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).\u000aPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}\u000aFor example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. \u000aThe choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. \u000aInterestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.\u000aIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. \u000aFrom the pathfinding perspective, the auction can be viewed as a three-level algorithm:\u000aWe note that level 2 is equivalent to spanning an ICT with costs $c_1 \u005cleq opt_{1}+m_1,...,c_k \u005cleq opt_{k}+m_k$, where $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS.\u000aICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node, the goal test searches for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation.\u000aLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the maximal cost of the path for agent $i$ over all possible optimal allocation. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$.\u000aMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. Next, we show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$.\u000aMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cmax_{a_j}\u005cdelta_j \u005ccdot k^2$.\u000aWe prove this by proving that no agent $i$ can reach $m_i>k\u005ccdot \u005cmax_{a_j}\u005cdelta_j$. We omit the details of this proof due to space limitation.\u000aA direct result of Theorem~\u005cref{the:delta} is the that number of MAPF-iBundle iterations is at most $\u005cmax_{a_j}\u005cdelta_j \u005ccdot k^2$.\u000aMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. \u000aThe auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.\u000aIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. \u000aIf  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. \u000aTheoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).\u000aICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.\u000aICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.\u000aTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).\u000aWe evaluated MAPF-iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.\u000a \u005cresizebox{8cm}{!}{%\u000ak & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chline\u000aCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chline\u000aMAPF-iBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chline\u000aTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, MAPF-iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents MAPF-iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.\u000ak & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chline\u000aCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chline\u000aMAPF-iBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chline\u000aICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chline\u000aNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, MAPF-iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while MAPF-iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to MAPF-iBundle. Moreover, as discussed earlier, MAPF-iBundle allows more flexibility.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a4 & 2.2 & 10     & 9     & 10      \u005c\u005c\u000a5 & 2.7 & 19     & 11    & 16     \u005c\u005c\u000a6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c\u000a7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c\u000a8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline\u000a8  & 1.7 & 18    & 15   & 19   \u005c\u005c\u000a9  & 2   & 29    & 17   & 35    \u005c\u005c\u000a10 & 2.3 & 243   & 22   & 33    \u005c\u005c\u000a11 & 2.4 & 45     & 27   & 114   \u005c\u005c\u000a12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c\u000a13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c\u000a14 & 4.8 & 16,965 & 2,187 & 42,874\u000aWe also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, MAPF-iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, MAPF-iBundle performed slower than both ICTS and CBS for most sizes of agents.  MAPF-iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.\u000a{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline\u000a5  & 1.0 & 262   & 41    & 73    \u005c\u005c\u000a10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c\u000a15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c\u000a20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c\u000a25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c\u000a30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline\u000a5  & 1.1     & 196   & 95    & 243    \u005c\u005c\u000a10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c\u000a15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c\u000a20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c\u000a25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c\u000a30 & 2.5 & 73,490 & 25,048 & 6,334 \u000aIn this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. \u000aBridging between auctions and MAPF opens the door for further integration of ideas. Insights and techniques from the auction literature can be adopted to the MAPF domain, for example using heuristics or approximate auction mechanisms. Similarly, techniques for reducing the complexity of MAPF problems might also be useful for auction mechanisms, and interpreting algorithms such as ICTS from an auction perspective might lead to novel auction mechanisms.\u000a
p1308
sg12
(lp1309
(iversion
Paragraph
p1310
(dp1311
g10
VTo describe the relation between ICA, MAPF, and ICTS, we first provide background on both. In combinatorial auction the auctioneer puts up for sale a set of items $M$ and agents bid on bundles of items $B \u005csubset M$. The auction determines a final allocation of bundles based on agents' bids, such that no item is sold to more than one agent.
p1312
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1313
(dp1314
g10
VIterative combinatorial auctions (ICA) are an auction mechanism consisting of multiple rounds (iterations). At each iteration, agents submit bids and the auctioneer updates prices, until the auction terminates. An {\u005cem happy} agent is an agent that receives one of the bundles it bid on. The auction terminates when (a) all agents are happy (a feasible allocation was found), or (b) all agents place exactly the same set of bids in successive iterations (no solution exists). iBundle~\u005ccite{parkes2001iterative} is an example of a well-known ICA mechanism. In iBundle, each iteration includes three stages: (1) bidding, (2) winner determination, and (3) price update. In the {\u005cem bidding} stage, agents bid on bundles based on the current ask prices (this is the current pricing of items). Agents can submit $XOR$ bids, i.e., bid on alternative bundles that they desire but stating that they wish to receive at most one of those bundles. In the {\u005cem winner determination} process, the auctioneer determines an  allocation that maximizes revenue based on the current bids. This allocation is referred to as the provisional allocation. An item can only be included in one bundle in the provisional allocation. Finally, prices are updated as follows: for each bundle that an ``unhappy'' agent bid on, the price is raised to the maximum bid received on that bundle by an unhappy agent plus $\u005cepsilon$, a parameter of the auction defining the minimal increment size in the auction. Intuitively, this means that as the auction progresses, prices are raised for bundles that include items with higher demand. This might cause the agents who bid on them to switch to other bundles. Alternatively, if agents have a high valuation for a bundle they will keep bidding on it despite the higher prices, leading other agents to give up and bid on other bundles instead.%``lose'' and update their bids. In the {\u005cem multi-agent path finding} (MAPF) problem, we are given a graph, $G(V,E)$, and a set of $k$ agents labeled $a_1 \u005cdots a_k$. Each agent $a_i$ has a start and goal positions $s_i,g_i \u005cin V$. At each time step an agent  either {\u005cem moves} to a neighboring location or {\u005cem waits} in its current location. A {\u005cem valid} solution is a set of paths, one for each agent, such that these paths leads the agents to their goals without conflicting (i.e., without being in the same location at the same time or crossing the same edge simultaneously in opposite directions). The task is to find least-cost set of actions that forms a valid solution.  See Figure~\u005cref{fig:mapf} for an example of a MAPF problem. The ICTS algorithm~\u005ccite{sharon2012increasing} is novel MAPF solver considered state-of-the-art in many settings~\u005ccite{sharon2012meta}; it consists of two phases. The high-level phase performs a search on a search tree called the {\u005cem increasing cost tree} (ICT). Each node in the ICT consists of a $k$-vector $\u005c{C_1,C_2, \u005cldots C_k\u005c}$, where $k$ is the number of agents in the problem. An ICT node represents {\u005cem all} possible solutions in which the cost of the individual path of each agent $a_i$ is exactly $C_i$. A goal ICT node contains a valid solution.
p1315
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1316
(dp1317
g10
VThe high-level phase searches the ICT for a goal node in an order that guarantees that the first goal node that is found contains the optimal solution.
p1318
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1319
(dp1320
g10
VFor every ICT node visited, the high-level phase invokes the low-level phase to check if there is a valid solution that is represented by this ICT node. The low-level phase itself consists of a search in the space of possible solutions where the costs of the different agents are given by the specification of the high-level ICT node.
p1321
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1322
(dp1323
g10
VThis is performed using a variant of the {\u005cem multi-value decision diagram} (MDD)~\u005ccite{srinivasan1990algorithms} . The MDD data-structure stores all possible paths for a given cost and a given agent. The low-level phase searches for a valid (non-conflicting) solution amongst all the possible single-agent paths, represented by the MDDs.
p1324
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1325
(dp1326
g10
VICTS also uses special pruning techniques that can quickly identify ICT nodes that do not represent any valid solution. These pruning techniques are based on examining small groups of agents (such as pairs or triples) and identifying internal conflicts that preclude the given ICT node from representing a valid solution. When such an ICT node is identified, there is no need to activate the low-level search and the high-level search can proceed to the next ICT node.
p1327
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1328
(dp1329
g10
VThis section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both MAPF and auction literature. We use the term MAPF-iBundle to refer to this iBundle implementation. The items in MAPF-iBundle are pairs of location and time. A bundles correspond to a set of location-time pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. Waiting for one time step corresponds to spending one budget unit. These assumption are common in MAPF algorithms. % and are fitting with fully cooperative settings. Similar principles can be used if agents have different costs and different budgets.
p1330
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1331
(dp1332
g10
VWe use as a running example the problem shown in Figure~\u005cref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$.  Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$).  % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.
p1333
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1334
(dp1335
g10
VWe implemented a myopic best response bidding strategy~\u005ccite{parkes1999bundle} for the agents. According to this strategy, agents bid on their best bundles at each iteration given the current prices and always place bids with the current price (e.g., they are not considering raising the price before it has been raised by the auctioneer). This is a reasonable strategy for agents, and it has been shown that myopic best response is the best strategy for an agent given that other agents are acting based on this strategy~\u005ccite{parkes2001iterative}.  In MAPF, myopic best response means that agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. They bid on these paths with the current ask price.
p1336
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1337
(dp1338
g10
VFor example, in the first iteration of an auction solving the problem shown in Figure~\u005cref{fig:mapf}, $a_1$ would bid on its shortest path, $[\u005clangle(0,1),t_1\u005crangle,\u005clangle(1,1),t_2\u005crangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\u005clangle(0,2),t_1\u005crangle,\u005clangle(0,1),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(1,1),t_3,\u005clangle(2,1),t_4\u005crangle]$; $[\u005clangle(0,2),t_1\u005crangle,\u005clangle(1,2),t_2,\u005clangle(2,2),t_3,\u005clangle(2,1),t_4\u005crangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.
p1339
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1340
(dp1341
g10
VAs prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). Importantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.
p1342
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1343
(dp1344
g10
VThis increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\u005clangle mdd,p_{mdd} \u005crangle$.
p1345
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1346
(dp1347
g10
VFigure~\u005cref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\u005cref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).
p1348
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1349
(dp1350
g10
VAt the end of each iteration, a \u005cemph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\u005cref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  At a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. The winner determination problem is computationally hard~\u005ccite{sandholm2002algorithm}. The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.
p1351
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1352
(dp1353
g10
VWe used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\u005ccite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\u005ccite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).
p1354
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1355
(dp1356
g10
VPrice updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the auction. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\u005cfootnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\u005ccite{parkes2001iterative}.}For example, recall that at the end of the first iteration of an auction for the problem from Figure~\u005cref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\u005cepsilon$. The choice of $\u005cepsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\u005cepsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\u005cepsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. Interestingly, due to the particular valuation function in MAPF, while increasing $\u005cepsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\u005cepsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.
p1357
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1358
(dp1359
g10
VIt has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\u005cepsilon \u005crightarrow 0$~\u005ccite{parkes2006iterative}. In the pathfinding domain, settings $\u005cepsilon = 1$ would result in the same bids as setting any $\u005cepsilon \u005crightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\u005cepsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. From the pathfinding perspective, the auction can be viewed as a three-level algorithm:We note that level 2 is equivalent to spanning an ICT with costs $c_1 \u005cleq opt_{1}+m_1,...,c_k \u005cleq opt_{k}+m_k$, where $opt_i$ denotes the cost of the optimal path for $i$ disregarding other agents. However, unlike ICTS these nodes also include ICT nodes with only a subset of the agents. Level 3 is equivalent to the low-level goal test in ICTS.
p1360
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1361
(dp1362
g10
VICTS and MAPF-iBundle differ in that ICTS performs a breadth-first search on the ICT and performs a goal test on each ICT node, the goal test searches for a feasible solution that includes \u005cemph{all} agents. This requires ICTS to expand all ICT nodes with $C<C^*$ and some nodes with $C=C^*$, where $C^*$ denotes the cost of the optimal solution. In contrast, each iteration of the auction examines candidate allocations corresponding to several ICT nodes, including nodes with only subsets of the agents. This examination of subsets of agents allows the auction to ``skip'' some ICT nodes that ICTS would try to solve. However, this pruning on nodes comes at the cost of solving additional allocations of subset of agents and the overhead of computing revenue and finding the winning allocation.
p1363
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1364
(dp1365
g10
VLet $\u005cdelta_i = C^*_{i}-opt_{i}$, where  $C^*_{i}$ denotes the maximal cost of the path for agent $i$ over all possible optimal allocation. We define $\u005cDelta = \u005csum\u005climits_{i=1}^k{\u005cdelta_i}$. ICTS will need to expand $k^{\u005cDelta}$ ICT nodes until the solution is found because it needs to reach an ICT node where the cost for each agent is exactly $C^*_i = opt_i + \u005cdelta_i$, and it expands nodes using breadth-first search. This means it will not need to expand nodes with $C>\u005cDelta$.
p1366
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1367
(dp1368
g10
VMAPF-iBundle might need to expand deeper ICT nodes but it might not need to expand all ICT nodes at each level. Next, we show that MAPF-iBundle  will not consider ICT nodes with $C>\u005cDelta \u005ccdot k$.
p1369
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1370
(dp1371
g10
VMAPF-iBundle will not consider allocations corresponding to ICT nodes with $C>\u005cmax_{a_j}\u005cdelta_j \u005ccdot k^2$.
p1372
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1373
(dp1374
g10
VWe prove this by proving that no agent $i$ can reach $m_i>k\u005ccdot \u005cmax_{a_j}\u005cdelta_j$. We omit the details of this proof due to space limitation.
p1375
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1376
(dp1377
g10
VA direct result of Theorem~\u005cref{the:delta} is the that number of MAPF-iBundle iterations is at most $\u005cmax_{a_j}\u005cdelta_j \u005ccdot k^2$.
p1378
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1379
(dp1380
g10
VMulti-agent pathfinding has been typically studied in cooperative settings and algorithms were developed under the assumption that there is a centralized planning mechanism. The computation of the algorithm might be distributed between the agents, but it is assumed that all agents aim to minimize the total cost for all agents. This assumption does not hold if agents are \u005cemph{self-interested}. For example, scenarios with robots of different companies that share a common area or driver-less cars might have diverging interests, but would still need to coordinate to avoid collisions. The auction mechanism can naturally be applied to non-cooperative settings. Agents submit bids based on their own interests and they do not necessarily have the same budget or have information about the other agents. For this non-cooperative setting, we assume the entity that controls the resources and the auction has the ability to enforce compliance with the paths that were allocated in the auction. That is, agents cannot choose a path that was not sold to them. This can be achieved by penalizing non-compliant agents. % making it non-beneficial for agents.
p1381
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1382
(dp1383
g10
VIn designing mechanisms for coordinating self-interested agents {\u005cem strategy-proofness} is a desired property. That is, we would like a mechanism that operates in such a way that agents' best strategy is to report their true preferences and not try to manipulate the outcomes. For example, if an agent participating in an auction somehow knows that the auction will not end in the next couple of rounds, it can start bidding on its bundles at a later round to prevent their prices from going up (``slow-bidding''). Such manipulations can lead to non-optimal outcomes. If  iBundle terminates with the Vickry payments (i.e., agents pay according to the decrease in utility they cause to other agents) then truthful myopic best response is the optimal strategy for a participating agent~\u005ccite{parkes2001iterative}. While it has been shown that iBundle terminates with the vickrey payments in many settings, it is not generally guaranteed to implement the vickrey outcome. An extension of the mechanism, called iBundle Extend \u005c& Adjust does terminate with the vickrey outcome by introducing proxy bidding agents that adjust prices after the final allocation is determined~\u005ccite{parkes2001iterative}. This extended mechanism can be implemented in the pathfinding domain similarly to the basic iBundle auction, resulting in strong strategy-proofness properties. Theoretically, existing algorithms for MAPF could also be applied in the presence of self-interested agents. However, in this context existing algorithms have significant limitations. Algorithms such as $A^*$ and its variants can be viewed as querying the agent only once, asking agents to report their complete preferences. These preferences need to include agents' locations, goals and coasts. For example, if agents have  complex preferences such as different costs for different locations or multiple goals, agents will need to report all this information to the central mechanism running the algorithm. Thus, using these algorithms will not maintain agents' privacy. It is also not robust to manipulations (e.g., agents can possibly report their preferences untruthfully to obtain a better path).
p1384
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1385
(dp1386
g10
VICTS and CBS are more similar to an iterative auction mechanism and can be viewed as having multiple interactions with agents to elicit their preferences incrementally as needed. In CBS, a goal-directed search is performed using a conflict tree. Each node in the tree includes a set of paths, one for each agent. If the node includes conflicting paths, child nodes are generated where each of them adds a constraint to one of the agents in the conflict such that iw will not be able to choose the conflicting path. The conflict tree is searched in a best-first manner and finds the optimal allocation. From an auction perspective, each of the child nodes of a conflicting node can be viewed as increasing the price of the conflicting location to infinity for one of the agents and querying it for its new preferred paths. In contrast with ascending price auctions, the conflict tree is expanded in a best-first manner prices will be raised and lowered during this process. This mechanism, however, can also be manipulated. For example, when prices are increased for an agent, it might report its new paths untruthfully to create more conflicts and cause the auctioneer to choose an allocation that is better for that agent.
p1387
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1388
(dp1389
g10
VICTS can be viewed as an ascending price auction where at each iteration the prices are increased to all agents (corresponding to a level in the ICT). Then it is possible to think of a price adjustment mechanism based on the actual solution is found. Like CBS, this mechanism does not have proven strategy-proofness properties and seems to be prone to  manipulations. For example, agents might report only a subset of their paths such that a solution will not be found when increasing costs to their paths, possibly resulting in a solution that is better for them but has a lower social welfare. Further exploring the possible interpretation of ICTS and CBS as iterative auctions is an interesting future direction.
p1390
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1391
(dp1392
g10
VTo the best of our knowledge, the only mechanism proposed for non-cooperative pathfinding is the Iterative Taxation Framework (ITF) by Bnaya et al.~\u005ccite{bnaya2013multi}. This mechanism assigns ``taxes'' to pairs of location and time, driving agents to follow paths with higher-social welfare. In contrast, the auction mechanism sells paths to agents. In terms of mechanism properties, the auction two key advantages: (1) it results in an optimal allocation of paths, and (2) in contrast with ITF, the operator of the mechanism  does not require knowledge about agents' locations or goals. This leads to stronger strategy-proofness properties (in ITF agents can potentially misreport their locations and goals to affect taxation).
p1393
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1394
(dp1395
g10
VWe evaluated MAPF-iBundle's performance, comparing it with ICTS and CBS, two recent state-of-the-art MAPF algorithms. ICTS and CBS were run with their recommended configurations~\u005ccite{sharon2012conflict,sharon2012meta}. All algorithms were run within the independence-detection (ID) framework~\u005ccite{standley2010finding}. This framework decomposes the problem to subproblems including subgroups of the agents that can be solved independently, leading to a lower effective problem size. For all algorithms, if no solution was found within 5 minute we consider it as a failure.
p1396
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1397
(dp1398
g10
V \u005cresizebox{8cm}{!}{%k & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \u005c\u005c \u005chlineCBS & 1 & 1 & 1 & 1 & 0.98 & 0.98 & 0.88 & 0.86 \u005c\u005c \u005chlineMAPF-iBundle & 1 & 1 & 1 & 1 & 0.98 & 1 & 0.96 & 0.9 \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0.98 \u005c\u005c \u005chlineTable~\u005cref{tab:success-8x8} shows the percentage of problem instances solved within the allotted 5 minutes, for MAPF problem instances in a $8\u005ctimes 8$ grid. As can be seen, MAPF-iBundle performs better than CBS but somewhat worst than ICTS. For example, for 15 agents MAPF-iBundle solved 0.9 of the instances, CBS solved 0.86, and ICTS solved 0.98. Similar trends were observed on a smaller $3\u005ctimes 3$ grid.
p1399
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1400
(dp1401
g10
Vk & 5 & 10 & 15 & 20 & 25 & 30  \u005c\u005c \u005chlineCBS & 1 & 0.96 & 1 & 0.98 & 0.92 & 0.8 \u005c\u005c \u005chlineMAPF-iBundle & 1 & 1 & 1 & 0.92 & 1 & 0.94  \u005c\u005c \u005chlineICTS & 1 & 1 & 1 & 0.94 & 1 & 0.98  \u005c\u005c \u005chlineNext, we performed similar experiments on the ``den 520'' map, taken from the ``Dragon Age'' video game and is available from Sturtevant's repository~\u005ccite{NATHANS}. In this domain too, MAPF-iBundle compares favorably to CBS, and is able to solve slightly less instances than ICTS. We performed a similar experiment for another map (``brc202d''), oberving similar results. Thus, while MAPF-iBundle is not the best MAPF solver, it is certainly comparable to them. Note that MAPF frameworks, such as MA-CBS~\u005ccite{sharon2012meta}, are orthogonal to MAPF-iBundle. Moreover, as discussed earlier, MAPF-iBundle allows more flexibility.
p1402
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1403
(dp1404
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline4 & 2.2 & 10     & 9     & 10      \u005c\u005c5 & 2.7 & 19     & 11    & 16     \u005c\u005c6 & 4.6 & 144    & 40    & 1,298   \u005c\u005c7 & 6.4 & 3,852   & 797   & 55,979  \u005c\u005c8 & 7.6 & 108,997 & 41,944 & 168,524 \u005c\u005c \u005chline8  & 1.7 & 18    & 15   & 19   \u005c\u005c9  & 2   & 29    & 17   & 35    \u005c\u005c10 & 2.3 & 243   & 22   & 33    \u005c\u005c11 & 2.4 & 45     & 27   & 114   \u005c\u005c12 & 3.4 & 6,272  & 42   & 6,133  \u005c\u005c13 & 3.7 & 331   & 54  & 6,351  \u005c\u005c14 & 4.8 & 16,965 & 2,187 & 42,874We also ran the algorithms on two maps, den520 and brc202d, from the ``Dragon Age'' video game, taken from Sturtevant's repository~\u005ccite{NATHANS}. We varied the number of agents between 5 and 30. Table~\u005cref{tab:dao} shows the runtime of the algorithms on these maps (averaged over 50 randomly generated problem instances). When solving den520 instances, MAPF-iBundle outperformed CBS but was slower than ICTS. When solving brc202d instances, MAPF-iBundle performed slower than both ICTS and CBS for most sizes of agents.  MAPF-iBundles was able to solve over $80\u005c%$ of the instances with 30 agents.
p1405
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1406
(dp1407
g10
V{$\u005cmathbf{k}$}   & {$\u005cmathbf{k'}$}  & \u005cbf{MAPF-iBundle} & \u005cbf{ICTS}    & \u005cbf{CBS}     \u005c\u005c \u005chline5  & 1.0 & 262   & 41    & 73    \u005c\u005c10 & 1.1 & 456   & 178   & 12,271 \u005c\u005c15 & 1.3 & 1,264  & 320   & 5,505  \u005c\u005c20 & 1.4 & 25,038 & 18,289 & 117,511 \u005c\u005c25 & 1.5 & 4,840  & 1,298  & 27,570 \u005c\u005c30 & 1.8 & 20,322 & 7,181  & 66,520 \u005c\u005c \u005chline5  & 1.1     & 196   & 95    & 243    \u005c\u005c10 & 1.3 & 1,000   & 320    & 648      \u005c\u005c15 & 1.6 & 13,123 & 7,007  & 13,416 \u005c\u005c20 & 1.7 & 13,653 & 6,759   & 23,088 \u005c\u005c25 & 2 & 37,646 & 14,917 & 18,246  \u005c\u005c30 & 2.5 & 73,490 & 25,048 & 6,334 In this paper we shows how an iterative combinatorial auction mechanism can be used to find optimal solutions to MAPF. Several properties of the structure of MAPF problems raised challenges for implementing the auction mechanism, such as the large number of items and possible bundles. Using efficient representations of paths used in prior MAPF works, we were able to develop an auction-based MAPF solver. Preliminary results are encouraging, showing that the auction approach performs close to state-of-the-art existing MAPF algorithms and in some settings finding solutions in less time. Moreover, the auction-based MAPF solver enjoys the flexibility of auctions, supporting user-specific preference over routes as well as a self-interested setting, where agents are not cooperative and require a strategy proof mechanism to coordinate them. The auction-based MAPF provides all these naturally. Bridging between auctions and MAPF opens the door for further integration of ideas. Insights and techniques from the auction literature can be adopted to the MAPF domain, for example using heuristics or approximate auction mechanisms. Similarly, techniques for reducing the complexity of MAPF problems might also be useful for auction mechanisms, and interpreting algorithms such as ICTS from an auction perspective might lead to novel auction mechanisms.
p1408
sg17
I00
sg18
Nsg19
NsbasbasS'title'
p1409
S'Ofra'
p1410
sb.