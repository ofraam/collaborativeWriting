(iversion
Page
p1
(dp2
S'revisions'
p3
(lp4
(iversion
Version
p5
(dp6
S'date'
p7
cdatetime
datetime
p8
(S'\x07\xde\x0c\x0f\x17\x11\x15\x04\xabP'
tRp9
sS'text'
p10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p11
sS'paragraphs'
p12
(lp13
(iversion
Paragraph
p14
(dp15
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p16
sS'changed'
p17
I00
sS'nextindex'
p18
NsS'lastindex'
p19
Nsba(iversion
Paragraph
p20
(dp21
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p22
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p23
(dp24
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p25
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p26
(dp27
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p28
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p29
(dp30
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p31
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p32
(dp33
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p34
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p35
(dp36
g10
S"\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p37
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p38
(dp39
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p40
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p41
(dp42
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p43
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p44
(dp45
g10
S"\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance."
p46
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p47
(dp48
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p49
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p50
(dp51
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p52
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p53
(dp54
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p55
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p56
(dp57
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p58
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p59
(dp60
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p61
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p62
(dp63
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p64
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p65
(dp66
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p67
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p68
(dp69
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p70
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p71
(dp72
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p73
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p74
(dp75
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p76
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p77
(dp78
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p79
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p80
(dp81
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p82
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p83
(dp84
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p85
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p86
(dp87
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p88
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p89
(dp90
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p91
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p92
(dp93
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p94
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p95
(dp96
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p97
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p98
(dp99
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p100
sg17
I00
sg18
Nsg19
NsbasS'author'
p101
S'OfraAmir'
p102
sba(iversion
Version
p103
(dp104
g7
g8
(S'\x07\xde\x0c\x10\x0f\x15 \x08\x1a8'
tRp105
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p106
sg12
(lp107
(iversion
Paragraph
p108
(dp109
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p110
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p111
(dp112
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p113
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p114
(dp115
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p116
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p117
(dp118
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p119
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p120
(dp121
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p122
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p123
(dp124
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p125
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p126
(dp127
g10
S"\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p128
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p129
(dp130
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p131
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p132
(dp133
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p134
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p135
(dp136
g10
S"\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance."
p137
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p138
(dp139
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p140
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p141
(dp142
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p143
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p144
(dp145
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p146
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p147
(dp148
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p149
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p150
(dp151
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p152
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p153
(dp154
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p155
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p156
(dp157
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p158
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p159
(dp160
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p161
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p162
(dp163
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p164
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p165
(dp166
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p167
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p168
(dp169
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p170
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p171
(dp172
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p173
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p174
(dp175
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p176
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p177
(dp178
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p179
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p180
(dp181
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p182
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p183
(dp184
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p185
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p186
(dp187
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p188
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p189
(dp190
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p191
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p192
sba(iversion
Version
p193
(dp194
g7
g8
(S'\x07\xde\x0c\x10\x14\x16#\t\xbc0'
tRp195
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p196
sg12
(lp197
(iversion
Paragraph
p198
(dp199
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p200
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p201
(dp202
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p203
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p204
(dp205
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p206
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p207
(dp208
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p209
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p210
(dp211
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p212
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p213
(dp214
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p215
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p216
(dp217
g10
S"\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p218
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p219
(dp220
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p221
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p222
(dp223
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p224
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p225
(dp226
g10
S"\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance."
p227
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p228
(dp229
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p230
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p231
(dp232
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p233
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p234
(dp235
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p236
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p237
(dp238
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p239
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p240
(dp241
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p242
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p243
(dp244
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p245
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p246
(dp247
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p248
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p249
(dp250
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p251
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p252
(dp253
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p254
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p255
(dp256
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p257
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p258
(dp259
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p260
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p261
(dp262
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p263
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p264
(dp265
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p266
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p267
(dp268
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p269
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p270
(dp271
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p272
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p273
(dp274
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p275
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p276
(dp277
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p278
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p279
(dp280
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p281
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p282
sba(iversion
Version
p283
(dp284
g7
g8
(S"\x07\xde\x0c\x10\x15'\x07\r\x17\x90"
tRp285
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p286
sg12
(lp287
(iversion
Paragraph
p288
(dp289
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p290
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p291
(dp292
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p293
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p294
(dp295
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p296
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p297
(dp298
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p299
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p300
(dp301
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p302
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p303
(dp304
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p305
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p306
(dp307
g10
S"\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p308
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p309
(dp310
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p311
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p312
(dp313
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p314
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p315
(dp316
g10
S"\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance."
p317
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p318
(dp319
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p320
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p321
(dp322
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p323
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p324
(dp325
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p326
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p327
(dp328
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p329
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p330
(dp331
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p332
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p333
(dp334
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p335
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p336
(dp337
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p338
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p339
(dp340
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p341
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p342
(dp343
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p344
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p345
(dp346
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p347
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p348
(dp349
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p350
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p351
(dp352
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p353
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p354
(dp355
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p356
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p357
(dp358
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p359
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p360
(dp361
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p362
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p363
(dp364
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p365
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p366
(dp367
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p368
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p369
(dp370
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p371
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p372
sba(iversion
Version
p373
(dp374
g7
g8
(S'\x07\xde\x0c\x11\x0f2\x06\x04x\x88'
tRp375
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p376
sg12
(lp377
(iversion
Paragraph
p378
(dp379
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p380
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p381
(dp382
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p383
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p384
(dp385
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p386
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p387
(dp388
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p389
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p390
(dp391
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p392
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p393
(dp394
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p395
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p396
(dp397
g10
S"\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p398
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p399
(dp400
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p401
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p402
(dp403
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p404
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p405
(dp406
g10
S"\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance."
p407
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p408
(dp409
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p410
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p411
(dp412
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p413
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p414
(dp415
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p416
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p417
(dp418
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p419
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p420
(dp421
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p422
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p423
(dp424
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p425
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p426
(dp427
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p428
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p429
(dp430
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p431
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p432
(dp433
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p434
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p435
(dp436
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p437
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p438
(dp439
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p440
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p441
(dp442
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p443
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p444
(dp445
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p446
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p447
(dp448
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p449
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p450
(dp451
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p452
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p453
(dp454
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p455
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p456
(dp457
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p458
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p459
(dp460
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p461
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p462
sba(iversion
Version
p463
(dp464
g7
g8
(S'\x07\xde\x0c\x11\x13)\x17\x07\xa8\xf0'
tRp465
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate both of these suspected relationships, we looked at the\nrelated paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p466
sg12
(lp467
(iversion
Paragraph
p468
(dp469
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p470
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p471
(dp472
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p473
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p474
(dp475
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p476
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p477
(dp478
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p479
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p480
(dp481
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p482
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p483
(dp484
g10
S"\\section{Approach}\\label{approach}\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p485
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p486
(dp487
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p488
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p489
(dp490
g10
S"Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance."
p491
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p492
(dp493
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p494
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p495
(dp496
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p497
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p498
(dp499
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p500
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p501
(dp502
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p503
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p504
(dp505
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p506
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p507
(dp508
g10
S"To evaluate both of these suspected relationships, we looked at the\nrelated paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p509
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p510
(dp511
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p512
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p513
(dp514
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p515
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p516
(dp517
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p518
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p519
(dp520
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p521
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p522
(dp523
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p524
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p525
(dp526
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p527
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p528
(dp529
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p530
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p531
(dp532
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p533
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p534
(dp535
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p536
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p537
(dp538
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p539
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p540
(dp541
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p542
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p543
(dp544
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p545
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p546
(dp547
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p548
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p549
sba(iversion
Version
p550
(dp551
g7
g8
(S'\x07\xde\x0c\x11\x17-\x03\x03\xe8\x00'
tRp552
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate both of these suspected relationships, we looked at the\nrelated paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions. {[}a{]}\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p553
sg12
(lp554
(iversion
Paragraph
p555
(dp556
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p557
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p558
(dp559
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p560
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p561
(dp562
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p563
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p564
(dp565
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p566
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p567
(dp568
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p569
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p570
(dp571
g10
S"\\section{Approach}\\label{approach}\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p572
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p573
(dp574
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p575
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p576
(dp577
g10
S"Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance."
p578
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p579
(dp580
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p581
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p582
(dp583
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p584
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p585
(dp586
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p587
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p588
(dp589
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p590
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p591
(dp592
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p593
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p594
(dp595
g10
S"To evaluate both of these suspected relationships, we looked at the\nrelated paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p596
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p597
(dp598
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions. {[}a{]}\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}."
p599
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p600
(dp601
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p602
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p603
(dp604
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p605
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p606
(dp607
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p608
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p609
(dp610
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p611
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p612
(dp613
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p614
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p615
(dp616
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p617
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p618
(dp619
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p620
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p621
(dp622
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p623
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p624
(dp625
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p626
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p627
(dp628
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p629
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p630
(dp631
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p632
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p633
sba(iversion
Version
p634
(dp635
g7
g8
(S'\x07\xde\x0c\x12\x0f!\x02\x05C\xa8'
tRp636
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate both of these suspected relationships, we looked at the\nrelated paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions. {[}a{]}\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}b{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}c{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p637
sg12
(lp638
(iversion
Paragraph
p639
(dp640
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p641
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p642
(dp643
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p644
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p645
(dp646
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p647
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p648
(dp649
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p650
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p651
(dp652
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p653
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p654
(dp655
g10
S"\\section{Approach}\\label{approach}\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p656
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p657
(dp658
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p659
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p660
(dp661
g10
S"Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance."
p662
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p663
(dp664
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p665
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p666
(dp667
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p668
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p669
(dp670
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p671
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p672
(dp673
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p674
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p675
(dp676
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p677
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p678
(dp679
g10
S"To evaluate both of these suspected relationships, we looked at the\nrelated paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p680
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p681
(dp682
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions. {[}a{]}\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}."
p683
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p684
(dp685
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p686
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p687
(dp688
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p689
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p690
(dp691
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p692
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p693
(dp694
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p695
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p696
(dp697
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p698
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p699
(dp700
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p701
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p702
(dp703
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}b{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}c{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p704
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p705
(dp706
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p707
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p708
(dp709
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p710
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p711
(dp712
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p713
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p714
(dp715
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p716
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p717
sba(iversion
Version
p718
(dp719
g7
g8
(S'\x07\xde\x0c\x16\x0f+\r\n90'
tRp720
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate both of these suspected relationships, we looked at the\nrelated paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions. {[}a{]}\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}b{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}c{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p721
sg12
(lp722
(iversion
Paragraph
p723
(dp724
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p725
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p726
(dp727
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p728
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p729
(dp730
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p731
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p732
(dp733
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p734
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p735
(dp736
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p737
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p738
(dp739
g10
S"\\section{Approach}\\label{approach}\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p740
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p741
(dp742
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p743
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p744
(dp745
g10
S"Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance."
p746
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p747
(dp748
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p749
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p750
(dp751
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p752
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p753
(dp754
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p755
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p756
(dp757
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p758
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p759
(dp760
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p761
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p762
(dp763
g10
S"To evaluate both of these suspected relationships, we looked at the\nrelated paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p764
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p765
(dp766
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions. {[}a{]}\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}."
p767
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p768
(dp769
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p770
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p771
(dp772
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p773
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p774
(dp775
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p776
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p777
(dp778
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p779
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p780
(dp781
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p782
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p783
(dp784
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p785
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p786
(dp787
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}b{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}c{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p788
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p789
(dp790
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p791
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p792
(dp793
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p794
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p795
(dp796
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p797
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p798
(dp799
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p800
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p801
sba(iversion
Version
p802
(dp803
g7
g8
(S"\x07\xde\x0c\x16\x10';\r\xbf\x88"
tRp804
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}b{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p805
sg12
(lp806
(iversion
Paragraph
p807
(dp808
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p809
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p810
(dp811
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p812
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p813
(dp814
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p815
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p816
(dp817
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p818
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p819
(dp820
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p821
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p822
(dp823
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p824
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p825
(dp826
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p827
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p828
(dp829
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p830
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p831
(dp832
g10
S"Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance."
p833
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p834
(dp835
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p836
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p837
(dp838
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p839
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p840
(dp841
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p842
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p843
(dp844
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p845
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p846
(dp847
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p848
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p849
(dp850
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).'
p851
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p852
(dp853
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p854
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p855
(dp856
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.'
p857
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p858
(dp859
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p860
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p861
(dp862
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p863
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p864
(dp865
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p866
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p867
(dp868
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p869
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p870
(dp871
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p872
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p873
(dp874
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}b{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p875
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p876
(dp877
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p878
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p879
(dp880
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p881
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p882
(dp883
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p884
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p885
(dp886
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p887
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p888
sba(iversion
Version
p889
(dp890
g7
g8
(S'\x07\xde\x0c\x0e\x10\t\x1f\x01s\x18'
tRp891
sg10
S'. See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.\n'
p892
sg12
(lp893
(iversion
Paragraph
p894
(dp895
g10
g892
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p896
sba(iversion
Version
p897
(dp898
g7
g8
(S'\x07\xde\x0c\x16\x101\x02\x04U`'
tRp899
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nParagraphs related by topic similarity were found on average once every\nten versions of the text. Paragraphs related by edit history were found\non average 1.6 times per version.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}b{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p900
sg12
(lp901
(iversion
Paragraph
p902
(dp903
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p904
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p905
(dp906
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p907
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p908
(dp909
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p910
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p911
(dp912
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p913
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p914
(dp915
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p916
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p917
(dp918
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p919
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p920
(dp921
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p922
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p923
(dp924
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p925
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p926
(dp927
g10
S"Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance."
p928
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p929
(dp930
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p931
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p932
(dp933
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p934
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p935
(dp936
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p937
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p938
(dp939
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p940
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p941
(dp942
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p943
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p944
(dp945
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).'
p946
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p947
(dp948
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p949
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p950
(dp951
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.'
p952
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p953
(dp954
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p955
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p956
(dp957
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p958
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p959
(dp960
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p961
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p962
(dp963
g10
S'Paragraphs related by topic similarity were found on average once every\nten versions of the text. Paragraphs related by edit history were found\non average 1.6 times per version.'
p964
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p965
(dp966
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p967
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p968
(dp969
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p970
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p971
(dp972
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}b{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p973
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p974
(dp975
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p976
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p977
(dp978
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p979
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p980
(dp981
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p982
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p983
(dp984
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p985
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p986
sba(iversion
Version
p987
(dp988
g7
g8
(S'\x07\xde\x0c\x16\x103)\x06\xae\xf0'
tRp989
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}b{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p990
sg12
(lp991
(iversion
Paragraph
p992
(dp993
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p994
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p995
(dp996
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p997
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p998
(dp999
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p1000
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1001
(dp1002
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p1003
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1004
(dp1005
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p1006
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1007
(dp1008
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p1009
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1010
(dp1011
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p1012
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1013
(dp1014
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p1015
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1016
(dp1017
g10
S"Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance."
p1018
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1019
(dp1020
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p1021
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1022
(dp1023
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p1024
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1025
(dp1026
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1027
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1028
(dp1029
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p1030
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1031
(dp1032
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p1033
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1034
(dp1035
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).'
p1036
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1037
(dp1038
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p1039
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1040
(dp1041
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.'
p1042
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1043
(dp1044
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p1045
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1046
(dp1047
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p1048
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1049
(dp1050
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p1051
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1052
(dp1053
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p1054
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1055
(dp1056
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p1057
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1058
(dp1059
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p1060
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1061
(dp1062
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 {[}a{]} & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity{[}b{]}? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p1063
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1064
(dp1065
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p1066
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1067
(dp1068
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p1069
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1070
(dp1071
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p1072
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1073
(dp1074
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p1075
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p1076
sba(iversion
Version
p1077
(dp1078
g7
g8
(S'\x07\xde\x0c\x16\x11\x03\x00\x0c\xd9\x10'
tRp1079
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}a{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p1080
sg12
(lp1081
(iversion
Paragraph
p1082
(dp1083
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p1084
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1085
(dp1086
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p1087
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1088
(dp1089
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p1090
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1091
(dp1092
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p1093
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1094
(dp1095
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p1096
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1097
(dp1098
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p1099
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1100
(dp1101
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p1102
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1103
(dp1104
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p1105
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1106
(dp1107
g10
S"Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. The process begins by\ncomposing a corpus for each Wikipedia article from all of the documents\n(paragraphs of the versions of the article). It analyzes tokens (a\nspecific instance of a word), eliminating those that only occur once, as\nwell as stopword tokens, such as `the' or `and'. It then creates a\nTF-IDF matrix, which assigns a weight to every token in each document,\nwhich indicates the importance of that token for this document. This\nweight increases proportionally to the frequency of the word in the\ndocument, but accounts for the frequency of the word in the corpus, such\nthat the frequent occurrence of a usually uncommon word is given a\nlarger weight to signify this importance."
p1108
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1109
(dp1110
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p1111
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1112
(dp1113
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p1114
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1115
(dp1116
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1117
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1118
(dp1119
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p1120
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1121
(dp1122
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p1123
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1124
(dp1125
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).'
p1126
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1127
(dp1128
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p1129
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1130
(dp1131
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.'
p1132
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1133
(dp1134
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p1135
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1136
(dp1137
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p1138
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1139
(dp1140
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p1141
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1142
(dp1143
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p1144
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1145
(dp1146
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p1147
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1148
(dp1149
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p1150
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1151
(dp1152
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}a{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p1153
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1154
(dp1155
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p1156
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1157
(dp1158
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p1159
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1160
(dp1161
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p1162
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1163
(dp1164
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p1165
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p1166
sba(iversion
Version
p1167
(dp1168
g7
g8
(S'\x07\xde\x0c\x16\x11\x0b\x15\x05\xb8\xd8'
tRp1169
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}a{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p1170
sg12
(lp1171
(iversion
Paragraph
p1172
(dp1173
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p1174
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1175
(dp1176
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p1177
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1178
(dp1179
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p1180
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1181
(dp1182
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p1183
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1184
(dp1185
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p1186
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1187
(dp1188
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p1189
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1190
(dp1191
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p1192
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1193
(dp1194
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p1195
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1196
(dp1197
g10
S'Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.'
p1198
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1199
(dp1200
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio."
p1201
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1202
(dp1203
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1204
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1205
(dp1206
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p1207
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1208
(dp1209
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p1210
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1211
(dp1212
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).'
p1213
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1214
(dp1215
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p1216
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1217
(dp1218
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.'
p1219
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1220
(dp1221
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p1222
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1223
(dp1224
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p1225
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1226
(dp1227
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p1228
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1229
(dp1230
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p1231
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1232
(dp1233
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p1234
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1235
(dp1236
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p1237
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1238
(dp1239
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}a{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p1240
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1241
(dp1242
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p1243
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1244
(dp1245
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p1246
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1247
(dp1248
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p1249
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1250
(dp1251
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p1252
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p1253
sba(iversion
Version
p1254
(dp1255
g7
g8
(S'\x07\xde\x0c\x16\x11\x10!\x0c\xfc8'
tRp1256
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\nAs shown in figure ~{[}fig:difflevtop{]}, which shows the distribution\nof the differences between a paragraph's Levenshtein ratios and LSI\nratios, the Levenshtein and LSI ratios demonstrate very different\nstatistics. In general, the topic similarity ratio is closer to one than\nthe levenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}a{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p1257
sg12
(lp1258
(iversion
Paragraph
p1259
(dp1260
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p1261
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1262
(dp1263
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p1264
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1265
(dp1266
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p1267
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1268
(dp1269
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p1270
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1271
(dp1272
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p1273
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1274
(dp1275
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p1276
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1277
(dp1278
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p1279
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1280
(dp1281
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p1282
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1283
(dp1284
g10
S'Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.'
p1285
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1286
(dp1287
g10
S"As shown in figure ~{[}fig:difflevtop{]}, which shows the distribution\nof the differences between a paragraph's Levenshtein ratios and LSI\nratios, the Levenshtein and LSI ratios demonstrate very different\nstatistics. In general, the topic similarity ratio is closer to one than\nthe levenshtein ratio."
p1288
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1289
(dp1290
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1291
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1292
(dp1293
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p1294
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1295
(dp1296
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p1297
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1298
(dp1299
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).'
p1300
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1301
(dp1302
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p1303
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1304
(dp1305
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.'
p1306
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1307
(dp1308
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p1309
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1310
(dp1311
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p1312
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1313
(dp1314
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p1315
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1316
(dp1317
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p1318
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1319
(dp1320
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p1321
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1322
(dp1323
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p1324
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1325
(dp1326
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}a{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p1327
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1328
(dp1329
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p1330
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1331
(dp1332
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p1333
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1334
(dp1335
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p1336
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1337
(dp1338
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p1339
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p1340
sba(iversion
Version
p1341
(dp1342
g7
g8
(S'\x07\xde\x0c\x17\x01%(\x07\xef@'
tRp1343
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\nAs shown in figure ~{[}fig:difflevtop{]}, which shows the distribution\nof the differences between a paragraph's Levenshtein ratios and LSI\nratios, the Levenshtein and LSI ratios demonstrate very different\nstatistics. In general, the topic similarity ratio is closer to one than\nthe levenshtein ratio.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}c{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p1344
sg12
(lp1345
(iversion
Paragraph
p1346
(dp1347
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p1348
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1349
(dp1350
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p1351
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1352
(dp1353
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p1354
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1355
(dp1356
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p1357
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1358
(dp1359
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p1360
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1361
(dp1362
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p1363
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1364
(dp1365
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p1366
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1367
(dp1368
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p1369
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1370
(dp1371
g10
S'Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.'
p1372
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1373
(dp1374
g10
S"As shown in figure ~{[}fig:difflevtop{]}, which shows the distribution\nof the differences between a paragraph's Levenshtein ratios and LSI\nratios, the Levenshtein and LSI ratios demonstrate very different\nstatistics. In general, the topic similarity ratio is closer to one than\nthe levenshtein ratio."
p1375
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1376
(dp1377
g10
S'\\includegraphics{figs/distribution_of_differences.png}\\\\By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1378
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1379
(dp1380
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p1381
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1382
(dp1383
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p1384
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1385
(dp1386
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article (see Figure~{[}fig:authors{]}).'
p1387
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1388
(dp1389
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p1390
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1391
(dp1392
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.'
p1393
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1394
(dp1395
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p1396
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1397
(dp1398
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p1399
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1400
(dp1401
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p1402
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1403
(dp1404
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p1405
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1406
(dp1407
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.'
p1408
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1409
(dp1410
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p1411
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1412
(dp1413
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}c{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p1414
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1415
(dp1416
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p1417
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1418
(dp1419
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p1420
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1421
(dp1422
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p1423
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1424
(dp1425
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p1426
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p1427
sba(iversion
Version
p1428
(dp1429
g7
g8
(S'\x07\xde\x0c\x17\x10\x0f%\x07\x8d\x98'
tRp1430
sg10
S''
sg12
(lp1431
sg101
S'OfraAmir'
p1432
sba(iversion
Version
p1433
(dp1434
g7
g8
(S'\x07\xde\x0c\x17\x10\x0f7\x07\x95h'
tRp1435
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}d{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p1436
sg12
(lp1437
(iversion
Paragraph
p1438
(dp1439
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p1440
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1441
(dp1442
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p1443
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1444
(dp1445
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p1446
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1447
(dp1448
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p1449
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1450
(dp1451
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p1452
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1453
(dp1454
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p1455
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1456
(dp1457
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p1458
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1459
(dp1460
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p1461
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1462
(dp1463
g10
S'Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.'
p1464
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1465
(dp1466
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1467
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1468
(dp1469
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p1470
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1471
(dp1472
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p1473
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1474
(dp1475
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.'
p1476
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1477
(dp1478
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p1479
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1480
(dp1481
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.'
p1482
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1483
(dp1484
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p1485
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1486
(dp1487
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p1488
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1489
(dp1490
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p1491
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1492
(dp1493
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p1494
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1495
(dp1496
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.'
p1497
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1498
(dp1499
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p1500
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1501
(dp1502
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}d{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p1503
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1504
(dp1505
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p1506
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1507
(dp1508
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p1509
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1510
(dp1511
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p1512
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1513
(dp1514
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p1515
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p1516
sba(iversion
Version
p1517
(dp1518
g7
g8
(S'\x07\xde\x0c\x17\x10\x0f8\rR('
tRp1519
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}d{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p1520
sg12
(lp1521
(iversion
Paragraph
p1522
(dp1523
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p1524
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1525
(dp1526
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p1527
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1528
(dp1529
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p1530
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1531
(dp1532
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p1533
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1534
(dp1535
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p1536
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1537
(dp1538
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for providing three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p1539
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1540
(dp1541
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p1542
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1543
(dp1544
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p1545
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1546
(dp1547
g10
S'Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.'
p1548
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1549
(dp1550
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1551
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1552
(dp1553
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p1554
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1555
(dp1556
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p1557
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1558
(dp1559
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.'
p1560
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1561
(dp1562
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p1563
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1564
(dp1565
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine 1) that\nparagraphs were correctly mapped and 2) that this method successfully\nclassifies edits. We provide an example of a significant edit below.\nWhile these paragraphs are clearly the same, the edit is significant\nbecause it contributes content and changes the tone of the paragraph.'
p1566
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1567
(dp1568
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p1569
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1570
(dp1571
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p1572
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1573
(dp1574
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p1575
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1576
(dp1577
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p1578
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1579
(dp1580
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.'
p1581
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1582
(dp1583
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p1584
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1585
(dp1586
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\nProximity{[}d{]}? & ? & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p1587
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1588
(dp1589
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p1590
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1591
(dp1592
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p1593
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1594
(dp1595
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p1596
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1597
(dp1598
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p1599
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p1600
sba(iversion
Version
p1601
(dp1602
g7
g8
(S'\x07\xde\x0c\x17\x10\x1b7\x02\x94('
tRp1603
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p1604
sg12
(lp1605
(iversion
Paragraph
p1606
(dp1607
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p1608
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1609
(dp1610
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p1611
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1612
(dp1613
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p1614
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1615
(dp1616
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p1617
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1618
(dp1619
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p1620
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1621
(dp1622
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p1623
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1624
(dp1625
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p1626
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1627
(dp1628
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p1629
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1630
(dp1631
g10
S'Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.'
p1632
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1633
(dp1634
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1635
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1636
(dp1637
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p1638
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1639
(dp1640
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p1641
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1642
(dp1643
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.'
p1644
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1645
(dp1646
g10
S'\\subsection{Findings}\\label{findings}\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p1647
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1648
(dp1649
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p1650
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1651
(dp1652
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p1653
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1654
(dp1655
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p1656
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1657
(dp1658
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p1659
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1660
(dp1661
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p1662
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1663
(dp1664
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.'
p1665
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1666
(dp1667
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.'
p1668
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1669
(dp1670
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p1671
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1672
(dp1673
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p1674
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1675
(dp1676
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p1677
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1678
(dp1679
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p1680
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1681
(dp1682
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p1683
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p1684
sba(iversion
Version
p1685
(dp1686
g7
g8
(S'\x07\xde\x0c\x0e\x10\x17\r\t\xee\xf8'
tRp1687
sg10
S". See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.\n\n\\section{Introduction}\\label{introduction}\n\nMaybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikis\n\nnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision Activity\n\nWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nThe system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.\n\nINSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.\n\nThis method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches.\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81 Topic Similarity .\nPhysical Proximity 24 Paragraph with original significant change 40\nRandom Sample of Paragraphs 15\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63 Editing History 27,722 19,685 71\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p1688
sg12
(lp1689
(iversion
Paragraph
p1690
(dp1691
g10
S'. See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.'
p1692
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1693
(dp1694
g10
S'\\section{Introduction}\\label{introduction}Maybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikisnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision ActivityWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.'
p1695
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1696
(dp1697
g10
S'The system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.'
p1698
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1699
(dp1700
g10
S"INSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit."
p1701
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1702
(dp1703
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p1704
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1705
(dp1706
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.'
p1707
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1708
(dp1709
g10
S'This method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.'
p1710
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1711
(dp1712
g10
S"A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches."
p1713
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1714
(dp1715
g10
S"\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p1716
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1717
(dp1718
g10
S"As shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance."
p1719
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1720
(dp1721
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p1722
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1723
(dp1724
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1725
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1726
(dp1727
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p1728
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1729
(dp1730
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p1731
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1732
(dp1733
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p1734
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1735
(dp1736
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p1737
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1738
(dp1739
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p1740
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1741
(dp1742
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p1743
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1744
(dp1745
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.'
p1746
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1747
(dp1748
g10
S'Caption: After a significant change at version 0, consequent edits are\nmore frequent.'
p1749
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1750
(dp1751
g10
S'We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p1752
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1753
(dp1754
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.'
p1755
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1756
(dp1757
g10
S'Relationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81 Topic Similarity .\nPhysical Proximity 24 Paragraph with original significant change 40\nRandom Sample of Paragraphs 15More importantly, with respect to the second measure, we correctly\npredicted 63Relationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63 Editing History 27,722 19,685 71Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p1758
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1759
(dp1760
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p1761
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1762
(dp1763
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p1764
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1765
(dp1766
g10
S'We imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.'
p1767
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1768
(dp1769
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n'
p1770
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p1771
sba(iversion
Version
p1772
(dp1773
g7
g8
(S'\x07\xde\x0c\x17\x106$\x08M\x00'
tRp1774
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and detection of significant\nchanges that formed the basis of the prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe also plan to develop additional algorithms for summarizing changes,\nbuilding on text summary algorithms from the NLP literature **need\ncitations*** {[}d{]}and further use algorithms that measure text\ncoherency (e.g., textiling **cite**) to alert authors to lack of\ncoherency issues. Finally, we plan to explore alternative ways of\npresenting the information chosen by algorithms to users. For example,\nan assistive system might highlight changes that it deems relevant to a\nspecific author, or it could provide a list of the changes etc.\n"
p1775
sg12
(lp1776
(iversion
Paragraph
p1777
(dp1778
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p1779
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1780
(dp1781
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p1782
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1783
(dp1784
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p1785
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1786
(dp1787
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p1788
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1789
(dp1790
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p1791
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1792
(dp1793
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p1794
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1795
(dp1796
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p1797
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1798
(dp1799
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p1800
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1801
(dp1802
g10
S'Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.'
p1803
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1804
(dp1805
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1806
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1807
(dp1808
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p1809
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1810
(dp1811
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p1812
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1813
(dp1814
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.'
p1815
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1816
(dp1817
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and detection of significant\nchanges that formed the basis of the prediction.'
p1818
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1819
(dp1820
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p1821
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1822
(dp1823
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p1824
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1825
(dp1826
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p1827
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1828
(dp1829
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p1830
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1831
(dp1832
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p1833
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1834
(dp1835
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p1836
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1837
(dp1838
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.'
p1839
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1840
(dp1841
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.'
p1842
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1843
(dp1844
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p1845
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1846
(dp1847
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p1848
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1849
(dp1850
g10
S"Our long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p1851
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1852
(dp1853
g10
S'We also plan to develop additional algorithms for summarizing changes,\nbuilding on text summary algorithms from the NLP literature **need\ncitations*** {[}d{]}and further use algorithms that measure text\ncoherency (e.g., textiling **cite**) to alert authors to lack of\ncoherency issues. Finally, we plan to explore alternative ways of\npresenting the information chosen by algorithms to users. For example,\nan assistive system might highlight changes that it deems relevant to a\nspecific author, or it could provide a list of the changes etc.\n'
p1854
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p1855
sba(iversion
Version
p1856
(dp1857
g7
g8
(S'\x07\xde\x0c\x17\x11\x025\x0f#\x00'
tRp1858
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes,\nbuilding on text summary algorithms from the NLP literature **need\ncitations*** {[}d{]}and further use algorithms that measure text\ncoherency (e.g., textiling **cite**) to alert authors to lack of\ncoherency issues. Finally, we plan to explore alternative ways of\npresenting the information chosen by algorithms to users. For example,\nan assistive system might highlight changes that it deems relevant to a\nspecific author, or it could provide a list of the changes etc.\n"
p1859
sg12
(lp1860
(iversion
Paragraph
p1861
(dp1862
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p1863
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1864
(dp1865
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p1866
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1867
(dp1868
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p1869
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1870
(dp1871
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p1872
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1873
(dp1874
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p1875
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1876
(dp1877
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p1878
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1879
(dp1880
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p1881
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1882
(dp1883
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p1884
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1885
(dp1886
g10
S'Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.'
p1887
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1888
(dp1889
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1890
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1891
(dp1892
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p1893
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1894
(dp1895
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p1896
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1897
(dp1898
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.'
p1899
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1900
(dp1901
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.'
p1902
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1903
(dp1904
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p1905
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1906
(dp1907
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p1908
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1909
(dp1910
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p1911
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1912
(dp1913
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p1914
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1915
(dp1916
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p1917
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1918
(dp1919
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p1920
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1921
(dp1922
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.'
p1923
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1924
(dp1925
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.'
p1926
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1927
(dp1928
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p1929
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1930
(dp1931
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p1932
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1933
(dp1934
g10
S'Our long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.'
p1935
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1936
(dp1937
g10
S'We also plan to develop additional algorithms for summarizing changes,\nbuilding on text summary algorithms from the NLP literature **need\ncitations*** {[}d{]}and further use algorithms that measure text\ncoherency (e.g., textiling **cite**) to alert authors to lack of\ncoherency issues. Finally, we plan to explore alternative ways of\npresenting the information chosen by algorithms to users. For example,\nan assistive system might highlight changes that it deems relevant to a\nspecific author, or it could provide a list of the changes etc.\n'
p1938
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p1939
sba(iversion
Version
p1940
(dp1941
g7
g8
(S'\x07\xde\x0c\x17\x11#%\x07\xe3\x88'
tRp1942
sg10
S''
sg12
(lp1943
sg101
S'LaurenUrke'
p1944
sba(iversion
Version
p1945
(dp1946
g7
g8
(S"\x07\xde\x0c\x17\x11'\t\x03k\x00"
tRp1947
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes,\nbuilding on text summary algorithms from the NLP literature **need\ncitations*** {[}d{]}and further use algorithms that measure text\ncoherency (e.g., textiling \\cite{hearst1994multi}) to alert authors to\nlack of coherency issues. Finally, we plan to explore alternative ways\nof presenting the information chosen by algorithms to users. For\nexample, an assistive system might highlight changes that it deems\nrelevant to a specific author, or it could provide a list of the changes\netc.\n"
p1948
sg12
(lp1949
(iversion
Paragraph
p1950
(dp1951
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p1952
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1953
(dp1954
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p1955
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1956
(dp1957
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p1958
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1959
(dp1960
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p1961
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1962
(dp1963
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p1964
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1965
(dp1966
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p1967
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1968
(dp1969
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p1970
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1971
(dp1972
g10
S"\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p1973
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1974
(dp1975
g10
S'Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.'
p1976
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1977
(dp1978
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p1979
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1980
(dp1981
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p1982
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1983
(dp1984
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p1985
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1986
(dp1987
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.'
p1988
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1989
(dp1990
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.'
p1991
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1992
(dp1993
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p1994
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1995
(dp1996
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p1997
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p1998
(dp1999
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p2000
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2001
(dp2002
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p2003
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2004
(dp2005
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p2006
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2007
(dp2008
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p2009
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2010
(dp2011
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}b{]}{[}c{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.'
p2012
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2013
(dp2014
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.'
p2015
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2016
(dp2017
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p2018
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2019
(dp2020
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p2021
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2022
(dp2023
g10
S'Our long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.'
p2024
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2025
(dp2026
g10
S'We also plan to develop additional algorithms for summarizing changes,\nbuilding on text summary algorithms from the NLP literature **need\ncitations*** {[}d{]}and further use algorithms that measure text\ncoherency (e.g., textiling \\cite{hearst1994multi}) to alert authors to\nlack of coherency issues. Finally, we plan to explore alternative ways\nof presenting the information chosen by algorithms to users. For\nexample, an assistive system might highlight changes that it deems\nrelevant to a specific author, or it could provide a list of the changes\netc.\n'
p2027
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p2028
sba(iversion
Version
p2029
(dp2030
g7
g8
(S'\x07\xde\x0c\x17\x12/(\x01\xd4\xc0'
tRp2031
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes\nand further use algorithms that measure text coherency (e.g., textiling\n\\cite{hearst1994multi}) to alert authors to lack of coherency issues.\nFinally, we plan to explore alternative ways of presenting the\ninformation chosen by algorithms to users. For example, an assistive\nsystem might highlight changes that it deems relevant to a specific\nauthor, or it could provide a list of the changes.\n"
p2032
sg12
(lp2033
(iversion
Paragraph
p2034
(dp2035
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p2036
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2037
(dp2038
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p2039
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2040
(dp2041
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p2042
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2043
(dp2044
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p2045
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2046
(dp2047
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2048
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2049
(dp2050
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p2051
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2052
(dp2053
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p2054
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2055
(dp2056
g10
S"\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p2057
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2058
(dp2059
g10
S'Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.'
p2060
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2061
(dp2062
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p2063
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2064
(dp2065
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p2066
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2067
(dp2068
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p2069
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2070
(dp2071
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.'
p2072
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2073
(dp2074
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.'
p2075
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2076
(dp2077
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p2078
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2079
(dp2080
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p2081
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2082
(dp2083
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p2084
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2085
(dp2086
g10
S'\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p2087
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2088
(dp2089
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p2090
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2091
(dp2092
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p2093
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2094
(dp2095
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.'
p2096
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2097
(dp2098
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.'
p2099
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2100
(dp2101
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p2102
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2103
(dp2104
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p2105
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2106
(dp2107
g10
S'Our long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.'
p2108
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2109
(dp2110
g10
S'We also plan to develop additional algorithms for summarizing changes\nand further use algorithms that measure text coherency (e.g., textiling\n\\cite{hearst1994multi}) to alert authors to lack of coherency issues.\nFinally, we plan to explore alternative ways of presenting the\ninformation chosen by algorithms to users. For example, an assistive\nsystem might highlight changes that it deems relevant to a specific\nauthor, or it could provide a list of the changes.\n'
p2111
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p2112
sba(iversion
Version
p2113
(dp2114
g7
g8
(S'\x07\xde\x0c\x17\x14\n\x06\r\xbf\x88'
tRp2115
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the document\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes\nand further use algorithms that measure text coherency (e.g., textiling\n\\cite{hearst1994multi}) to alert authors to lack of coherency issues.\nFinally, we plan to explore alternative ways of presenting the\ninformation chosen by algorithms to users. For example, an assistive\nsystem might highlight changes that it deems relevant to a specific\nauthor, or it could provide a list of the changes.\n"
p2116
sg12
(lp2117
(iversion
Paragraph
p2118
(dp2119
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity, for example, researchers\nwrite papers and proposals together, lawyers draft contracts, etc. In\nrecent years, collaborative writing of documents has become even more\nwidespread with the support of frameworks that simplify distributed\nediting (e.g., google docs, dropbox). However, while document processors\nprovide capabilities such as ``track changes'', ``diff'' and commenting,\nthey lack intelligent information sharing mechanisms. They do not\nattempt to reason about the importance or relevance of changes to\ndifferent authors and do not consider how edits might affect other parts\nof the document."
p2120
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2121
(dp2122
g10
S'In practice, the collaborative writing process requires significant\ncommunication between authors to update each other. Because the authors\nneed to make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p2123
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2124
(dp2125
g10
S'This paper presents our initial work on developing methods that provide\nthe basis for intelligent interactive systems that support collaborating\nauthors. These methods include drawing their attention to edits that are\nimportant and relevant for them, as well as to other parts of the\ndocument that are likely to require consequent editing. Systems with\nsuch capabilities have potential to improve coherence and coordination\nwhile reducing the communication burden.'
p2126
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2127
(dp2128
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p2129
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2130
(dp2131
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2132
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2133
(dp2134
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p2135
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2136
(dp2137
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p2138
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2139
(dp2140
g10
S"\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p2141
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2142
(dp2143
g10
S'Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Specifically, we use cosine similarity\nbetween word vectors that represent the paragraphs, incorportating\nLatent Semantic Indexing~\\cite{deerwester1990indexing} (LSI) which\naccounts for synonyms and does not penalize for typographical errors.'
p2144
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2145
(dp2146
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p2147
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2148
(dp2149
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\nother parts of the documentWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p2150
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2151
(dp2152
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes our preliminary evaluation of the proposed\nmethods, using a corpus of Wikipedia articles and their revision\nhistories.'
p2153
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2154
(dp2155
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. This approach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.'
p2156
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2157
(dp2158
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.'
p2159
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2160
(dp2161
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p2162
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2163
(dp2164
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p2165
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2166
(dp2167
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p2168
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2169
(dp2170
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p2171
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2172
(dp2173
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p2174
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2175
(dp2176
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.'
p2177
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2178
(dp2179
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.'
p2180
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2181
(dp2182
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p2183
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2184
(dp2185
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p2186
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2187
(dp2188
g10
S'Our long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific, important changes and places in the\ndocument that are likely to require revisions. However, our approach\nthus far have not leveraged information about the authors who made the\nedits. In future work we plan to incorporate information about author\nidentity to design personalized alerts for authors depending on their\ncontext of editing and history of revisions. For example, the paragraph\ntracking algorithm makes it possible to create a list of authors who\nhave contributed to a specific paragraph, which can be used to determine\nwho to alert when significant edits occur.'
p2189
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2190
(dp2191
g10
S'We also plan to develop additional algorithms for summarizing changes\nand further use algorithms that measure text coherency (e.g., textiling\n\\cite{hearst1994multi}) to alert authors to lack of coherency issues.\nFinally, we plan to explore alternative ways of presenting the\ninformation chosen by algorithms to users. For example, an assistive\nsystem might highlight changes that it deems relevant to a specific\nauthor, or it could provide a list of the changes.\n'
p2192
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p2193
sba(iversion
Version
p2194
(dp2195
g7
g8
(S'\x07\xde\x0c\x19\x0f\x0f8\ry8'
tRp2196
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication among authors to update each other. Because authors need\nto make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents initial work on developing methods that intelligent\ninteractive systems could deploy to support collaborating authors. These\nmethods include drawing authors' attention to edits that are important\nand relevant for them, as well as pointing out other parts of the\ndocument that are likely to require editing given changes they have just\nmade. Systems with such capabilities have potential to improve coherence\nand coordination while reducing authors' communication burden.\n\nThe proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\n{[}3{]} We consider a significant change to be a noticeable change in\nthe paragraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n{[}1; omitting the ``therefore''{]}Therefore, we use a topic modeling\napproach, which is a better fit for assessing changes in content.\nSpecifically, we use cosine similarity between word vectors that\nrepresent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\n{[}2{]} By calculating the topic similarity between two concurrent\nversions of an edited paragraph, the system can detect whether a\nsignificant change has occurred. If the cosine similarity between the\ntwo paragraphs was below an empirically determined threshold of 0.8, we\nlabel the edit as significant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\npreliminary evaluation of the proposed methods used a corpus of\nWikipedia articles and their revision histories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. A variety of recent work has used this approach\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This capability\nprovides the basis for detecting significant changes and anticipating\nfuture semantic conflicts. Our edit evaluation method successfully\ndetects the most significant changes using the LSI Topic Similarity\nmodel. Based on these significant changes, our anticipate possible\nsemantic conflicts in linked paragraphs. After a significant change,\nparagraphs related to the edited paragraph were indeed more likely to be\nedited in response a couple versions later. Paragraphs linked by similar\nedit histories were most likely to need editing, with paragraphs linked\nby topic similarity not far behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific changes and places in the document\nthat are likely to require revisions. Thus far, have not investigated\nways to leverage information about the authors who made the edits. In\nfuture work, we plan to incorporate information about author identity to\ndesign personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes\nand to investigate the use of algorithms that measure text coherence\n(e.g.,Textiling \\cite{hearst1994multi}) for alerting authors to portions\nof the text that appear to lack coherence. Finally, we plan to explore\nalternative ways of presenting to authors the information chosen by the\nalgorithms as important for them to consider. For example, the system\nmight highlight changes that it deems relevant or provide a list of them\nwith links to the places they appear in the text.\n"
p2197
sg12
(lp2198
(iversion
Paragraph
p2199
(dp2200
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document."
p2201
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2202
(dp2203
g10
S'In practice, the collaborative writing process requires significant\ncommunication among authors to update each other. Because authors need\nto make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p2204
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2205
(dp2206
g10
S"This paper presents initial work on developing methods that intelligent\ninteractive systems could deploy to support collaborating authors. These\nmethods include drawing authors' attention to edits that are important\nand relevant for them, as well as pointing out other parts of the\ndocument that are likely to require editing given changes they have just\nmade. Systems with such capabilities have potential to improve coherence\nand coordination while reducing authors' communication burden."
p2207
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2208
(dp2209
g10
S'The proposed methods use NLP techniques such as distance metrics and\ntopic models to track paragraphs across revisions and to identify\nsignificant changes made to the document. Analysis of co-occurrence of\nchanges in past revisions is used to identify parts of the document that\ntend to change together, which is used to predict which parts of a\ndocument will require edits as a result of a significant change to a\nparagraph. An empirical evaluation of the approach on a corpus of\nWikipedia articles shows promising initial results, as it is able to\ntrack paragraph across revisions, identify significant changes, and\npredict which paragraphs are likely to be edited following significant\nedits.'
p2210
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2211
(dp2212
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2213
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2214
(dp2215
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for the following three key\ncapabilities: (1) tracking paragraphs; (2) identifying significant\nchanges to paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes can help promote only the most important\nchanges and decide whether to alert collaborating authors. Predicting\nfuture changes is required in order to draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p2216
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2217
(dp2218
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p2219
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2220
(dp2221
g10
S"\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}{[}3{]} We consider a significant change to be a noticeable change in\nthe paragraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p2222
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2223
(dp2224
g10
S"{[}1; omitting the ``therefore''{]}Therefore, we use a topic modeling\napproach, which is a better fit for assessing changes in content.\nSpecifically, we use cosine similarity between word vectors that\nrepresent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors."
p2225
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2226
(dp2227
g10
S'{[}2{]} By calculating the topic similarity between two concurrent\nversions of an edited paragraph, the system can detect whether a\nsignificant change has occurred. If the cosine similarity between the\ntwo paragraphs was below an empirically determined threshold of 0.8, we\nlabel the edit as significant.'
p2228
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2229
(dp2230
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p2231
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2232
(dp2233
g10
S'We considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p2234
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2235
(dp2236
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}preliminary evaluation of the proposed methods used a corpus of\nWikipedia articles and their revision histories.'
p2237
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2238
(dp2239
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. A variety of recent work has used this approach\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.'
p2240
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2241
(dp2242
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.'
p2243
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2244
(dp2245
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p2246
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2247
(dp2248
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p2249
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2250
(dp2251
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p2252
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2253
(dp2254
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p2255
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2256
(dp2257
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p2258
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2259
(dp2260
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.'
p2261
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2262
(dp2263
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.'
p2264
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2265
(dp2266
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p2267
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2268
(dp2269
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This capability\nprovides the basis for detecting significant changes and anticipating\nfuture semantic conflicts. Our edit evaluation method successfully\ndetects the most significant changes using the LSI Topic Similarity\nmodel. Based on these significant changes, our anticipate possible\nsemantic conflicts in linked paragraphs. After a significant change,\nparagraphs related to the edited paragraph were indeed more likely to be\nedited in response a couple versions later. Paragraphs linked by similar\nedit histories were most likely to need editing, with paragraphs linked\nby topic similarity not far behind.'
p2270
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2271
(dp2272
g10
S'Our long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific changes and places in the document\nthat are likely to require revisions. Thus far, have not investigated\nways to leverage information about the authors who made the edits. In\nfuture work, we plan to incorporate information about author identity to\ndesign personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur.'
p2273
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2274
(dp2275
g10
S'We also plan to develop additional algorithms for summarizing changes\nand to investigate the use of algorithms that measure text coherence\n(e.g.,Textiling \\cite{hearst1994multi}) for alerting authors to portions\nof the text that appear to lack coherence. Finally, we plan to explore\nalternative ways of presenting to authors the information chosen by the\nalgorithms as important for them to consider. For example, the system\nmight highlight changes that it deems relevant or provide a list of them\nwith links to the places they appear in the text.\n'
p2276
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p2277
sba(iversion
Version
p2278
(dp2279
g7
g8
(S'\x07\xde\x0c\x1d\x11\x08%\x0bm\xc8'
tRp2280
sg10
S"\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document.\n\nIn practice, the collaborative writing process requires significant\ncommunication among authors to update each other. Because authors need\nto make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.\n\nThis paper presents initial work on developing methods that intelligent\ninteractive systems could deploy to support collaborating authors. These\nmethods include drawing authors' attention to edits that are important\nand relevant for them, as well as pointing out other parts of the\ndocument that are likely to require editing given changes they have just\nmade. Systems with such capabilities have potential to improve coherence\nand coordination while reducing authors' communication burden.\n\nThe paper describes methods that would enable systems to track\nparagraphs as they are revised, identify paragraphs that have\nsignificant changes, and predict likely future changes based on a\nparticular edit. The first two methods use natural-language processing\n(NLP) techniques for measuring distance between texts and for topic\nmodeling, respectively. The third is based on an analysis of\nco-occurrence of changes in past revisions. An empirical evaluation of\nthe approach on a corpus of Wikipedia articles shows promising initial\nresults. Using these methods it is possible to track paragraph across\nrevisions, identify significant changes, and predict the paragraphs that\nare likely to be edited following a significant edit of a particular\nparagraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes the developed methods for: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. The capability of tracking a\nparagraph through revisions is required for both monitoring changes and\npredicting them. The capability of identifying significant content\nchanges can help promote only the most important changes and decide\nwhether to alert collaborating authors of a change. The capability of\npredicting future changes is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\n{[}3{]} We consider a significant change to be a noticeable change in\nthe paragraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n{[}1; omitting the ``therefore''{]}Therefore, we use a topic modeling\napproach, which is a better fit for assessing changes in content.\nSpecifically, we use cosine similarity between word vectors that\nrepresent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors.\n\n{[}2{]} By calculating the topic similarity between two concurrent\nversions of an edited paragraph, the system can detect whether a\nsignificant change has occurred. If the cosine similarity between the\ntwo paragraphs was below an empirically determined threshold of 0.8, we\nlabel the edit as significant.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\npreliminary evaluation of the proposed methods used a corpus of\nWikipedia articles and their revision histories.\n\n\\subsection{Data}\\label{data}\n\nWikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. A variety of recent work has used this approach\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nIn the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This capability\nprovides the basis for detecting significant changes and anticipating\nfuture semantic conflicts. Our edit evaluation method successfully\ndetects the most significant changes using the LSI Topic Similarity\nmodel. Based on these significant changes, our anticipate possible\nsemantic conflicts in linked paragraphs. After a significant change,\nparagraphs related to the edited paragraph were indeed more likely to be\nedited in response a couple versions later. Paragraphs linked by similar\nedit histories were most likely to need editing, with paragraphs linked\nby topic similarity not far behind.\n\nOur long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific changes and places in the document\nthat are likely to require revisions. Thus far, have not investigated\nways to leverage information about the authors who made the edits. In\nfuture work, we plan to incorporate information about author identity to\ndesign personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur.\n\nWe also plan to develop additional algorithms for summarizing changes\nand to investigate the use of algorithms that measure text coherence\n(e.g.,Textiling \\cite{hearst1994multi}) for alerting authors to portions\nof the text that appear to lack coherence. Finally, we plan to explore\nalternative ways of presenting to authors the information chosen by the\nalgorithms as important for them to consider. For example, the system\nmight highlight changes that it deems relevant or provide a list of them\nwith links to the places they appear in the text.\n"
p2281
sg12
(lp2282
(iversion
Paragraph
p2283
(dp2284
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document."
p2285
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2286
(dp2287
g10
S'In practice, the collaborative writing process requires significant\ncommunication among authors to update each other. Because authors need\nto make sure their edits are coherent with the document as a whole,\nincluding sections written by others, they need to read the entire\ndocument frequently, or rely on updates from their co-authors. Even when\nauthors communicate with each other frequently, they can get lost in the\nvolume of edits from other collaborators or become overwhelmed with too\nmuch information.'
p2288
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2289
(dp2290
g10
S"This paper presents initial work on developing methods that intelligent\ninteractive systems could deploy to support collaborating authors. These\nmethods include drawing authors' attention to edits that are important\nand relevant for them, as well as pointing out other parts of the\ndocument that are likely to require editing given changes they have just\nmade. Systems with such capabilities have potential to improve coherence\nand coordination while reducing authors' communication burden."
p2291
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2292
(dp2293
g10
S'The paper describes methods that would enable systems to track\nparagraphs as they are revised, identify paragraphs that have\nsignificant changes, and predict likely future changes based on a\nparticular edit. The first two methods use natural-language processing\n(NLP) techniques for measuring distance between texts and for topic\nmodeling, respectively. The third is based on an analysis of\nco-occurrence of changes in past revisions. An empirical evaluation of\nthe approach on a corpus of Wikipedia articles shows promising initial\nresults. Using these methods it is possible to track paragraph across\nrevisions, identify significant changes, and predict the paragraphs that\nare likely to be edited following a significant edit of a particular\nparagraph.'
p2294
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2295
(dp2296
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2012tracking,birnholtz2013write}, and has\ndeveloped tools for supporting such collaboration (e.g.,\nQuilt~\\cite{fish1988quilt}). Most closely related to our work are\nmethods and tools for supporting improved \\emph{awareness} of\ncollaborators about changes made to a document. These include flexible\ndiffing for reporting significant changes~\\cite{neuwirth1992flexible},\nmethods for categorization of edits and interfaces for presenting them\nto\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2297
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2298
(dp2299
g10
S"\\section{Approach}\\label{approach}This section describes the developed methods for: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. The capability of tracking a\nparagraph through revisions is required for both monitoring changes and\npredicting them. The capability of identifying significant content\nchanges can help promote only the most important changes and decide\nwhether to alert collaborating authors of a change. The capability of\npredicting future changes is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit."
p2300
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2301
(dp2302
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a mapping algorithm that compares paragraphs based on their\nLevenshtein distance, that is, the number of changed characters required\nto move from one paragraph to another, including additions, deletions,\nand substitutions. In particular, we use the Levenshtein edit ratio\nmeasure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to one indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision of a document, the algorithm computes the\nLevenshtein ratio between each paragraph in the old version and each\nparagraph in the new version. Two paragraphs are mapped across the\nrevision if they each have the highest Levenshtein ratio for the other.\nIf a paragraph in the new version has no matching paragraphs in the old\nversion, meaning that none of its ratios were above a threshold of 0.4,\nwe label the paragraph as an addition. If a paragraph in the old version\nis not matched with any paragraphs in the next version, then we consider\nit a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:\nparagraphs 9, 10, and 12 of the old version were deleted, while the\nothers found clear matches (e.g., paragraph 11 in the revised document\nwas mapped with paragraph 9 in the older version of the document).'
p2303
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2304
(dp2305
g10
S"\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}{[}3{]} We consider a significant change to be a noticeable change in\nthe paragraph's topic and content. For this calculation, the Levenshtein\nratio does not provide the right kind of information. For example, if\ntwo of the paragraph's sentences switch places, the Levenshtein ratio\nwould decrease despite no meaningful change in content. On the other\nhand, changing a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p2306
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2307
(dp2308
g10
S"{[}1; omitting the ``therefore''{]}Therefore, we use a topic modeling\napproach, which is a better fit for assessing changes in content.\nSpecifically, we use cosine similarity between word vectors that\nrepresent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors."
p2309
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2310
(dp2311
g10
S'{[}2{]} By calculating the topic similarity between two concurrent\nversions of an edited paragraph, the system can detect whether a\nsignificant change has occurred. If the cosine similarity between the\ntwo paragraphs was below an empirically determined threshold of 0.8, we\nlabel the edit as significant.'
p2312
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2313
(dp2314
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p2315
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2316
(dp2317
g10
S'We considered three possible types of inter-paragraph relationships.\nParagraphs could be related by \\emph{proximity}: perhaps the neighboring\nparagraphs would require adjustments, as they are likely part of the\nsame section. Paragraphs could also be related by \\emph{topic\nsimilarity}. For example, in an academic paper, the discussion section\nand the conclusion should present similar themes. If one changes, the\nother may need to be edited to reflect this change. For each significant\nchange, we used the existing LSI Topic Model to determine which\nparagraphs discussed similar topics. Lastly, paragraphs could be related\nbecause of similar \\emph{edit histories}. For each paragraph that\nunderwent a significant change, we evaluated the edit history of this\nparagraph with every other paragraph in the document. We labeled pairs\nas related if they changed or remained unchanged together over half the\ntime. With a higher threshold, the sample size decreases, but with a\nlower threshold, the results become less predictive of a significant\nchange prompting further edits. This threshold strikes a balance between\nthese two outcomes, as discussed in the Findings section.'
p2318
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2319
(dp2320
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}preliminary evaluation of the proposed methods used a corpus of\nWikipedia articles and their revision histories.'
p2321
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2322
(dp2323
g10
S'\\subsection{Data}\\label{data}Wikipedia is a unique source for collaborative writing, providing\nextensive data. For our empirical evaluation, we used the complete\nrevision history of 41 different articles chosen from a diverse set of\ntopics, ranging from famous people and places to mathematical algorithms\nto novels. A variety of recent work has used this approach\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes~\\footnote{We defined minor\n  edits as having a Levenshtein distance of under fifteen.} were\neliminated as well to reduce the number of maintenance edits\n\\cite{kittur2007he}. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs each.\nWikipedia data affords results applicable to other collaborative writing\nspaces with smaller groups of collaborators, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In our corpus, 15 authors on average made 80\\%\nof the edits to an article.'
p2324
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2325
(dp2326
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the foundation for edit prediction.'
p2327
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2328
(dp2329
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p2330
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2331
(dp2332
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a couple hundred of these edits\nto determine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p2333
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2334
(dp2335
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, where each\nline represents a paragraph that is edited significantly at time zero\nfor the first time in a while, further adjustments (as represented by\ndownward spikes) are triggered in the near future.'
p2336
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2337
(dp2338
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p2339
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2340
(dp2341
g10
S'In the Wikipedia data, paragraphs related by edit history were found on\naverage 1.6 times per version, and paragraphs related by topic\nsimilarity were rarer and only found on average once every ten versions\nof the text.'
p2342
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2343
(dp2344
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive than physical\nproximity, as shown in Table~{[}table:futureEdits{]}. They are also\nsignificantly more predictive than random sample controls. For controls,\nwe compare with the original paragraph as well as a random sample of any\nten consecutive versions within Wikipedia article histories.'
p2345
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2346
(dp2347
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. (Proximity was not evaluated for this harsher measure, as\nit did almost no better than the random control for the first measure.)\nFurther, we obtained a recall of 80\\% for these correct predictions;\nthus, only 20\\% of the paragraphs that should have been labeled as\nrelated (based on information ten versions in the future) were missed.'
p2348
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2349
(dp2350
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p2351
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2352
(dp2353
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This capability\nprovides the basis for detecting significant changes and anticipating\nfuture semantic conflicts. Our edit evaluation method successfully\ndetects the most significant changes using the LSI Topic Similarity\nmodel. Based on these significant changes, our anticipate possible\nsemantic conflicts in linked paragraphs. After a significant change,\nparagraphs related to the edited paragraph were indeed more likely to be\nedited in response a couple versions later. Paragraphs linked by similar\nedit histories were most likely to need editing, with paragraphs linked\nby topic similarity not far behind.'
p2354
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2355
(dp2356
g10
S'Our long-term goal is to build an assistive system that will improve the\ncollaborative writing process. Our developed methods provide the basis\nfor such a system, by enabling automatic detection of significant edits\nand predicting their effects. These capabilities can inform decisions\nabout alerting authors to specific changes and places in the document\nthat are likely to require revisions. Thus far, have not investigated\nways to leverage information about the authors who made the edits. In\nfuture work, we plan to incorporate information about author identity to\ndesign personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur.'
p2357
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2358
(dp2359
g10
S'We also plan to develop additional algorithms for summarizing changes\nand to investigate the use of algorithms that measure text coherence\n(e.g.,Textiling \\cite{hearst1994multi}) for alerting authors to portions\nof the text that appear to lack coherence. Finally, we plan to explore\nalternative ways of presenting to authors the information chosen by the\nalgorithms as important for them to consider. For example, the system\nmight highlight changes that it deems relevant or provide a list of them\nwith links to the places they appear in the text.\n'
p2360
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p2361
sba(iversion
Version
p2362
(dp2363
g7
g8
(S'\x07\xde\x0c\x1d\x14\x01,\x08\xbeH'
tRp2364
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nParagraphs related by edit history were found on average 1.6 times per\nversion, and paragraphs related by topic similarity were more rare and\nonly found on average once every ten versions of the text. Proximity\nrelationships always exist for each paragraphs as there are always\nneighboring paragraphs.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2365
sg12
(lp2366
(iversion
Paragraph
p2367
(dp2368
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p2369
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2370
(dp2371
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p2372
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2373
(dp2374
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p2375
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2376
(dp2377
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p2378
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2379
(dp2380
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p2381
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2382
(dp2383
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2384
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2385
(dp2386
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p2387
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2388
(dp2389
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p2390
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2391
(dp2392
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p2393
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2394
(dp2395
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p2396
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2397
(dp2398
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p2399
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2400
(dp2401
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p2402
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2403
(dp2404
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p2405
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2406
(dp2407
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p2408
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2409
(dp2410
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p2411
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2412
(dp2413
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p2414
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2415
(dp2416
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p2417
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2418
(dp2419
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p2420
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2421
(dp2422
g10
S'Paragraphs related by edit history were found on average 1.6 times per\nversion, and paragraphs related by topic similarity were more rare and\nonly found on average once every ten versions of the text. Proximity\nrelationships always exist for each paragraphs as there are always\nneighboring paragraphs.'
p2423
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2424
(dp2425
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p2426
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2427
(dp2428
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.'
p2429
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2430
(dp2431
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p2432
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2433
(dp2434
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p2435
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p2436
sba(iversion
Version
p2437
(dp2438
g7
g8
(S'\x07\xde\x0c\x0e\x10\x18\x0f\x0c\xaa0'
tRp2439
sg10
S". See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.\n\n\\section{Introduction}\\label{introduction}\n\nMaybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikis\n\nnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision Activity\n\nWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nThe system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.\n\nINSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.\n\nThis method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches.\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in figure\n{[}X{]}.\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p2440
sg12
(lp2441
(iversion
Paragraph
p2442
(dp2443
g10
S'. See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.'
p2444
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2445
(dp2446
g10
S'\\section{Introduction}\\label{introduction}Maybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikisnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision ActivityWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.'
p2447
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2448
(dp2449
g10
S'The system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.'
p2450
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2451
(dp2452
g10
S"INSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit."
p2453
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2454
(dp2455
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p2456
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2457
(dp2458
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.'
p2459
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2460
(dp2461
g10
S'This method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.'
p2462
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2463
(dp2464
g10
S"A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches."
p2465
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2466
(dp2467
g10
S"\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p2468
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2469
(dp2470
g10
S"As shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance."
p2471
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2472
(dp2473
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p2474
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2475
(dp2476
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p2477
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2478
(dp2479
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p2480
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2481
(dp2482
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p2483
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2484
(dp2485
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p2486
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2487
(dp2488
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p2489
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2490
(dp2491
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in figure\n{[}X{]}.'
p2492
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2493
(dp2494
g10
S'We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p2495
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2496
(dp2497
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p2498
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2499
(dp2500
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.'
p2501
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2502
(dp2503
g10
S'Caption: After a significant change at version 0, consequent edits are\nmore frequent.'
p2504
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2505
(dp2506
g10
S'We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p2507
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2508
(dp2509
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.'
p2510
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2511
(dp2512
g10
S'Relationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80Relationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p2513
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2514
(dp2515
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p2516
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2517
(dp2518
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p2519
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2520
(dp2521
g10
S'We imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.'
p2522
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2523
(dp2524
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n'
p2525
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p2526
sba(iversion
Version
p2527
(dp2528
g7
g8
(S'\x07\xde\x0c\x1f\x11\x00\x1d\x0c8\xe8'
tRp2529
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nPairs of paragraphs related by edit history were found on average 1.6\ntimes per revision of the text. A pair related by topic similarity were\nonly found once every ten versions. Proximity relationships always exist\nfor each paragraphs as there are always neighboring paragraphs.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2530
sg12
(lp2531
(iversion
Paragraph
p2532
(dp2533
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p2534
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2535
(dp2536
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p2537
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2538
(dp2539
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p2540
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2541
(dp2542
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p2543
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2544
(dp2545
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p2546
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2547
(dp2548
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2549
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2550
(dp2551
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p2552
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2553
(dp2554
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p2555
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2556
(dp2557
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p2558
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2559
(dp2560
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p2561
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2562
(dp2563
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p2564
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2565
(dp2566
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p2567
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2568
(dp2569
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p2570
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2571
(dp2572
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p2573
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2574
(dp2575
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p2576
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2577
(dp2578
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p2579
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2580
(dp2581
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p2582
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2583
(dp2584
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p2585
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2586
(dp2587
g10
S'Pairs of paragraphs related by edit history were found on average 1.6\ntimes per revision of the text. A pair related by topic similarity were\nonly found once every ten versions. Proximity relationships always exist\nfor each paragraphs as there are always neighboring paragraphs.'
p2588
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2589
(dp2590
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p2591
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2592
(dp2593
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.'
p2594
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2595
(dp2596
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p2597
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2598
(dp2599
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p2600
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p2601
sba(iversion
Version
p2602
(dp2603
g7
g8
(S'\x07\xdf\x01\x01\x16 \x01\x07\x85\xc8'
tRp2604
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nPairs of paragraphs related by edit history were found on average 1.6\ntimes per revision of the text. A pair related by topic similarity were\nonly found once every ten versions. Proximity relationships always exist\nfor each paragraphs as there are always neighboring paragraphs.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2605
sg12
(lp2606
(iversion
Paragraph
p2607
(dp2608
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p2609
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2610
(dp2611
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p2612
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2613
(dp2614
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p2615
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2616
(dp2617
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p2618
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2619
(dp2620
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p2621
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2622
(dp2623
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2624
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2625
(dp2626
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p2627
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2628
(dp2629
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p2630
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2631
(dp2632
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p2633
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2634
(dp2635
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p2636
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2637
(dp2638
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p2639
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2640
(dp2641
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p2642
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2643
(dp2644
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p2645
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2646
(dp2647
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p2648
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2649
(dp2650
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p2651
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2652
(dp2653
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p2654
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2655
(dp2656
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p2657
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2658
(dp2659
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p2660
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2661
(dp2662
g10
S'Pairs of paragraphs related by edit history were found on average 1.6\ntimes per revision of the text. A pair related by topic similarity were\nonly found once every ten versions. Proximity relationships always exist\nfor each paragraphs as there are always neighboring paragraphs.'
p2663
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2664
(dp2665
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p2666
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2667
(dp2668
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.'
p2669
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2670
(dp2671
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p2672
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2673
(dp2674
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p2675
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p2676
sba(iversion
Version
p2677
(dp2678
g7
g8
(S'\x07\xdf\x01\x02\x10\x16"\x03[`'
tRp2679
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nPairs of paragraphs related by edit history were found on average 1.6\ntimes per revision of the text. A pair related by topic similarity were\nonly found once every ten versions. Proximity relationships always exist\nfor each paragraphs as there are always neighboring paragraphs.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2680
sg12
(lp2681
(iversion
Paragraph
p2682
(dp2683
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p2684
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2685
(dp2686
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p2687
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2688
(dp2689
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p2690
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2691
(dp2692
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p2693
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2694
(dp2695
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p2696
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2697
(dp2698
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2699
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2700
(dp2701
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p2702
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2703
(dp2704
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p2705
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2706
(dp2707
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p2708
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2709
(dp2710
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p2711
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2712
(dp2713
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p2714
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2715
(dp2716
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p2717
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2718
(dp2719
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p2720
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2721
(dp2722
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p2723
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2724
(dp2725
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p2726
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2727
(dp2728
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p2729
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2730
(dp2731
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p2732
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2733
(dp2734
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p2735
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2736
(dp2737
g10
S'Pairs of paragraphs related by edit history were found on average 1.6\ntimes per revision of the text. A pair related by topic similarity were\nonly found once every ten versions. Proximity relationships always exist\nfor each paragraphs as there are always neighboring paragraphs.'
p2738
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2739
(dp2740
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p2741
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2742
(dp2743
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.'
p2744
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2745
(dp2746
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p2747
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2748
(dp2749
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p2750
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p2751
sba(iversion
Version
p2752
(dp2753
g7
g8
(S'\x07\xdf\x01\x02\x10\x16%\x07;\x90'
tRp2754
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nPairs of paragraphs related by edit history were found on average 1.6\ntimes per revision of the text. A pair related by topic similarity were\nonly found once every ten versions. Proximity relationships always exist\nfor each paragraphs as there are always neighboring paragraphs.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2755
sg12
(lp2756
(iversion
Paragraph
p2757
(dp2758
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p2759
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2760
(dp2761
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p2762
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2763
(dp2764
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p2765
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2766
(dp2767
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p2768
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2769
(dp2770
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p2771
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2772
(dp2773
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2774
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2775
(dp2776
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p2777
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2778
(dp2779
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p2780
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2781
(dp2782
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p2783
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2784
(dp2785
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p2786
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2787
(dp2788
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p2789
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2790
(dp2791
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p2792
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2793
(dp2794
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p2795
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2796
(dp2797
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p2798
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2799
(dp2800
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p2801
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2802
(dp2803
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p2804
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2805
(dp2806
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p2807
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2808
(dp2809
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p2810
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2811
(dp2812
g10
S'Pairs of paragraphs related by edit history were found on average 1.6\ntimes per revision of the text. A pair related by topic similarity were\nonly found once every ten versions. Proximity relationships always exist\nfor each paragraphs as there are always neighboring paragraphs.'
p2813
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2814
(dp2815
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p2816
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2817
(dp2818
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.'
p2819
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2820
(dp2821
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p2822
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2823
(dp2824
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p2825
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p2826
sba(iversion
Version
p2827
(dp2828
g7
g8
(S'\x07\xdf\x01\x02\x10\x1e\x02\x05$h'
tRp2829
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nPairs of paragraphs related by edit history were found on average 1.6\ntimes per revision of the text. A pair related by topic similarity were\nonly found once every ten versions. Proximity relationships always exist\nfor each paragraphs as there are always neighboring paragraphs.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2830
sg12
(lp2831
(iversion
Paragraph
p2832
(dp2833
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p2834
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2835
(dp2836
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p2837
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2838
(dp2839
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p2840
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2841
(dp2842
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p2843
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2844
(dp2845
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p2846
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2847
(dp2848
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2849
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2850
(dp2851
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorrespond to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p2852
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2853
(dp2854
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p2855
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2856
(dp2857
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p2858
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2859
(dp2860
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p2861
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2862
(dp2863
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p2864
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2865
(dp2866
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p2867
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2868
(dp2869
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p2870
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2871
(dp2872
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p2873
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2874
(dp2875
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p2876
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2877
(dp2878
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p2879
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2880
(dp2881
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p2882
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2883
(dp2884
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p2885
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2886
(dp2887
g10
S'Pairs of paragraphs related by edit history were found on average 1.6\ntimes per revision of the text. A pair related by topic similarity were\nonly found once every ten versions. Proximity relationships always exist\nfor each paragraphs as there are always neighboring paragraphs.'
p2888
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2889
(dp2890
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p2891
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2892
(dp2893
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.'
p2894
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2895
(dp2896
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p2897
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2898
(dp2899
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p2900
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p2901
sba(iversion
Version
p2902
(dp2903
g7
g8
(S'\x07\xdf\x01\x02\x11\x04"\x00\'\x10'
tRp2904
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2905
sg12
(lp2906
(iversion
Paragraph
p2907
(dp2908
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p2909
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2910
(dp2911
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p2912
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2913
(dp2914
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p2915
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2916
(dp2917
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p2918
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2919
(dp2920
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p2921
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2922
(dp2923
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2924
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2925
(dp2926
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p2927
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2928
(dp2929
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p2930
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2931
(dp2932
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p2933
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2934
(dp2935
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p2936
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2937
(dp2938
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{topic\nsimilarity}, i.e., paragraphs with high cosine similarity, and (3)\n\\emph{edit histories}, i.e., paragraphs that tended to be edited\ntogether in previous revisions. For (3), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p2939
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2940
(dp2941
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p2942
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2943
(dp2944
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p2945
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2946
(dp2947
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p2948
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2949
(dp2950
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p2951
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2952
(dp2953
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p2954
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2955
(dp2956
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p2957
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2958
(dp2959
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p2960
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2961
(dp2962
g10
S'On average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.'
p2963
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2964
(dp2965
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p2966
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2967
(dp2968
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.'
p2969
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2970
(dp2971
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p2972
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2973
(dp2974
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p2975
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p2976
sba(iversion
Version
p2977
(dp2978
g7
g8
(S'\x07\xdf\x01\x02\x116\x14\x08\x06\xb0'
tRp2979
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p2980
sg12
(lp2981
(iversion
Paragraph
p2982
(dp2983
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p2984
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2985
(dp2986
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p2987
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2988
(dp2989
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p2990
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2991
(dp2992
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p2993
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2994
(dp2995
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p2996
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p2997
(dp2998
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p2999
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3000
(dp3001
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p3002
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3003
(dp3004
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p3005
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3006
(dp3007
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3008
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3009
(dp3010
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3011
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3012
(dp3013
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p3014
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3015
(dp3016
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3017
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3018
(dp3019
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p3020
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3021
(dp3022
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p3023
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3024
(dp3025
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p3026
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3027
(dp3028
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p3029
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3030
(dp3031
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, topic similarity and edit history) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p3032
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3033
(dp3034
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p3035
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3036
(dp3037
g10
S'On average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.'
p3038
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3039
(dp3040
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity{[}a{]}{[}b{]} are much more predictive of a future\nsignificant edit than proximity, as shown in\nTable~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p3041
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3042
(dp3043
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 63\\% of pairs\nrelated by topic and 71\\% of pairs related by edit history. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.'
p3044
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3045
(dp3046
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3047
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3048
(dp3049
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p3050
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p3051
sba(iversion
Version
p3052
(dp3053
g7
g8
(S'\x07\xdf\x01\x02\x11;7\x07\x0c\xb0'
tRp3054
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic . (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p3055
sg12
(lp3056
(iversion
Paragraph
p3057
(dp3058
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p3059
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3060
(dp3061
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p3062
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3063
(dp3064
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p3065
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3066
(dp3067
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p3068
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3069
(dp3070
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p3071
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3072
(dp3073
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p3074
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3075
(dp3076
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p3077
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3078
(dp3079
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p3080
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3081
(dp3082
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3083
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3084
(dp3085
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3086
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3087
(dp3088
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p3089
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3090
(dp3091
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3092
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3093
(dp3094
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p3095
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3096
(dp3097
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p3098
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3099
(dp3100
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p3101
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3102
(dp3103
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p3104
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3105
(dp3106
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p3107
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3108
(dp3109
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p3110
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3111
(dp3112
g10
S'On average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.'
p3113
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3114
(dp3115
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.'
p3116
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3117
(dp3118
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic . (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.'
p3119
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3120
(dp3121
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3122
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3123
(dp3124
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p3125
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p3126
sba(iversion
Version
p3127
(dp3128
g7
g8
(S'\x07\xdf\x01\x02\x16\x1f0\x0cX('
tRp3129
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p3130
sg12
(lp3131
(iversion
Paragraph
p3132
(dp3133
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p3134
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3135
(dp3136
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p3137
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3138
(dp3139
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p3140
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3141
(dp3142
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p3143
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3144
(dp3145
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p3146
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3147
(dp3148
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p3149
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3150
(dp3151
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p3152
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3153
(dp3154
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p3155
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3156
(dp3157
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3158
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3159
(dp3160
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3161
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3162
(dp3163
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p3164
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3165
(dp3166
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3167
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3168
(dp3169
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p3170
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3171
(dp3172
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p3173
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3174
(dp3175
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p3176
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3177
(dp3178
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p3179
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3180
(dp3181
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p3182
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3183
(dp3184
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p3185
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3186
(dp3187
g10
S'On average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.'
p3188
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3189
(dp3190
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.'
p3191
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3192
(dp3193
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; thus, only 20\\%\nof the paragraphs that should have been labeled as related (based on\ninformation ten versions in the future) were missed.'
p3194
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3195
(dp3196
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3197
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3198
(dp3199
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p3200
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p3201
sba(iversion
Version
p3202
(dp3203
g7
g8
(S'\x07\xdf\x01\x02\x160$\x06\xf1X'
tRp3204
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p3205
sg12
(lp3206
(iversion
Paragraph
p3207
(dp3208
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p3209
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3210
(dp3211
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p3212
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3213
(dp3214
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p3215
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3216
(dp3217
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p3218
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3219
(dp3220
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p3221
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3222
(dp3223
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p3224
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3225
(dp3226
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p3227
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3228
(dp3229
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p3230
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3231
(dp3232
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3233
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3234
(dp3235
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3236
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3237
(dp3238
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p3239
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3240
(dp3241
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3242
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3243
(dp3244
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p3245
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3246
(dp3247
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p3248
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3249
(dp3250
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p3251
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3252
(dp3253
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p3254
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3255
(dp3256
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p3257
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3258
(dp3259
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p3260
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3261
(dp3262
g10
S'On average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.'
p3263
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3264
(dp3265
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.'
p3266
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3267
(dp3268
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.'
p3269
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3270
(dp3271
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a collaborative system that will improve\nthe collaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edit and\nfor predicting future edits, provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3272
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3273
(dp3274
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p3275
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p3276
sba(iversion
Version
p3277
(dp3278
g7
g8
(S'\x07\xde\x0c\x0e\x10\x18\x13\x07\xa5\x08'
tRp3279
sg10
S". See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.\n\n\\section{Introduction}\\label{introduction}\n\nMaybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikis\n\nnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision Activity\n\nWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nThe system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.\n\nINSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.\n\nThis method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches.\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in figure\n{[}X{]}.\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p3280
sg12
(lp3281
(iversion
Paragraph
p3282
(dp3283
g10
S'. See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.'
p3284
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3285
(dp3286
g10
S'\\section{Introduction}\\label{introduction}Maybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikisnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision ActivityWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.'
p3287
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3288
(dp3289
g10
S'The system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.'
p3290
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3291
(dp3292
g10
S"INSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit."
p3293
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3294
(dp3295
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p3296
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3297
(dp3298
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.'
p3299
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3300
(dp3301
g10
S'This method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.'
p3302
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3303
(dp3304
g10
S"A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches."
p3305
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3306
(dp3307
g10
S"\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p3308
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3309
(dp3310
g10
S"As shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance."
p3311
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3312
(dp3313
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p3314
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3315
(dp3316
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p3317
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3318
(dp3319
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p3320
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3321
(dp3322
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p3323
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3324
(dp3325
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p3326
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3327
(dp3328
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p3329
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3330
(dp3331
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in figure\n{[}X{]}.'
p3332
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3333
(dp3334
g10
S'We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p3335
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3336
(dp3337
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p3338
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3339
(dp3340
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.'
p3341
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3342
(dp3343
g10
S'Caption: After a significant change at version 0, consequent edits are\nmore frequent.'
p3344
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3345
(dp3346
g10
S'We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p3347
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3348
(dp3349
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.'
p3350
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3351
(dp3352
g10
S'Relationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80Relationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p3353
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3354
(dp3355
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p3356
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3357
(dp3358
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p3359
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3360
(dp3361
g10
S'We imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.'
p3362
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3363
(dp3364
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n'
p3365
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p3366
sba(iversion
Version
p3367
(dp3368
g7
g8
(S'\x07\xdf\x01\x03\x04/\x1f\x08\x1e '
tRp3369
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits.\n\nBecause authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.\n\nThis paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p3370
sg12
(lp3371
(iversion
Paragraph
p3372
(dp3373
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntowards the development of a collaborative system for supporting\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits and predicting parts of the paper that are\nlikely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p3374
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3375
(dp3376
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nor relevance of changes to different authors and do not consider how\nedits might affect other parts of the document. Therefore, there is\ncurrently significant coordination overhead: authors need to frequently\nre-read the entire document or rely on communication from their\nco-authors in order to keep track with the current state of the document\nand ensure that their edits are mash with other edits."
p3377
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3378
(dp3379
g10
S'Because authors need to make sure their edits are coherent with the\ndocument as a whole, including sections written by others, they need to\nread the entire document frequently, or rely on updates from their\nco-authors. Even when authors communicate with each other frequently,\nthey can get lost in the volume of edits from other collaborators or\nbecome overwhelmed with too much information.'
p3380
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3381
(dp3382
g10
S'This paper presents our initial work towards the development of a\ncollaborative system for assisting multi-author writing by drawing\nauthors attention to edits that are important and relevant for them, and\npointing out other parts of the document that are likely to require\nediting given changes they have just made.'
p3383
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3384
(dp3385
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have potential to\nimprove coherence and coordination while reducing authors' communication\nburden. An empirical evaluation of the approach on a corpus of Wikipedia\narticles shows promising initial results. Using these methods it is\npossible to track paragraph across revisions, identify significant\nchanges, and predict the paragraphs that are likely to be edited\nfollowing a significant edit of a particular paragraph."
p3386
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3387
(dp3388
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorization of edits\nand interfaces for presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p3389
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3390
(dp3391
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our investigation of the\nlightweight use of NLP techniques and history tracking for providing\nthese important capabilities\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version)."
p3392
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3393
(dp3394
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p3395
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3396
(dp3397
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3398
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3399
(dp3400
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3401
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3402
(dp3403
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p3404
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3405
(dp3406
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3407
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3408
(dp3409
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p3410
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3411
(dp3412
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p3413
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3414
(dp3415
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p3416
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3417
(dp3418
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p3419
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3420
(dp3421
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p3422
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3423
(dp3424
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p3425
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3426
(dp3427
g10
S'On average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.'
p3428
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3429
(dp3430
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.'
p3431
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3432
(dp3433
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.'
p3434
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3435
(dp3436
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3437
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3438
(dp3439
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p3440
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p3441
sba(iversion
Version
p3442
(dp3443
g7
g8
(S'\x07\xdf\x01\x03\x10\x189\x07GH'
tRp3444
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits, and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p3445
sg12
(lp3446
(iversion
Paragraph
p3447
(dp3448
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits, and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p3449
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3450
(dp3451
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits."
p3452
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3453
(dp3454
g10
S"This paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made."
p3455
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3456
(dp3457
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph."
p3458
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3459
(dp3460
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p3461
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3462
(dp3463
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities."
p3464
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3465
(dp3466
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: paragraphs 9, 10,\nand 12 of the old version were deleted, while the others found clear\nmatches (e.g., paragraph 11 in the new version was mapped with paragraph\n9 in the old version).'
p3467
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3468
(dp3469
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach. Specifically, we use cosine similarity between word\nvectors that represent the paragraphs, incorporating Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI) which accounts for synonyms\nand does not penalize for typographical errors. If the cosine similarity\nbetween the new and old versions of a paragraph is below an empirically\ndetermined threshold of 0.8, we consider the edit to be significant."
p3470
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3471
(dp3472
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3473
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3474
(dp3475
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3476
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3477
(dp3478
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, that is neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith high cosine similarity. For (2), we labeled pairs as related if\nthey changed or remained unchanged together over half the time in\nprevious revisions.'
p3479
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3480
(dp3481
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3482
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3483
(dp3484
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p3485
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3486
(dp3487
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p3488
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3489
(dp3490
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p3491
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3492
(dp3493
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p3494
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3495
(dp3496
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p3497
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3498
(dp3499
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p3500
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3501
(dp3502
g10
S'On average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.'
p3503
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3504
(dp3505
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.'
p3506
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3507
(dp3508
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.'
p3509
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3510
(dp3511
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3512
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3513
(dp3514
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p3515
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p3516
sba(iversion
Version
p3517
(dp3518
g7
g8
(S"\x07\xdf\x01\x03\x10'\x03\x00\xe2\x90"
tRp3519
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits, and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p3520
sg12
(lp3521
(iversion
Paragraph
p3522
(dp3523
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits, and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p3524
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3525
(dp3526
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits."
p3527
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3528
(dp3529
g10
S"This paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made."
p3530
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3531
(dp3532
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph."
p3533
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3534
(dp3535
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p3536
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3537
(dp3538
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities."
p3539
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3540
(dp3541
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}tracking\\textsubscript{v}is\\textsubscript{p}aper.pngAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3542
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3543
(dp3544
g10
S"\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant."
p3545
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3546
(dp3547
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3548
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3549
(dp3550
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3551
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3552
(dp3553
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.'
p3554
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3555
(dp3556
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3557
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3558
(dp3559
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough information. To focus on revisions that contain some substantial\nchanges, the versions with simple typo fixes (Levenshtein distance\n\\(< 15\\) ) were eliminated.'
p3560
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3561
(dp3562
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. Our\nmain focus was the prediction of future edits, but we also conducted a\nmanual evaluation of paragraph mapping and significant change detection,\nwhich formed the basis for edit prediction.'
p3563
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3564
(dp3565
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p3566
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3567
(dp3568
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p3569
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3570
(dp3571
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p3572
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3573
(dp3574
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p3575
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3576
(dp3577
g10
S'On average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.'
p3578
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3579
(dp3580
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.'
p3581
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3582
(dp3583
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.'
p3584
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3585
(dp3586
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3587
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3588
(dp3589
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p3590
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p3591
sba(iversion
Version
p3592
(dp3593
g7
g8
(S'\x07\xdf\x01\x03\x102\t\t#\xd8'
tRp3594
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits, and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made.\n\nThe paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which formed the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.\n\nOn average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n"
p3595
sg12
(lp3596
(iversion
Paragraph
p3597
(dp3598
g10
S"Many documents (e.g., academic papers) are typically written by multiple\ncollaborators. While many existing tools support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. While capabilities such as ``track\nchanges'' and ``diff'' visualize changes to authors, they do not\ndistinguish between minor and major edits, and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the proposed methods shows promising results."
p3599
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3600
(dp3601
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits."
p3602
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3603
(dp3604
g10
S"This paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made."
p3605
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3606
(dp3607
g10
S"The paper describes methods for tracking paragraphs as they are revised,\nfor identifying paragraphs that have been significantly changed, and for\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph."
p3608
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3609
(dp3610
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p3611
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3612
(dp3613
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities."
p3614
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3615
(dp3616
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3617
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3618
(dp3619
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant."
p3620
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3621
(dp3622
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3623
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3624
(dp3625
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3626
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3627
(dp3628
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.'
p3629
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3630
(dp3631
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3632
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3633
(dp3634
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p3635
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3636
(dp3637
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which formed the basis for edit prediction.'
p3638
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3639
(dp3640
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As can be seen, most edits are\nminor, and with the threshold ratio of 0.8 we labeled about 15\\% of the\nedits as significant.'
p3641
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3642
(dp3643
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\ndetermine 1) that paragraphs were correctly mapped and 2) that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit in Figure~{[}fig:pars{]}. While these paragraphs are\nclearly the same, the edit is significant because it contributes content\nand changes the tone of the paragraph.'
p3644
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3645
(dp3646
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We generally found that a significant edit to a paragraph often triggers\nedits in other paragraphs in the next revisions. This is shown in\nFigure~{[}fig:edits{]}, where each line represents a paragraph that is\nedited significantly at time 0 after not being significantly edited in\nrecent versions, further adjustments (as represented by downward spikes)\nare triggered in the near future. We evaluated the three inter-paragraph\nrelationships (proximity, edit history, and topic similarity) to\ndetermine which paragraphs are more likely to require further editing\nafter a significant change occurs in the article.'
p3647
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3648
(dp3649
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checked whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the paragraphs continue to be edited together ten\nversions after the significant change, that is whether they change\ntogether (or remain unchanged together) more than half the time. This is\na stronger indication than just undergoing at least one significant\nchange.'
p3650
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3651
(dp3652
g10
S'On average, 1.6 pairs of paragraphs related by edit history were found\nper revision of the text. A pair related by topic similarity was only\nfound once every ten versions. Proximity relationships always exist in\neach version, as most paragraphs have two neighbors.'
p3653
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3654
(dp3655
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.'
p3656
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3657
(dp3658
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times there exists at least one significant\nchange}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions; That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) were not included in the set\nof related paragraphs predicted by edit history and topic similarity.'
p3659
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3660
(dp3661
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3662
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3663
(dp3664
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on their context of\nediting and history of revisions. For example, the paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which can be used to determine who\nto alert when significant edits occur. We also plan to develop\nadditional algorithms for summarizing changes and to investigate the use\nof algorithms that measure text coherence (e.g.,Textiling\n\\cite{hearst1994multi}) for alerting authors to portions of the text\nthat appear to lack coherence. Finally, we plan to explore alternative\nways of presenting to authors the information chosen by the algorithms\nas important for them to consider. For example, the system might\nhighlight changes that it deems relevant or provide a list of them with\nlinks to the places they appear in the text.\n'
p3665
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p3666
sba(iversion
Version
p3667
(dp3668
g7
g8
(S"\x07\xdf\x01\x03\x11\x10'\nw\xb0"
tRp3669
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While many existing tools support such collaborative efforts\n(e.g., dropbox, google docs), these tools lack intelligent information\nsharing mechanisms. While capabilities such as ``track changes'' and\n``diff'' visualize changes to authors, they do not distinguish between\nminor and major edits, and do not consider the possible effects of edits\non other parts of the document. Drawing collaborators' attention to\nspecific edits and describing them remains the responsibility of\nauthors. This paper presents our initial work toward the development of\na collaborative system that supports multi-author writing. We describe\nmethods for tracking paragraphs, identifying significant edits, and\npredicting parts of the paper that are likely to require changes as a\nresult of previous edits. Preliminary evaluation of the proposed methods\nshows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made. The paper\ndescribes methods for tracking paragraphs as they are revised,\nidentifying paragraphs that have been significantly changed, and\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future(as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they change\ntogether (or remain unchanged together) more than half the time. This\nsecond measure is a stronger indication than a paragraph undergoing just\none significant change.\n\nThe frequency of the relationship occurrence was variable. On average,\n1.6 pairs of paragraphs related by edit history were found per revision\nof the text. A pair related by topic similarity was only found once\nevery ten versions. Proximity relationships always exist in each\nversion, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than controls. For these controls, we compare with the\noriginal paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions. That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) and were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alerting authors to portions of the text that could be\nimproved. Finally, we plan to explore alternative ways of presenting the\ninformation chosen by the algorithms as important for authors to\nconsider. For example, the system might highlight changes that it deems\nrelevant or provide a list of them with links to the places they appear\nin the text.\n"
p3670
sg12
(lp3671
(iversion
Paragraph
p3672
(dp3673
g10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While many existing tools support such collaborative efforts\n(e.g., dropbox, google docs), these tools lack intelligent information\nsharing mechanisms. While capabilities such as ``track changes'' and\n``diff'' visualize changes to authors, they do not distinguish between\nminor and major edits, and do not consider the possible effects of edits\non other parts of the document. Drawing collaborators' attention to\nspecific edits and describing them remains the responsibility of\nauthors. This paper presents our initial work toward the development of\na collaborative system that supports multi-author writing. We describe\nmethods for tracking paragraphs, identifying significant edits, and\npredicting parts of the paper that are likely to require changes as a\nresult of previous edits. Preliminary evaluation of the proposed methods\nshows promising results."
p3674
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3675
(dp3676
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'' and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits."
p3677
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3678
(dp3679
g10
S"This paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing given the changes they have just made. The paper\ndescribes methods for tracking paragraphs as they are revised,\nidentifying paragraphs that have been significantly changed, and\npredicting which parts of the document are likely to change following a\nparticular edit. Systems with such capabilities have the potential to\nimprove coherence and coordination while reducing the authors'\ncommunication burden. An empirical evaluation of the approach on a\ncorpus of Wikipedia articles shows promising initial results. Using\nthese methods, it is possible to track paragraphs across revisions,\nidentify significant changes, and predict paragraphs likely to be edited\nfollowing a significant edit of a particular paragraph."
p3680
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3681
(dp3682
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant edits and furthermore predict future\nedits, without requiring authors to specify explicitly what changes are\nof interest to them. These capabilities go beyond prior approaches for\nsupporting change awareness in that they can support authors not only in\nfinding the changes that have been made, but also in drawing their\nattention to parts of the document that are likely to require edits as a\nresult of those changes.'
p3683
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3684
(dp3685
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques and history tracking, which provide the basis for these\nimportant capabilities."
p3686
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3687
(dp3688
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3689
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3690
(dp3691
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant."
p3692
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3693
(dp3694
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3695
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3696
(dp3697
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3698
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3699
(dp3700
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.'
p3701
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3702
(dp3703
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3704
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3705
(dp3706
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p3707
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3708
(dp3709
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.'
p3710
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3711
(dp3712
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p3713
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3714
(dp3715
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.'
p3716
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3717
(dp3718
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future(as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p3719
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3720
(dp3721
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they change\ntogether (or remain unchanged together) more than half the time. This\nsecond measure is a stronger indication than a paragraph undergoing just\none significant change.'
p3722
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3723
(dp3724
g10
S'The frequency of the relationship occurrence was variable. On average,\n1.6 pairs of paragraphs related by edit history were found per revision\nof the text. A pair related by topic similarity was only found once\nevery ten versions. Proximity relationships always exist in each\nversion, as most paragraphs have two neighbors.'
p3725
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3726
(dp3727
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than controls. For these controls, we compare with the\noriginal paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.'
p3728
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3729
(dp3730
g10
S'{\\textbar{}p{5cm}\\textbar{}p{5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions. That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) and were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.'
p3731
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3732
(dp3733
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3734
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3735
(dp3736
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alerting authors to portions of the text that could be\nimproved. Finally, we plan to explore alternative ways of presenting the\ninformation chosen by the algorithms as important for authors to\nconsider. For example, the system might highlight changes that it deems\nrelevant or provide a list of them with links to the places they appear\nin the text.\n'
p3737
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p3738
sba(iversion
Version
p3739
(dp3740
g7
g8
(S'\x07\xdf\x01\x03\x11.%\x05\xdf\xe8'
tRp3741
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While many existing tools support such collaborative efforts\n(e.g., dropbox, google docs), these tools lack intelligent information\nsharing mechanisms. While capabilities such as ``track changes'' and\n``diff'' visualize changes to authors, they do not distinguish between\nminor and major edits, and do not consider the possible effects of edits\non other parts of the document. Drawing collaborators' attention to\nspecific edits and describing them remains the responsibility of\nauthors. This paper presents our initial work toward the development of\na collaborative system that supports multi-author writing. We describe\nmethods for tracking paragraphs, identifying significant edits, and\npredicting parts of the paper that are likely to require changes as a\nresult of previous edits. Preliminary evaluation of the proposed methods\nshows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'', and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing, given the changes they have just made. Systems with\nsuch capabilities have the potential to improve coherence and\ncoordination while reducing the amount of communication required. An\nempirical evaluation of the approach on a corpus of Wikipedia articles\nshows promising initial results. Our methods make it possible to track\nparagraphs across revisions, identify significant changes, and predict\nparagraphs likely to be edited following a significant edit of a\nparticular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant changes, without requiring authors to\nspecify explicitly what changes are of interest to them. Furthermore,\nthese capabilities go beyond prior approaches for supporting change\nawareness in that they can support authors by drawing their attention to\nparts of the document that are likely to require edits as a result of\nthose changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques, which provide the foundation for these important\ncapabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they change\ntogether (or remain unchanged together) more than half the time. This\nsecond measure is a stronger indication than a paragraph undergoing just\none significant change.\n\nThe frequency of the relationship occurrence was variable. On average,\n1.6 pairs of paragraphs related by edit history were found per revision\nof the text. A pair related by topic similarity was only found once\nevery ten versions. Proximity relationships always exist in each\nversion, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than controls. For these controls, we compare with the\noriginal paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions. That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) and were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alerting authors to portions of the text that could be\nimproved. Finally, we plan to explore alternative ways of presenting the\ninformation chosen by the algorithms as important for authors to\nconsider. For example, the system might highlight changes that it deems\nrelevant or provide a list of them with links to the places they appear\nin the text.\n"
p3742
sg12
(lp3743
(iversion
Paragraph
p3744
(dp3745
g10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While many existing tools support such collaborative efforts\n(e.g., dropbox, google docs), these tools lack intelligent information\nsharing mechanisms. While capabilities such as ``track changes'' and\n``diff'' visualize changes to authors, they do not distinguish between\nminor and major edits, and do not consider the possible effects of edits\non other parts of the document. Drawing collaborators' attention to\nspecific edits and describing them remains the responsibility of\nauthors. This paper presents our initial work toward the development of\na collaborative system that supports multi-author writing. We describe\nmethods for tracking paragraphs, identifying significant edits, and\npredicting parts of the paper that are likely to require changes as a\nresult of previous edits. Preliminary evaluation of the proposed methods\nshows promising results."
p3746
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3747
(dp3748
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'', and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits."
p3749
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3750
(dp3751
g10
S"This paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing, given the changes they have just made. Systems with\nsuch capabilities have the potential to improve coherence and\ncoordination while reducing the amount of communication required. An\nempirical evaluation of the approach on a corpus of Wikipedia articles\nshows promising initial results. Our methods make it possible to track\nparagraphs across revisions, identify significant changes, and predict\nparagraphs likely to be edited following a significant edit of a\nparticular paragraph."
p3752
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3753
(dp3754
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant changes, without requiring authors to\nspecify explicitly what changes are of interest to them. Furthermore,\nthese capabilities go beyond prior approaches for supporting change\nawareness in that they can support authors by drawing their attention to\nparts of the document that are likely to require edits as a result of\nthose changes.'
p3755
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3756
(dp3757
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques, which provide the foundation for these important\ncapabilities."
p3758
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3759
(dp3760
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3761
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3762
(dp3763
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant."
p3764
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3765
(dp3766
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3767
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3768
(dp3769
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3770
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3771
(dp3772
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.'
p3773
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3774
(dp3775
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3776
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3777
(dp3778
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p3779
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3780
(dp3781
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.'
p3782
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3783
(dp3784
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p3785
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3786
(dp3787
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.'
p3788
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3789
(dp3790
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p3791
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3792
(dp3793
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they change\ntogether (or remain unchanged together) more than half the time. This\nsecond measure is a stronger indication than a paragraph undergoing just\none significant change.'
p3794
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3795
(dp3796
g10
S'The frequency of the relationship occurrence was variable. On average,\n1.6 pairs of paragraphs related by edit history were found per revision\nof the text. A pair related by topic similarity was only found once\nevery ten versions. Proximity relationships always exist in each\nversion, as most paragraphs have two neighbors.'
p3797
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3798
(dp3799
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than controls. For these controls, we compare with the\noriginal paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.'
p3800
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3801
(dp3802
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions. That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) and were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.'
p3803
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3804
(dp3805
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3806
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3807
(dp3808
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alerting authors to portions of the text that could be\nimproved. Finally, we plan to explore alternative ways of presenting the\ninformation chosen by the algorithms as important for authors to\nconsider. For example, the system might highlight changes that it deems\nrelevant or provide a list of them with links to the places they appear\nin the text.\n'
p3809
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p3810
sba(iversion
Version
p3811
(dp3812
g7
g8
(S'\x07\xdf\x01\x03\x111\x16\x0e\xcd\x10'
tRp3813
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While many existing tools support such collaborative efforts\n(e.g., dropbox, google docs), these tools lack intelligent information\nsharing mechanisms. While capabilities such as ``track changes'' and\n``diff'' visualize changes to authors, they do not distinguish between\nminor and major edits, and do not consider the possible effects of edits\non other parts of the document. Drawing collaborators' attention to\nspecific edits and describing them remains the responsibility of\nauthors. This paper presents our initial work toward the development of\na collaborative system that supports multi-author writing. We describe\nmethods for tracking paragraphs, identifying significant edits, and\npredicting parts of the paper that are likely to require changes as a\nresult of previous edits. Preliminary evaluation of the proposed methods\nshows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'', and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing, given the changes they have just made. Systems with\nsuch capabilities have the potential to improve coherence and\ncoordination while reducing the amount of communication required. An\nempirical evaluation of the approach on a corpus of Wikipedia articles\nshows promising initial results. Our methods make it possible to track\nparagraphs across revisions, identify significant changes, and predict\nparagraphs likely to be edited following a significant edit of a\nparticular paragraph.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant changes, without requiring authors to\nspecify explicitly what changes are of interest to them. Furthermore,\nthese capabilities go beyond prior approaches for supporting change\nawareness in that they can support authors by drawing their attention to\nparts of the document that are likely to require edits as a result of\nthose changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques, which provide the foundation for these important\ncapabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of a more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChange1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they change\ntogether (or remain unchanged together) more than half the time. This\nsecond measure is a stronger indication than a paragraph undergoing just\none significant change.\n\nThe frequency of the relationship occurrence was variable. On average,\n1.6 pairs of paragraphs related by edit history were found per revision\nof the text. A pair related by topic similarity was only found once\nevery ten versions. Proximity relationships always exist in each\nversion, as most paragraphs have two neighbors.\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than controls. For these controls, we compare with the\noriginal paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions. That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) and were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to portions of the text that could be improved.\nFinally, we plan to explore alternative ways of presenting the\ninformation chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n"
p3814
sg12
(lp3815
(iversion
Paragraph
p3816
(dp3817
g10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While many existing tools support such collaborative efforts\n(e.g., dropbox, google docs), these tools lack intelligent information\nsharing mechanisms. While capabilities such as ``track changes'' and\n``diff'' visualize changes to authors, they do not distinguish between\nminor and major edits, and do not consider the possible effects of edits\non other parts of the document. Drawing collaborators' attention to\nspecific edits and describing them remains the responsibility of\nauthors. This paper presents our initial work toward the development of\na collaborative system that supports multi-author writing. We describe\nmethods for tracking paragraphs, identifying significant edits, and\npredicting parts of the paper that are likely to require changes as a\nresult of previous edits. Preliminary evaluation of the proposed methods\nshows promising results."
p3818
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3819
(dp3820
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'', and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits."
p3821
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3822
(dp3823
g10
S"This paper presents our initial work toward the development of a\ncollaborative system that assists multi-author writing by drawing\nauthors' attention to edits that are important and relevant for them,\nand by pointing out other parts of the document that are likely to\nrequire editing, given the changes they have just made. Systems with\nsuch capabilities have the potential to improve coherence and\ncoordination while reducing the amount of communication required. An\nempirical evaluation of the approach on a corpus of Wikipedia articles\nshows promising initial results. Our methods make it possible to track\nparagraphs across revisions, identify significant changes, and predict\nparagraphs likely to be edited following a significant edit of a\nparticular paragraph."
p3824
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3825
(dp3826
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing of edits\nand presenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing and data mining methods to\nautomatically detect significant changes, without requiring authors to\nspecify explicitly what changes are of interest to them. Furthermore,\nthese capabilities go beyond prior approaches for supporting change\nawareness in that they can support authors by drawing their attention to\nparts of the document that are likely to require edits as a result of\nthose changes.'
p3827
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3828
(dp3829
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our lightweight use of NLP\ntechniques, which provide the foundation for these important\ncapabilities."
p3830
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3831
(dp3832
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio for the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3833
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3834
(dp3835
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant."
p3836
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3837
(dp3838
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3839
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3840
(dp3841
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3842
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3843
(dp3844
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.'
p3845
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3846
(dp3847
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3848
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3849
(dp3850
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p3851
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3852
(dp3853
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.'
p3854
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3855
(dp3856
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p3857
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3858
(dp3859
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of a more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.'
p3860
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3861
(dp3862
g10
S'\\includegraphics{figs/parTopicChange1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p3863
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3864
(dp3865
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they change\ntogether (or remain unchanged together) more than half the time. This\nsecond measure is a stronger indication than a paragraph undergoing just\none significant change.'
p3866
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3867
(dp3868
g10
S'The frequency of the relationship occurrence was variable. On average,\n1.6 pairs of paragraphs related by edit history were found per revision\nof the text. A pair related by topic similarity was only found once\nevery ten versions. Proximity relationships always exist in each\nversion, as most paragraphs have two neighbors.'
p3869
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3870
(dp3871
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. It is also significantly more\npredictive than controls. For these controls, we compare with the\noriginal paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories. For this measure, the\nrelationship of topic similarity still needs to be evaluated.'
p3872
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3873
(dp3874
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\With respect to the second measure, we correctly predicted 71\\% of pairs\nrelated by edit history and 63\\% of pairs related by topic. (Proximity\nwas not evaluated for this measure, as it did almost no better than the\nrandom control for the first, less strict, measure.) Further, we\nobtained a recall of 80\\% for these correct predictions. That is, only\n20\\% of the paragraphs that should have been labeled as related (based\non information ten versions in the future) and were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.'
p3875
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3876
(dp3877
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3878
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3879
(dp3880
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to portions of the text that could be improved.\nFinally, we plan to explore alternative ways of presenting the\ninformation chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n'
p3881
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p3882
sba(iversion
Version
p3883
(dp3884
g7
g8
(S'\x07\xdf\x01\x03\x16\x00\t\t;H'
tRp3885
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While existing tools facilitate and support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. Capabilities such as ``track changes''\nand ``diff'' visualize changes to authors, but do not distinguish\nbetween minor and major edits and do not consider the possible effects\nof edits on other parts of the document. Drawing collaborators'\nattention to specific edits and describing them remains the\nresponsibility of authors. This paper presents our initial work toward\nthe development of a collaborative system that supports multi-author\nwriting. We describe methods for tracking paragraphs, identifying\nsignificant edits, and predicting parts of the paper that are likely to\nrequire changes as a result of previous edits. Preliminary evaluation of\nthe proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'', and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attentions\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nand coordination while reducing the amount of communication required\nbetween authors. An empirical evaluation of the proposed approach on a\ncorpus of Wikipedia articles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our use of lightweight NLP\ntechniques, which provide the foundation for these important\ncapabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio with the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n"
p3886
sg12
(lp3887
(iversion
Paragraph
p3888
(dp3889
g10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While existing tools facilitate and support such collaborative\nefforts (e.g., dropbox, google docs), these tools lack intelligent\ninformation sharing mechanisms. Capabilities such as ``track changes''\nand ``diff'' visualize changes to authors, but do not distinguish\nbetween minor and major edits and do not consider the possible effects\nof edits on other parts of the document. Drawing collaborators'\nattention to specific edits and describing them remains the\nresponsibility of authors. This paper presents our initial work toward\nthe development of a collaborative system that supports multi-author\nwriting. We describe methods for tracking paragraphs, identifying\nsignificant edits, and predicting parts of the paper that are likely to\nrequire changes as a result of previous edits. Preliminary evaluation of\nthe proposed methods shows promising results."
p3890
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3891
(dp3892
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., google docs, dropbox). However,\nwhile document processors provide capabilities such as ``track\nchanges'', ``diff'', and commenting, they lack intelligent information\nsharing mechanisms. They do not attempt to reason about the importance\nof changes to different authors and do not consider how edits might\naffect other parts of the document. Therefore, there is significant\ncoordination overhead: authors need to re-read the entire document\nfrequently or rely on communication from their co-authors in order to\nkeep track of the current state of the document and ensure that their\nedits are consistent with other edits."
p3893
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3894
(dp3895
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attentions\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nand coordination while reducing the amount of communication required\nbetween authors. An empirical evaluation of the proposed approach on a\ncorpus of Wikipedia articles shows promising initial results."
p3896
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3897
(dp3898
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p3899
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3900
(dp3901
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our use of lightweight NLP\ntechniques, which provide the foundation for these important\ncapabilities."
p3902
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3903
(dp3904
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in the new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio with the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3905
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3906
(dp3907
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant."
p3908
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3909
(dp3910
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3911
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3912
(dp3913
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3914
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3915
(dp3916
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.'
p3917
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3918
(dp3919
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3920
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3921
(dp3922
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p3923
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3924
(dp3925
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.'
p3926
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3927
(dp3928
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p3929
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3930
(dp3931
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.'
p3932
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3933
(dp3934
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p3935
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3936
(dp3937
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.'
p3938
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3939
(dp3940
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p3941
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3942
(dp3943
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.'
p3944
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3945
(dp3946
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p3947
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3948
(dp3949
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p3950
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3951
(dp3952
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n'
p3953
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p3954
sba(iversion
Version
p3955
(dp3956
g7
g8
(S'\x07\xdf\x01\x04\x0b\x037\x07\x14\x80'
tRp3957
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While existing tools facilitate and support such collaborative\nefforts (e.g., Dropbox, Google Docs), these tools lack intelligent\ninformation sharing mechanisms. Capabilities such as ``track changes''\nand ``diff'' visualize changes to authors, but do not distinguish\nbetween minor and major edits and do not consider the possible effects\nof edits on other parts of the document. Drawing collaborators'\nattention to specific edits and describing them remains the\nresponsibility of authors. This paper presents our initial work toward\nthe development of a collaborative system that supports multi-author\nwriting. We describe methods for tracking paragraphs, identifying\nsignificant edits, and predicting parts of the paper that are likely to\nrequire changes as a result of previous edits. Preliminary evaluation of\nthe proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our use of lightweight NLP\ntechniques, which provide the foundation for these important\ncapabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio with the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n"
p3958
sg12
(lp3959
(iversion
Paragraph
p3960
(dp3961
g10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While existing tools facilitate and support such collaborative\nefforts (e.g., Dropbox, Google Docs), these tools lack intelligent\ninformation sharing mechanisms. Capabilities such as ``track changes''\nand ``diff'' visualize changes to authors, but do not distinguish\nbetween minor and major edits and do not consider the possible effects\nof edits on other parts of the document. Drawing collaborators'\nattention to specific edits and describing them remains the\nresponsibility of authors. This paper presents our initial work toward\nthe development of a collaborative system that supports multi-author\nwriting. We describe methods for tracking paragraphs, identifying\nsignificant edits, and predicting parts of the paper that are likely to\nrequire changes as a result of previous edits. Preliminary evaluation of\nthe proposed methods shows promising results."
p3962
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3963
(dp3964
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p3965
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3966
(dp3967
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results."
p3968
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3969
(dp3970
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p3971
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3972
(dp3973
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our use of lightweight NLP\ntechniques, which provide the foundation for these important\ncapabilities."
p3974
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3975
(dp3976
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio with the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p3977
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3978
(dp3979
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize for typographical errors. This approach\nuses the cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant."
p3980
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3981
(dp3982
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p3983
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3984
(dp3985
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p3986
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3987
(dp3988
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.'
p3989
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3990
(dp3991
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p3992
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3993
(dp3994
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of the articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p3995
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3996
(dp3997
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.'
p3998
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p3999
(dp4000
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p4001
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4002
(dp4003
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.'
p4004
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4005
(dp4006
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4007
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4008
(dp4009
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.'
p4010
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4011
(dp4012
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4013
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4014
(dp4015
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.'
p4016
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4017
(dp4018
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4019
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4020
(dp4021
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p4022
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4023
(dp4024
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n'
p4025
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4026
sba(iversion
Version
p4027
(dp4028
g7
g8
(S'\x07\xdf\x01\x04\x0e\r\x12\x050 '
tRp4029
sg10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While existing tools facilitate and support such collaborative\nefforts (e.g., Dropbox, Google Docs), these tools lack intelligent\ninformation sharing mechanisms. Capabilities such as ``track changes''\nand ``diff'' visualize changes to authors, but do not distinguish\nbetween minor and major edits and do not consider the possible effects\nof edits on other parts of the document. Drawing collaborators'\nattention to specific edits and describing them remains the\nresponsibility of authors. This paper presents our initial work toward\nthe development of a collaborative system that supports multi-author\nwriting. We describe methods for tracking paragraphs, identifying\nsignificant edits, and predicting parts of the paper that are likely to\nrequire changes as a result of previous edits. Preliminary evaluation of\nthe proposed methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our use of lightweight NLP\ntechniques, which provide the foundation for these important\ncapabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio with the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize typographical errors. This approach uses\nthe cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n"
p4030
sg12
(lp4031
(iversion
Paragraph
p4032
(dp4033
g10
S"Many documents (e.g., academic papers) are typically written by multiple\nauthors. While existing tools facilitate and support such collaborative\nefforts (e.g., Dropbox, Google Docs), these tools lack intelligent\ninformation sharing mechanisms. Capabilities such as ``track changes''\nand ``diff'' visualize changes to authors, but do not distinguish\nbetween minor and major edits and do not consider the possible effects\nof edits on other parts of the document. Drawing collaborators'\nattention to specific edits and describing them remains the\nresponsibility of authors. This paper presents our initial work toward\nthe development of a collaborative system that supports multi-author\nwriting. We describe methods for tracking paragraphs, identifying\nsignificant edits, and predicting parts of the paper that are likely to\nrequire changes as a result of previous edits. Preliminary evaluation of\nthe proposed methods shows promising results."
p4034
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4035
(dp4036
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p4037
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4038
(dp4039
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results."
p4040
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4041
(dp4042
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative writing (e.g.,\n~\\cite{neuwirth2001computer,kittur2007he}), as well as the social\naspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about changes made to a\ndocument. These include flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p4043
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4044
(dp4045
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the article. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help promote only the\nmost important changes and decide whether to alert collaborating authors\nof a change. Capability (3) is required in order to draw authors'\nattention to other parts of the document that might require changes as a\nresult of a recent edit. We describe our use of lightweight NLP\ntechniques, which provide the foundation for these important\ncapabilities."
p4046
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4047
(dp4048
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio between two paragraphs close to 1 indicates high\nsimilarity, while a ratio close to 0 indicates the opposite. For each\nrevision of a document, the algorithm computes the Levenshtein ratio\nbetween each paragraph in the old version and each paragraph in the new\nversion. Two paragraphs are mapped across the revision if they each have\nthe highest Levenshtein ratio with the other. If a paragraph in the new\nversion has no matching paragraphs in the old version (none of its\nratios were above a threshold of 0.4), we label the paragraph as an\naddition. If a paragraph in the old version is not matched with any\nparagraphs in the next version, then we consider it a deletion.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p4049
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4050
(dp4051
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach, specifically, Latent Semantic\nIndexing~\\cite{deerwester1990indexing} (LSI), which accounts for\nsynonyms and does not penalize typographical errors. This approach uses\nthe cosine similarity between word vectors that represent the\nparagraphs; if the cosine similarity between the new and old versions of\na paragraph is below an empirically determined threshold of 0.8, we\nconsider the edit significant."
p4052
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4053
(dp4054
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p4055
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4056
(dp4057
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we developed methods for predicting which paragraphs are\nlikely to change in future revisions as a result of significant edits in\na particular paragraph of the document.'
p4058
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4059
(dp4060
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, or neighboring paragraphs; (2) \\emph{edit histories},\ni.e., paragraphs that tended to be edited together in previous\nrevisions, and (3) \\emph{topic similarity}, i.e., paragraphs with high\ntopic cosine similarity. For (2), we labeled pairs as related if they\nchanged or remained unchanged together over half the time in the\nprevious ten revisions. For (3), we labeled pairs as related if their\ncosine similarity was above an empirically determined threshold of 0.4.'
p4061
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4062
(dp4063
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p4064
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4065
(dp4066
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p4067
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4068
(dp4069
g10
S'\\subsection{Findings}\\label{findings}This section describes the findings from our empirical evaluation. We\nfocused mostly on the prediction of future edits, but we also conducted\na manual evaluation of paragraph mapping and significant change\ndetection, which form the basis for edit prediction.'
p4070
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4071
(dp4072
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p4073
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4074
(dp4075
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 such edits to\nensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it contributes content and alters the tone of the\ntext.'
p4076
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4077
(dp4078
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4079
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4080
(dp4081
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that indicate that a paragraph may need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.'
p4082
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4083
(dp4084
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4085
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4086
(dp4087
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.'
p4088
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4089
(dp4090
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4091
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4092
(dp4093
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Ratio of correctly-predicted future linking by\nrelationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{Ratio} & &\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 63\\% & &\\tabularnewline\nEdit Similarity & 71\\% & &\\tabularnewline\n\\bottomrule\n\\end{longtable}\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p4094
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4095
(dp4096
g10
S'In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. For\nexample, the system might highlight changes that it deems relevant or\nprovide a list of them with links to the places they appear in the text.\n'
p4097
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4098
sba(iversion
Version
p4099
(dp4100
g7
g8
(S'\x07\xde\x0c\x0e\x10;\x05\n\xb2H'
tRp4101
sg10
S". See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.\n\n\\section{Introduction}\\label{introduction}\n\nMaybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikis\n\nnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision Activity\n\nWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nThe system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.\n\nINSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.\n\nThis method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches.\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in figure\n{[}X{]}.\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p4102
sg12
(lp4103
(iversion
Paragraph
p4104
(dp4105
g10
S'. See: \\url{http://www.acm.org/about/class/1998/} for help using the ACM\nClassification system.'
p4106
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4107
(dp4108
g10
S'\\section{Introduction}\\label{introduction}Maybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikisnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision ActivityWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.'
p4109
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4110
(dp4111
g10
S'The system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.'
p4112
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4113
(dp4114
g10
S"INSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit."
p4115
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4116
(dp4117
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes{[}1{]} were\neliminated as well. This resulted in a total of 17,199 versions across\nthe 41 articles, with an average length of 25.71 paragraphs. Wikipedia\ndata affords results applicable to other collaborative writing spaces,\nbecause although the average article has over 400 contributing authors,\nmost of these authors make a one-time change. In fact, on average, 15\nauthors make 80\\% of the edits to an article. This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p4118
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4119
(dp4120
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined in equation 1.'
p4121
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4122
(dp4123
g10
S'This method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.'
p4124
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4125
(dp4126
g10
S"A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision. The\nimage below demonstrates this algorithm: paragraphs 9, 10 and 12 of the\nold version were deleted, while the others found clear matches."
p4127
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4128
(dp4129
g10
S"\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p4130
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4131
(dp4132
g10
S"As shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance."
p4133
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4134
(dp4135
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p4136
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4137
(dp4138
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p4139
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4140
(dp4141
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p4142
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4143
(dp4144
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p4145
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4146
(dp4147
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p4148
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4149
(dp4150
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p4151
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4152
(dp4153
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in figure\n{[}X{]}.'
p4154
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4155
(dp4156
g10
S'We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p4157
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4158
(dp4159
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p4160
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4161
(dp4162
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in figure {[}X{]}, when a paragraph is\nedited for the first time in a while, further adjustments are triggered\nin the near future.'
p4163
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4164
(dp4165
g10
S'Caption: After a significant change at version 0, consequent edits are\nmore frequent.'
p4166
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4167
(dp4168
g10
S'We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p4169
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4170
(dp4171
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in table {[}X{]}. They are also significantly more predictive than\nrandom sample controls. For controls, we compare with the original\nparagraph as well as a random sample of any ten consecutive versions\nwithin Wikipedia article histories.'
p4172
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4173
(dp4174
g10
S'Relationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p4175
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4176
(dp4177
g10
S'Relationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p4178
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4179
(dp4180
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p4181
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4182
(dp4183
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p4184
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4185
(dp4186
g10
S'We imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.'
p4187
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4188
(dp4189
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n'
p4190
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4191
sba(iversion
Version
p4192
(dp4193
g7
g8
(S'\x07\xdf\x01\x04\x11\x15#\x0b\xa8`'
tRp4194
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we investigated which paragraphs are likely to change in\nfuture revisions as a result of edits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimiarlity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 such edits to\nensure that paragraphs were correctly mapped and determine that the\nmethod successfully classified edits (as significant or insignificant).\nto ensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it adds new content and alters the tone of the text.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n"
p4195
sg12
(lp4196
(iversion
Paragraph
p4197
(dp4198
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results."
p4199
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4200
(dp4201
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p4202
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4203
(dp4204
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results."
p4205
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4206
(dp4207
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p4208
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4209
(dp4210
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p4211
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4212
(dp4213
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.'
p4214
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4215
(dp4216
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p4217
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4218
(dp4219
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p4220
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4221
(dp4222
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we investigated which paragraphs are likely to change in\nfuture revisions as a result of edits to other paragraphs.'
p4223
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4224
(dp4225
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimiarlity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p4226
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4227
(dp4228
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p4229
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4230
(dp4231
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p4232
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4233
(dp4234
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p4235
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4236
(dp4237
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 such edits to\nensure that paragraphs were correctly mapped and determine that the\nmethod successfully classified edits (as significant or insignificant).\nto ensure that 1) paragraphs were correctly mapped and 2) this method\nsuccessfully classifies edits as significant or insignificant. We\nprovide an example of a significant edit in Figure~{[}fig:pars{]}. While\nthese are clearly two versions of the same paragraph, the edit is\nsignificant because it adds new content and alters the tone of the text.'
p4238
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4239
(dp4240
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4241
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4242
(dp4243
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.'
p4244
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4245
(dp4246
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4247
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4248
(dp4249
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.'
p4250
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4251
(dp4252
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4253
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4254
(dp4255
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p4256
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4257
(dp4258
g10
S"In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n"
p4259
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4260
sba(iversion
Version
p4261
(dp4262
g7
g8
(S'\x07\xdf\x02\x03\x11\x0f\x1f\ri\x98'
tRp4263
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we investigated which paragraphs are likely to change in\nfuture revisions as a result of edits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimiarlity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 such edits to\nensure that paragraphs were correctly mapped and whether the method\nsuccessfully classified edits as significant or insignificant. Overall,\nwe found that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further. Figure~{[}fig:pars{]} shows an\nexample of a significant edit: while the bottom paragraph is clearly a\nrevision of the same paragraph (recurring text shown in bold), the edit\nis significant because it adds new content and alters the tone of the\ntext.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n"
p4264
sg12
(lp4265
(iversion
Paragraph
p4266
(dp4267
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results."
p4268
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4269
(dp4270
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p4271
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4272
(dp4273
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results."
p4274
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4275
(dp4276
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p4277
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4278
(dp4279
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p4280
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4281
(dp4282
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.'
p4283
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4284
(dp4285
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p4286
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4287
(dp4288
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p4289
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4290
(dp4291
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we investigated which paragraphs are likely to change in\nfuture revisions as a result of edits to other paragraphs.'
p4292
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4293
(dp4294
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimiarlity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p4295
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4296
(dp4297
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p4298
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4299
(dp4300
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p4301
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4302
(dp4303
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p4304
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4305
(dp4306
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 such edits to\nensure that paragraphs were correctly mapped and whether the method\nsuccessfully classified edits as significant or insignificant. Overall,\nwe found that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further. Figure~{[}fig:pars{]} shows an\nexample of a significant edit: while the bottom paragraph is clearly a\nrevision of the same paragraph (recurring text shown in bold), the edit\nis significant because it adds new content and alters the tone of the\ntext.'
p4307
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4308
(dp4309
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4310
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4311
(dp4312
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.'
p4313
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4314
(dp4315
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4316
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4317
(dp4318
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.'
p4319
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4320
(dp4321
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4322
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4323
(dp4324
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.'
p4325
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4326
(dp4327
g10
S"In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n"
p4328
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4329
sba(iversion
Version
p4330
(dp4331
g7
g8
(S'\x07\xdf\x02\x03\x13#\x03\x08\x978'
tRp4332
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we investigated which paragraphs are likely to change in\nfuture revisions as a result of edits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimilarity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Edit Correlations and Prediction of Future\nEdits}\\label{edit-correlations-and-prediction-of-future-edits}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n"
p4333
sg12
(lp4334
(iversion
Paragraph
p4335
(dp4336
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results."
p4337
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4338
(dp4339
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p4340
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4341
(dp4342
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results."
p4343
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4344
(dp4345
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p4346
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4347
(dp4348
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p4349
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4350
(dp4351
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.'
p4352
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4353
(dp4354
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p4355
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4356
(dp4357
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p4358
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4359
(dp4360
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, we investigated which paragraphs are likely to change in\nfuture revisions as a result of edits to other paragraphs.'
p4361
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4362
(dp4363
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimilarity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p4364
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4365
(dp4366
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p4367
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4368
(dp4369
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p4370
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4371
(dp4372
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p4373
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4374
(dp4375
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.'
p4376
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4377
(dp4378
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Edit Correlations and Prediction of Future\nEdits}\\label{edit-correlations-and-prediction-of-future-edits}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4379
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4380
(dp4381
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.'
p4382
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4383
(dp4384
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4385
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4386
(dp4387
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.'
p4388
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4389
(dp4390
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4391
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4392
(dp4393
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.'
p4394
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4395
(dp4396
g10
S"In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n"
p4397
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4398
sba(iversion
Version
p4399
(dp4400
g7
g8
(S'\x07\xdf\x02\x03\x17,(\x02\x8cX'
tRp4401
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs. Therefore, we investigated\nwhich paragraphs are likely to change in future revisions as a result of\nedits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimilarity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Edit Correlations and Prediction of Future\nEdits}\\label{edit-correlations-and-prediction-of-future-edits}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4402
sg12
(lp4403
(iversion
Paragraph
p4404
(dp4405
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results."
p4406
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4407
(dp4408
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p4409
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4410
(dp4411
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results."
p4412
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4413
(dp4414
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p4415
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4416
(dp4417
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p4418
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4419
(dp4420
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.'
p4421
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4422
(dp4423
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p4424
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4425
(dp4426
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p4427
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4428
(dp4429
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs. Therefore, we investigated\nwhich paragraphs are likely to change in future revisions as a result of\nedits to other paragraphs.'
p4430
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4431
(dp4432
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimilarity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p4433
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4434
(dp4435
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p4436
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4437
(dp4438
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p4439
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4440
(dp4441
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p4442
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4443
(dp4444
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.'
p4445
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4446
(dp4447
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Edit Correlations and Prediction of Future\nEdits}\\label{edit-correlations-and-prediction-of-future-edits}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4448
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4449
(dp4450
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the\ntime. This second measure is a stronger indication of a possible\ninterdependency between the paragraphs than the first measure.'
p4451
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4452
(dp4453
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4454
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4455
(dp4456
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.'
p4457
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4458
(dp4459
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4460
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4461
(dp4462
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.'
p4463
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4464
(dp4465
g10
S"In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'')."
p4466
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4467
(dp4468
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p4469
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4470
sba(iversion
Version
p4471
(dp4472
g7
g8
(S'\x07\xdf\x02\x04\x01#)\x0eW\xe0'
tRp4473
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs. Therefore, we investigated\nwhich paragraphs are likely to change in future revisions as a result of\nedits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimilarity does not really capture a similarity in content.) For each of\nthe three inter-paragraph relationships, we use the edit history prior\nto revision \\(t\\) to predict which paragraphs will be likely to change\nin consequent revisions.\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. That is, we\nuse information from the revisions up to revision \\(t\\) to predict\nwhether a paragraph will change significantly in revisions \\(t+1\\) to\n\\(t+10\\). The second measure tests whether the two paragraphs are\nrelated by edit patterns ten versions after the significant change, that\nis, whether they keep changing together (or remain unchanged together)\nmore than half the time in revisions \\(t+1\\) to \\(t+10\\). This second\nmeasure is a stronger indication of a possible interdependency between\nthe paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4474
sg12
(lp4475
(iversion
Paragraph
p4476
(dp4477
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results."
p4478
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4479
(dp4480
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p4481
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4482
(dp4483
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results."
p4484
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4485
(dp4486
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p4487
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4488
(dp4489
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p4490
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4491
(dp4492
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.'
p4493
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4494
(dp4495
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p4496
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4497
(dp4498
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p4499
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4500
(dp4501
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs. Therefore, we investigated\nwhich paragraphs are likely to change in future revisions as a result of\nedits to other paragraphs.'
p4502
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4503
(dp4504
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity was above an empirically determined threshold of 0.4. (There\nare rarely paragraphs with a higher similarity than 0.4, while a lower\nsimilarity does not really capture a similarity in content.) For each of\nthe three inter-paragraph relationships, we use the edit history prior\nto revision \\(t\\) to predict which paragraphs will be likely to change\nin consequent revisions.'
p4505
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4506
(dp4507
g10
S'\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p4508
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4509
(dp4510
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p4511
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4512
(dp4513
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p4514
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4515
(dp4516
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p4517
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4518
(dp4519
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.'
p4520
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4521
(dp4522
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4523
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4524
(dp4525
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. That is, we\nuse information from the revisions up to revision \\(t\\) to predict\nwhether a paragraph will change significantly in revisions \\(t+1\\) to\n\\(t+10\\). The second measure tests whether the two paragraphs are\nrelated by edit patterns ten versions after the significant change, that\nis, whether they keep changing together (or remain unchanged together)\nmore than half the time in revisions \\(t+1\\) to \\(t+10\\). This second\nmeasure is a stronger indication of a possible interdependency between\nthe paragraphs than the first measure.'
p4526
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4527
(dp4528
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4529
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4530
(dp4531
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.'
p4532
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4533
(dp4534
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4535
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4536
(dp4537
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.'
p4538
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4539
(dp4540
g10
S"In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'')."
p4541
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4542
(dp4543
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p4544
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4545
sba(iversion
Version
p4546
(dp4547
g7
g8
(S'\x07\xdf\x02\x04\x111\x11\t\xbc0'
tRp4548
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs. Therefore, we investigated\nwhich paragraphs are likely to change in future revisions as a result of\nedits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity in the was above an empirically determined threshold of 0.4.\n(There are rarely paragraphs with a higher similarity than 0.4, while a\nlower similarity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. That is, we\nuse information from the revisions up to revision \\(t\\) to predict\nwhether a paragraph will change significantly in revisions \\(t+1\\) to\n\\(t+10\\). The second measure tests whether the two paragraphs are\nrelated by edit patterns ten versions after the significant change, that\nis, whether they keep changing together (or remain unchanged together)\nmore than half the time in revisions \\(t+1\\) to \\(t+10\\). This second\nmeasure is a stronger indication of a possible interdependency between\nthe paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4549
sg12
(lp4550
(iversion
Paragraph
p4551
(dp4552
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results."
p4553
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4554
(dp4555
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p4556
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4557
(dp4558
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results."
p4559
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4560
(dp4561
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p4562
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4563
(dp4564
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p4565
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4566
(dp4567
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.'
p4568
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4569
(dp4570
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p4571
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4572
(dp4573
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p4574
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4575
(dp4576
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs. Therefore, we investigated\nwhich paragraphs are likely to change in future revisions as a result of\nedits to other paragraphs.'
p4577
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4578
(dp4579
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity in the was above an empirically determined threshold of 0.4.\n(There are rarely paragraphs with a higher similarity than 0.4, while a\nlower similarity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p4580
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4581
(dp4582
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p4583
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4584
(dp4585
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p4586
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4587
(dp4588
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p4589
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4590
(dp4591
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.'
p4592
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4593
(dp4594
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4595
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4596
(dp4597
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. That is, we\nuse information from the revisions up to revision \\(t\\) to predict\nwhether a paragraph will change significantly in revisions \\(t+1\\) to\n\\(t+10\\). The second measure tests whether the two paragraphs are\nrelated by edit patterns ten versions after the significant change, that\nis, whether they keep changing together (or remain unchanged together)\nmore than half the time in revisions \\(t+1\\) to \\(t+10\\). This second\nmeasure is a stronger indication of a possible interdependency between\nthe paragraphs than the first measure.'
p4598
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4599
(dp4600
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4601
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4602
(dp4603
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.'
p4604
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4605
(dp4606
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4607
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4608
(dp4609
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.'
p4610
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4611
(dp4612
g10
S"In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'')."
p4613
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4614
(dp4615
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p4616
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4617
sba(iversion
Version
p4618
(dp4619
g7
g8
(S'\x07\xdf\x02\x04\x13\t\x1d\tbX'
tRp4620
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs. Therefore, we investigated\nwhich paragraphs are likely to change in future revisions as a result of\nedits to other paragraphs.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity in the was above an empirically determined threshold of 0.4.\n(There are rarely paragraphs with a higher similarity than 0.4, while a\nlower similarity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. That is, we\nuse information from the revisions up to revision \\(t\\) to predict\nwhether a paragraph will change significantly in revisions \\(t+1\\) to\n\\(t+10\\). The second measure tests whether the two paragraphs are\nrelated by edit patterns ten versions after the significant change, that\nis, whether they keep changing together (or remain unchanged together)\nmore than half the time in revisions \\(t+1\\) to \\(t+10\\). This second\nmeasure is a stronger indication of a possible interdependency between\nthe paragraphs than the first measure.\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.\n\n{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandomly sampled paragraph \\& 15\\%\\\\\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.\n\nIn future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4621
sg12
(lp4622
(iversion
Paragraph
p4623
(dp4624
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results."
p4625
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4626
(dp4627
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p4628
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4629
(dp4630
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results."
p4631
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4632
(dp4633
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p4634
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4635
(dp4636
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p4637
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4638
(dp4639
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. To track paragraphs throughout document revisions, we developed\na mapping algorithm that determines which paragraph in a new version\ncorresponds to each of the paragraphs in the previous version (prior to\nediting). The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio measure, which is\ndefined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to 1 indicates high similarity, while a ratio\nclose to 0 indicates the opposite. For each revision of a document, the\nalgorithm computes the Levenshtein ratio between each paragraph in the\nold version and each paragraph in the new version. Two paragraphs are\nmapped across the revision if they each have the highest Levenshtein\nratio with the other. If a paragraph in the new version has no matching\nparagraphs in the old version (i.e., none of its ratios were above a\nthreshold of 0.4), we label the paragraph as an addition. If a paragraph\nin the old version is not matched with any paragraphs in the next\nversion, then we consider it a deletion. Figure~{[}fig:mapping{]}\nillustrates this algorithm: some paragraphs found clear matches (e.g.,\n0, 1, 2), while paragraph 11 from the old version was deleted and 6, 9,\n10, and 12 were added in the new version.'
p4640
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4641
(dp4642
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p4643
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4644
(dp4645
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the Levenshtein ratio approach used for mapping paragraphs, topic\nmodeling considers the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple of key words will slightly lower the Levenshtein\nratio, but could drastically affect the content."
p4646
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4647
(dp4648
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs. Therefore, we investigated\nwhich paragraphs are likely to change in future revisions as a result of\nedits to other paragraphs.'
p4649
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4650
(dp4651
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity in the was above an empirically determined threshold of 0.4.\n(There are rarely paragraphs with a higher similarity than 0.4, while a\nlower similarity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p4652
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4653
(dp4654
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p4655
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4656
(dp4657
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p4658
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4659
(dp4660
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p4661
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4662
(dp4663
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)). Similarly, we found the classification of significant edits to\nbe correct in most cases, however this is a more subjective measure\nwhich we plan to evaluate further in future work.'
p4664
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4665
(dp4666
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4667
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4668
(dp4669
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. That is, we\nuse information from the revisions up to revision \\(t\\) to predict\nwhether a paragraph will change significantly in revisions \\(t+1\\) to\n\\(t+10\\). The second measure tests whether the two paragraphs are\nrelated by edit patterns ten versions after the significant change, that\nis, whether they keep changing together (or remain unchanged together)\nmore than half the time in revisions \\(t+1\\) to \\(t+10\\). This second\nmeasure is a stronger indication of a possible interdependency between\nthe paragraphs than the first measure.'
p4670
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4671
(dp4672
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4673
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4674
(dp4675
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We also computed this measure\nfor the original paragraph as well as randomly sampled paragraphs and\nfound a significantly lower likelihood than for paragraphs related by\nedit similarity. For this measure, the relationship of topic similarity\nstill needs to be evaluated.'
p4676
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4677
(dp4678
g10
S'{\\textbar{}p{5cm}\\textbar{}p{2.5cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage}\\\\Edit History \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Randomly sampled paragraph \\& 15\\%\\\\With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4679
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4680
(dp4681
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\nWhile the motivation for our work is supporting collaborating authors,\nthe methods could also provide better support a single author.'
p4682
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4683
(dp4684
g10
S"In future work, we plan to incorporate information about author identity\nto design personalized alerts for authors depending on the edits they\nhave made. For example, the paragraph tracking algorithm makes it\npossible to create a list of authors who have contributed to a specific\nparagraph, which can be used to determine who to alert when significant\nedits that affect it occur. We also plan to develop additional\nalgorithms for summarizing changes and investigate the use of algorithms\nthat measure text coherence (e.g.,Textiling \\cite{hearst1994multi}) in\norder to alert authors to parts of the text that could be improved.\nFinally, we plan to explore alternative interface designs for presenting\nthe information chosen by the algorithms for authors to consider. We\nalso plan to incorporate explanations for system recommendations (e.g.,\n``we recommend reading the introduction because it is often edited\nfollowing edits to the results section'')."
p4685
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4686
(dp4687
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p4688
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4689
sba(iversion
Version
p4690
(dp4691
g7
g8
(S'\x07\xdf\x02\x05\x02\x01(\x07\xdb\xb8'
tRp4692
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios were above a threshold of 0.4), we label the\nparagraph as an addition. If a paragraph in the old version is not\nmatched with any paragraphs in the new version, we consider it as\ndeleted. Figure~{[}fig:mapping{]} illustrates this algorithm: some\nparagraphs found clear matches (e.g., 0, 1, 2), while paragraph 11 from\nthe old version was deleted and 6, 9, 10, and 12 were added in the new\nversion.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backwards mapping of allows for more\nrobust detection of paragraph movement even when there are significant\nchanges to the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity in the was above an empirically determined threshold of 0.4.\n(There are rarely paragraphs with a higher similarity than 0.4, while a\nlower similarity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, however this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time point to predict changes in revisions \\(d_{t+1}\\) to\n\\(d_{t+10}\\).\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed this measure for the\noriginal paragraph as well as randomly sampled paragraphs and found a\nsignificantly lower likelihood than for paragraphs related by edit\nsimilarity.\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider, and ways to\nincorporate explanations for system recommendations (e.g., ``we\nrecommend reading the introduction because it is often edited following\nedits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4693
sg12
(lp4694
(iversion
Paragraph
p4695
(dp4696
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results."
p4697
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4698
(dp4699
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p4700
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4701
(dp4702
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results."
p4703
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4704
(dp4705
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p4706
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4707
(dp4708
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p4709
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4710
(dp4711
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios were above a threshold of 0.4), we label the\nparagraph as an addition. If a paragraph in the old version is not\nmatched with any paragraphs in the new version, we consider it as\ndeleted. Figure~{[}fig:mapping{]} illustrates this algorithm: some\nparagraphs found clear matches (e.g., 0, 1, 2), while paragraph 11 from\nthe old version was deleted and 6, 9, 10, and 12 were added in the new\nversion.'
p4712
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4713
(dp4714
g10
S'While Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backwards mapping of allows for more\nrobust detection of paragraph movement even when there are significant\nchanges to the content.'
p4715
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4716
(dp4717
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p4718
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4719
(dp4720
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent."
p4721
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4722
(dp4723
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.'
p4724
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4725
(dp4726
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity in the was above an empirically determined threshold of 0.4.\n(There are rarely paragraphs with a higher similarity than 0.4, while a\nlower similarity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p4727
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4728
(dp4729
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p4730
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4731
(dp4732
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p4733
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4734
(dp4735
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p4736
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4737
(dp4738
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, however this is a more\nsubjective measure which we plan to evaluate further in future work.'
p4739
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4740
(dp4741
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4742
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4743
(dp4744
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time point to predict changes in revisions \\(d_{t+1}\\) to\n\\(d_{t+10}\\).'
p4745
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4746
(dp4747
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4748
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4749
(dp4750
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed this measure for the\noriginal paragraph as well as randomly sampled paragraphs and found a\nsignificantly lower likelihood than for paragraphs related by edit\nsimilarity.'
p4751
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4752
(dp4753
g10
S'With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4754
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4755
(dp4756
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p4757
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4758
(dp4759
g10
S"In future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider, and ways to\nincorporate explanations for system recommendations (e.g., ``we\nrecommend reading the introduction because it is often edited following\nedits to the results section'')."
p4760
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4761
(dp4762
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p4763
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4764
sba(iversion
Version
p4765
(dp4766
g7
g8
(S'\x07\xdf\x02\x08\x02(\x1e\x01\x8a\x88'
tRp4767
sg10
S"af\n\nMany documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios were above a threshold of 0.4), we label the\nparagraph as an addition. If a paragraph in the old version is not\nmatched with any paragraphs in the new version, we consider it as\ndeleted. Figure~{[}fig:mapping{]} illustrates this algorithm: some\nparagraphs found clear matches (e.g., 0, 1, 2), while paragraph 11 from\nthe old version was deleted and 6, 9, 10, and 12 were added in the new\nversion.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backwards mapping of allows for more\nrobust detection of paragraph movement even when there are significant\nchanges to the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity in the was above an empirically determined threshold of 0.4.\n(There are rarely paragraphs with a higher similarity than 0.4, while a\nlower similarity does not really capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, however this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time point to predict changes in revisions \\(d_{t+1}\\) to\n\\(d_{t+10}\\).\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed this measure for the\noriginal paragraph as well as randomly sampled paragraphs and found a\nsignificantly lower likelihood than for paragraphs related by edit\nsimilarity.\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider, and ways to\nincorporate explanations for system recommendations (e.g., ``we\nrecommend reading the introduction because it is often edited following\nedits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4768
sg12
(lp4769
(iversion
Paragraph
p4770
(dp4771
g10
S"afMany documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of the these methods shows promising results."
p4772
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4773
(dp4774
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p4775
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4776
(dp4777
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of drawing authors' attention\nto edits that are important and relevant for them, and of pointing out\nother parts of the document that are likely to require further editing.\nSystems with such capabilities have the potential to improve coherence\nof documents and coordination among authors while reducing the amount of\ncommunication required between authors. An empirical evaluation of the\nproposed approach on a corpus of Wikipedia articles shows promising\ninitial results."
p4778
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4779
(dp4780
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p4781
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4782
(dp4783
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p4784
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4785
(dp4786
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios were above a threshold of 0.4), we label the\nparagraph as an addition. If a paragraph in the old version is not\nmatched with any paragraphs in the new version, we consider it as\ndeleted. Figure~{[}fig:mapping{]} illustrates this algorithm: some\nparagraphs found clear matches (e.g., 0, 1, 2), while paragraph 11 from\nthe old version was deleted and 6, 9, 10, and 12 were added in the new\nversion.'
p4787
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4788
(dp4789
g10
S'While Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backwards mapping of allows for more\nrobust detection of paragraph movement even when there are significant\nchanges to the content.'
p4790
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4791
(dp4792
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p4793
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4794
(dp4795
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent."
p4796
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4797
(dp4798
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.'
p4799
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4800
(dp4801
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed getting a\nmeaningful signal of correlation between edits, while not looking too\nfar in the past when the content might have been significantly\ndifferent. For (3), we labeled pairs as related if their cosine\nsimilarity in the was above an empirically determined threshold of 0.4.\n(There are rarely paragraphs with a higher similarity than 0.4, while a\nlower similarity does not really capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p4802
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4803
(dp4804
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p4805
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4806
(dp4807
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p4808
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4809
(dp4810
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8 we labeled about 15\\% of the edits as\nsignificant.'
p4811
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4812
(dp4813
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 random edited\nmapped paragraphs to ensure that paragraphs were correctly mapped and\nwhether the method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, however this is a more\nsubjective measure which we plan to evaluate further in future work.'
p4814
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4815
(dp4816
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4817
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4818
(dp4819
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time point to predict changes in revisions \\(d_{t+1}\\) to\n\\(d_{t+10}\\).'
p4820
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4821
(dp4822
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4823
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4824
(dp4825
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed this measure for the\noriginal paragraph as well as randomly sampled paragraphs and found a\nsignificantly lower likelihood than for paragraphs related by edit\nsimilarity.'
p4826
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4827
(dp4828
g10
S'With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4829
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4830
(dp4831
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p4832
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4833
(dp4834
g10
S"In future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider, and ways to\nincorporate explanations for system recommendations (e.g., ``we\nrecommend reading the introduction because it is often edited following\nedits to the results section'')."
p4835
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4836
(dp4837
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p4838
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4839
sba(iversion
Version
p4840
(dp4841
g7
g8
(S'\x07\xdf\x02\x08\x03"(\r\xa8\x18'
tRp4842
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios were above a threshold of 0.4), we label the\nparagraph as an addition. If a paragraph in the old version is not\nmatched with any paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8, we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and whether the method\nsuccessfully classified edits as significant or insignificant.\nFigure~{[}fig:pars{]} shows an example of a significant edit: while the\nbottom paragraph is clearly a revision of the same paragraph (recurring\ntext shown in bold), the edit is significant because it adds new content\nand alters the tone of the text. Overall, we found that paragraphs were\nrarely mapped incorrectly (less than \\(5\\%\\)), even when their content\n(as measured by topic similarity) changed significantly. Similarly, we\nfound the classification of significant edits to be correct in most\ncases, though this is a more subjective measure which we plan to\nevaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time to predict changes in revisions \\(d_{t+1}\\) to\n\\(d_{t+10}\\).\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed this measure for the\noriginal paragraph as well as randomly sampled paragraphs and found a\nsignificantly lower likelihood than for paragraphs related by edit\nsimilarity.\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider, and ways to\nincorporate explanations for system recommendations (e.g., ``we\nrecommend reading the introduction because it is often edited following\nedits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p4843
sg12
(lp4844
(iversion
Paragraph
p4845
(dp4846
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results."
p4847
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4848
(dp4849
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p4850
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4851
(dp4852
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results."
p4853
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4854
(dp4855
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and help co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p4856
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4857
(dp4858
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p4859
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4860
(dp4861
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios were above a threshold of 0.4), we label the\nparagraph as an addition. If a paragraph in the old version is not\nmatched with any paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p4862
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4863
(dp4864
g10
S'While Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.'
p4865
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4866
(dp4867
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a significant change to be a noticeable change in the\nparagraph's topic and content. To detect such changes, we use a topic\nmodeling approach which computes the cosine similarity between word\nvectors that represent the two versions of a paragraph. Specifically, we\nuse Latent Semantic Indexing~\\cite{deerwester1990indexing} (LSI), which\naccounts for synonyms and does not penalize typographical errors. If the\ncosine similarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p4868
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4869
(dp4870
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent."
p4871
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4872
(dp4873
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.'
p4874
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4875
(dp4876
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p4877
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4878
(dp4879
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p4880
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4881
(dp4882
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p4883
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4884
(dp4885
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8, we labeled about 15\\% of the edits as\nsignificant.'
p4886
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4887
(dp4888
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and whether the method\nsuccessfully classified edits as significant or insignificant.\nFigure~{[}fig:pars{]} shows an example of a significant edit: while the\nbottom paragraph is clearly a revision of the same paragraph (recurring\ntext shown in bold), the edit is significant because it adds new content\nand alters the tone of the text. Overall, we found that paragraphs were\nrarely mapped incorrectly (less than \\(5\\%\\)), even when their content\n(as measured by topic similarity) changed significantly. Similarly, we\nfound the classification of significant edits to be correct in most\ncases, though this is a more subjective measure which we plan to\nevaluate further in future work.'
p4889
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4890
(dp4891
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p4892
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4893
(dp4894
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time to predict changes in revisions \\(d_{t+1}\\) to\n\\(d_{t+10}\\).'
p4895
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4896
(dp4897
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p4898
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4899
(dp4900
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed this measure for the\noriginal paragraph as well as randomly sampled paragraphs and found a\nsignificantly lower likelihood than for paragraphs related by edit\nsimilarity.'
p4901
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4902
(dp4903
g10
S'With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future) were not included in the set of\nrelated paragraphs predicted by edit history and topic similarity.'
p4904
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4905
(dp4906
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p4907
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4908
(dp4909
g10
S"In future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider, and ways to\nincorporate explanations for system recommendations (e.g., ``we\nrecommend reading the introduction because it is often edited following\nedits to the results section'')."
p4910
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4911
(dp4912
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p4913
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p4914
sba(iversion
Version
p4915
(dp4916
g7
g8
(S"\x07\xde\x0c\x0e\x12\r'\x03\xdcH"
tRp4917
sg10
S"\\section{Introduction}\\label{introduction}\n\nMaybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikis\n\nnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision Activity\n\nWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nThe system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.\n\nINSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes~\\footnote{We\n  defined minor edits as having a Levenshtein distance of under fifteen.}\nwere eliminated as well. This resulted in a total of 17,199 versions\nacross the 41 articles, with an average length of 25.71 paragraphs.\nWikipedia data affords results applicable to other collaborative writing\nspaces, because although the average article has over 400 contributing\nauthors, most of these authors make a one-time change. In fact, on\naverage, 15 authors make 80\\% of the edits to an article (see\nFigure~{[}fig:authors{]}). This enables the consideration of\ninteractions between authors, which is crucial for learning about\ncollaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nThis method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}..\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Topic Similarity \\&\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p4918
sg12
(lp4919
(iversion
Paragraph
p4920
(dp4921
g10
S'\\section{Introduction}\\label{introduction}Maybe one paragraph (previous years talk about motivation in similar\nwork in intro and have one-two paragraphs in a background/related work\nsection) about how previous work tried to come up with frameworks to\nsupport writers and tried to investigate the writers problems. They\ndescribe the motivation and the need for such a system: * Tracking\nChanges in Collaborative Writing: Edits, Visibility and Group\nMaintenance Old examples: * Quilt: A collaborative tool for cooperative\nwriting - 1988 * User-centred iterative design of collaborative software\n-1993 * what do co-authors use? * They try to find relevant changes: *\nFlexible Diff-ing in a collaborative writing system * What did they do?\nDeriving High-Level edit histories in Wikisnewer examples also try to classify changes: * How a Structured Document\nModel Can Support Awareness in Collaborative Authoring * A framework for\nasynchronous change awareness in collaborative documents and workspaces\n* some try to find conflicts (different definition of conflict though):\n* Enabling truly collaborative writing on a computer * and some try to\nfind an explicit structur in texts: * A narrative-based collaborative\nwriting tool for constructing coherent technical documents * trying to\npredict: * WikiChanges - Exposing Wikipedia Revision ActivityWhen authors collaborate to write a paper, they need to communicate\nconstantly to ensure that they are all on the same page. Because the\nauthors need to make sure that their edits are coherent with the rest of\nthe paper, including sections written by others, they need to read the\nentire paper frequently, or rely on updates communicated by their\ncoauthors. Even with constant communication, authors can get lost in the\nvolume of edits from other collaborators. Therefore, an assistive system\nwith a summary of the significant changes contributed by other authors\nwould be helpful. We hypothesize that when an author makes a significant\nedit to a paragraph, it eventually triggers a series of adjustments in\nrelated paragraphs. Before these adjustments occur, semantic conflicts\nmight occur between authors. We wanted a collaborative writing system to\nalso predict when and where these conflicts may occur, in order to alert\neven more specifically.'
p4922
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4923
(dp4924
g10
S'The system is composed of the following three components: (1) tracking\nparagraphs; (2) identifying significant changes to paragraphs, and (3)\npredicting future changes to the article. Tracking paragraphs through\npaper revisions is a core capability required for monitoring changes and\npredicting them. The identification of significant content changes is\nimportant for a system to understand how important different changes are\nand whether collaborating authors should be notified. Predicting future\nchanges enables the system to not only report to authors about changes\nthat have already been made, but also draw their attention to other\nparts of the document that might require changes as a result of the\nchanges made.'
p4925
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4926
(dp4927
g10
S"INSERT THIS SOMEHOW IN MOTIVATION {[}A significant edit demanded changes\nin related paragraphs eighty percent of the time{]}, but in\ncollaborative writing, these resulting edits do not occur\ninstantaneously. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nthat can alert relevant authors about paragraphs that might need an\nadditional look as a result of an edit."
p4928
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4929
(dp4930
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. The\nrevision histories were downloaded as raw xml data. We removed\nWikipedia-specific tags that indicate formatting and other irrelevant\ndata, and eliminated versions of the articles under 150 characters, as\nthey did not contain enough information. To focus only on revisions with\nconsequential changes, the versions with simple typo fixes~\\footnote{We\n  defined minor edits as having a Levenshtein distance of under fifteen.}\nwere eliminated as well. This resulted in a total of 17,199 versions\nacross the 41 articles, with an average length of 25.71 paragraphs.\nWikipedia data affords results applicable to other collaborative writing\nspaces, because although the average article has over 400 contributing\nauthors, most of these authors make a one-time change. In fact, on\naverage, 15 authors make 80\\% of the edits to an article (see\nFigure~{[}fig:authors{]}). This enables the consideration of\ninteractions between authors, which is crucial for learning about\ncollaborative behavior.'
p4931
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4932
(dp4933
g10
S'\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)This method differed from previous attempts in the sense that it tracks\nparagraphs as a whole instead of just the longest common subsequence as\nused in {[}a b c{]} or on a sentence level as used in {[}a b c{]}.'
p4934
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4935
(dp4936
g10
S"A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p4937
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4938
(dp4939
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p4940
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4941
(dp4942
g10
S"As shown in figure 1, which shows the distribution of the differences\nbetween a paragraph's Levenshtein ratios and LSI ratios, the Levenshtein\nand LSI ratios demonstrate very different statistics. {[}INSERT\nFIGURE{]}Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance."
p4943
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4944
(dp4945
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p4946
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4947
(dp4948
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p4949
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4950
(dp4951
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p4952
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4953
(dp4954
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p4955
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4956
(dp4957
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p4958
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4959
(dp4960
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p4961
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4962
(dp4963
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}..'
p4964
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4965
(dp4966
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p4967
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4968
(dp4969
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p4970
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4971
(dp4972
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p4973
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4974
(dp4975
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\Caption: After a significant change at version 0, consequent edits are\nmore frequent.'
p4976
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4977
(dp4978
g10
S'We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p4979
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4980
(dp4981
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p4982
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4983
(dp4984
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Topic Similarity \\&\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\Relationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p4985
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4986
(dp4987
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Relationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p4988
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4989
(dp4990
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p4991
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4992
(dp4993
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p4994
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4995
(dp4996
g10
S'We imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.'
p4997
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p4998
(dp4999
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n'
p5000
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p5001
sba(iversion
Version
p5002
(dp5003
g7
g8
(S'\x07\xdf\x02\x08\x171\r\x02\x80\xa0'
tRp5004
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such changes, we\nuse a topic modeling approach which computes the cosine similarity\nbetween word vectors that represent the two versions of a paragraph.\nSpecifically, we use (LSI), which accounts for synonyms and does not\npenalize typographical errors. If the cosine similarity between new and\nold versions of a paragraph is below a threshold of 0.8, we consider the\nedit significant. The threshold of 0.8 was determined empirically by\nmanually evaluating differences between paragraphs with varied\nsimilarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8, we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time to predict changes in revisions \\(d_{t+1}\\) to\n\\(d_{t+10}\\).\n\nThe frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed this measure for the\noriginal paragraph as well as randomly sampled paragraphs and found a\nsignificantly lower likelihood than for paragraphs related by edit\nsimilarity.\n\nWith respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future){[}b{]} were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider, and ways to\nincorporate explanations for system recommendations (e.g., ``we\nrecommend reading the introduction because it is often edited following\nedits to the results section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p5005
sg12
(lp5006
(iversion
Paragraph
p5007
(dp5008
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results."
p5009
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5010
(dp5011
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p5012
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5013
(dp5014
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results."
p5015
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5016
(dp5017
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p5018
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5019
(dp5020
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p5021
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5022
(dp5023
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p5024
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5025
(dp5026
g10
S'While Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.'
p5027
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5028
(dp5029
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such changes, we\nuse a topic modeling approach which computes the cosine similarity\nbetween word vectors that represent the two versions of a paragraph.\nSpecifically, we use (LSI), which accounts for synonyms and does not\npenalize typographical errors. If the cosine similarity between new and\nold versions of a paragraph is below a threshold of 0.8, we consider the\nedit significant. The threshold of 0.8 was determined empirically by\nmanually evaluating differences between paragraphs with varied\nsimilarity values."
p5030
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5031
(dp5032
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent."
p5033
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5034
(dp5035
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.'
p5036
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5037
(dp5038
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p5039
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5040
(dp5041
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p5042
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5043
(dp5044
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p5045
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5046
(dp5047
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8, we labeled about 15\\% of the edits as\nsignificant.'
p5048
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5049
(dp5050
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.'
p5051
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5052
(dp5053
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p5054
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5055
(dp5056
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time to predict changes in revisions \\(d_{t+1}\\) to\n\\(d_{t+10}\\).'
p5057
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5058
(dp5059
g10
S'The frequency of occurrences of each type of inter-paragraph\nrelationship varied. On average, 1.6 pairs of paragraphs related by edit\nhistory were found per revision of the text. A pair related by topic\nsimilarity was only found once every ten versions. Proximity\nrelationships always exist in each version, as each paragraph has at\nleast one neighboring paragraph (and most have two).'
p5060
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5061
(dp5062
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed this measure for the\noriginal paragraph as well as randomly sampled paragraphs and found a\nsignificantly lower likelihood than for paragraphs related by edit\nsimilarity.'
p5063
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5064
(dp5065
g10
S'With respect to the second measure, we found that 71\\% of paragraphs\npairs related by edit history and 63\\% for pairs related by topic\nsimilarity continued being modified (or unmodified) together in the next\n10 versions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related (based on\ninformation ten versions in the future){[}b{]} were not included in the\nset of related paragraphs predicted by edit history and topic\nsimilarity.'
p5066
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5067
(dp5068
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p5069
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5070
(dp5071
g10
S"In future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider, and ways to\nincorporate explanations for system recommendations (e.g., ``we\nrecommend reading the introduction because it is often edited following\nedits to the results section'')."
p5072
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5073
(dp5074
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p5075
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p5076
sba(iversion
Version
p5077
(dp5078
g7
g8
(S'\x07\xdf\x02\x08\x177\x15\x05\x10\xe0'
tRp5079
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such changes, we\nuse a topic modeling approach which computes the cosine similarity\nbetween word vectors that represent the two versions of a paragraph.\nSpecifically, we use (LSI), which accounts for synonyms and does not\npenalize typographical errors. If the cosine similarity between new and\nold versions of a paragraph is below a threshold of 0.8, we consider the\nedit significant. The threshold of 0.8 was determined empirically by\nmanually evaluating differences between paragraphs with varied\nsimilarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8, we labeled about 15\\% of the edits as\nsignificant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nWe looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time (\\(t\\)) to predict changes in revisions \\(d_{t+1}\\)\nto \\(d_{t+10}\\).\n\nThe frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.\n\nWith respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p5080
sg12
(lp5081
(iversion
Paragraph
p5082
(dp5083
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results."
p5084
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5085
(dp5086
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p5087
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5088
(dp5089
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results."
p5090
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5091
(dp5092
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p5093
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5094
(dp5095
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p5096
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5097
(dp5098
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p5099
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5100
(dp5101
g10
S'While Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.'
p5102
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5103
(dp5104
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such changes, we\nuse a topic modeling approach which computes the cosine similarity\nbetween word vectors that represent the two versions of a paragraph.\nSpecifically, we use (LSI), which accounts for synonyms and does not\npenalize typographical errors. If the cosine similarity between new and\nold versions of a paragraph is below a threshold of 0.8, we consider the\nedit significant. The threshold of 0.8 was determined empirically by\nmanually evaluating differences between paragraphs with varied\nsimilarity values."
p5105
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5106
(dp5107
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent."
p5108
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5109
(dp5110
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.'
p5111
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5112
(dp5113
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p5114
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5115
(dp5116
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p5117
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5118
(dp5119
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p5120
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5121
(dp5122
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of LSI similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold ratio of 0.8, we labeled about 15\\% of the edits as\nsignificant.'
p5123
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5124
(dp5125
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.'
p5126
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5127
(dp5128
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p5129
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5130
(dp5131
g10
S'\\includegraphics{figs/parChangesNew.pdf}\\\\We looked at two measures that might indicate that a paragraph will need\nattention. The first checks whether the related paragraphs underwent at\nleast one significant change within the next ten versions. The second\nmeasure tests whether the two paragraphs are related by edit patterns\nten versions after the significant change, that is, whether they keep\nchanging together (or remain unchanged together) more than half the time\nin the following 10 revisions. This second measure provides a stronger\nindication of a possible interdependency between the paragraphs. To\ncompute these measures, we iterate over all the revisions of each of the\ndocuments \\(d\\), and for each revision \\(d_t\\) we use only information\nknown at that time (\\(t\\)) to predict changes in revisions \\(d_{t+1}\\)\nto \\(d_{t+10}\\).'
p5132
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5133
(dp5134
g10
S'The frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).'
p5135
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5136
(dp5137
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.'
p5138
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5139
(dp5140
g10
S'With respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.'
p5141
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5142
(dp5143
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p5144
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5145
(dp5146
g10
S"In future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'')."
p5147
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5148
(dp5149
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p5150
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p5151
sba(iversion
Version
p5152
(dp5153
g7
g8
(S'\x07\xdf\x02\t\x11%)\x04\xe5\xe8'
tRp5154
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such change, we\ncompute the cosine similarity between word vectors that represent the\ntwo versions of a paragraph, using a Latent Semantic Indexing topic\nmodeling approach~\\cite{deerwester1990indexing}. If the cosine\nsimilarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of topic similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold of 0.8, we labeled about 15\\% of the edits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nTo evaluate the accuracy of the prediction, we iterate over all the\nrevisions of each of the documents \\(d\\), and for each revision \\(d_t\\)\nwe use only information known at that time (\\(t\\)) to predict changes in\nrevisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two measures that\nmight indicate that a paragraph will need attention: (1) whether\nparagraphs related to a ``triggering paragraph'' that changed\nsignificantly in revision \\(d_t\\) underwent at least one significant\nchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2) whether those\nparagraphs continue to be related by edit patterns to the triggering\nparagraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is, whether\nthey keep changing together (or remain unchanged together) more than\nhalf the time in the following 10 revisions. This second measure\nprovides a stronger indication of a possible interdependency between the\nparagraphs.\n\nThe frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.\n\nWith respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p5155
sg12
(lp5156
(iversion
Paragraph
p5157
(dp5158
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results."
p5159
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5160
(dp5161
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p5162
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5163
(dp5164
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results."
p5165
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5166
(dp5167
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p5168
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5169
(dp5170
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p5171
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5172
(dp5173
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p5174
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5175
(dp5176
g10
S'While Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.'
p5177
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5178
(dp5179
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such change, we\ncompute the cosine similarity between word vectors that represent the\ntwo versions of a paragraph, using a Latent Semantic Indexing topic\nmodeling approach~\\cite{deerwester1990indexing}. If the cosine\nsimilarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p5180
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5181
(dp5182
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent."
p5183
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5184
(dp5185
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.'
p5186
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5187
(dp5188
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p5189
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5190
(dp5191
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p5192
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5193
(dp5194
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p5195
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5196
(dp5197
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of topic similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold of 0.8, we labeled about 15\\% of the edits as significant.'
p5198
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5199
(dp5200
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.'
p5201
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5202
(dp5203
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p5204
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5205
(dp5206
g10
S"\\includegraphics{figs/parChangesNew.pdf}\\\\To evaluate the accuracy of the prediction, we iterate over all the\nrevisions of each of the documents \\(d\\), and for each revision \\(d_t\\)\nwe use only information known at that time (\\(t\\)) to predict changes in\nrevisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two measures that\nmight indicate that a paragraph will need attention: (1) whether\nparagraphs related to a ``triggering paragraph'' that changed\nsignificantly in revision \\(d_t\\) underwent at least one significant\nchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2) whether those\nparagraphs continue to be related by edit patterns to the triggering\nparagraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is, whether\nthey keep changing together (or remain unchanged together) more than\nhalf the time in the following 10 revisions. This second measure\nprovides a stronger indication of a possible interdependency between the\nparagraphs."
p5207
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5208
(dp5209
g10
S'The frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).'
p5210
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5211
(dp5212
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.'
p5213
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5214
(dp5215
g10
S'With respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.'
p5216
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5217
(dp5218
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p5219
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5220
(dp5221
g10
S"In future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'')."
p5222
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5223
(dp5224
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p5225
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p5226
sba(iversion
Version
p5227
(dp5228
g7
g8
(S'\x07\xdf\x02\t\x12\n\x1b\x05\xa1h'
tRp5229
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such change, we\ncompute the cosine similarity between word vectors that represent the\ntwo versions of a paragraph, using a Latent Semantic Indexing topic\nmodeling approach~\\cite{deerwester1990indexing}. If the cosine\nsimilarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of topic similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold of 0.8, we labeled about 15\\% of the edits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nTo evaluate the accuracy of the predictions of paragraphs that will\nrequire attention following a significant edit to another paragraph, we\ncheck whether the predicted paragraphs undergo a significant change in\nconsequent revisions. Specifically, we iterate over all the revisions of\neach of the documents \\(d\\), and for each revision \\(d_t\\) we use only\ninformation known at that time (\\(t\\)) to predict paragraphs that will\nchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two\nmeasures: (1) whether paragraphs related to a ``triggering paragraph''\nthat changed significantly in revision \\(d_t\\) underwent at least one\nsignificant change in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2)\nwhether those paragraphs continue to be related by edit patterns to the\ntriggering paragraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is,\nwhether they keep changing together (or remain unchanged together) more\nthan half the time in the following 10 revisions. This second measure\nprovides a stronger indication of a possible interdependency between the\nparagraphs.\n\nThe frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.\n\nWith respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p5230
sg12
(lp5231
(iversion
Paragraph
p5232
(dp5233
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results."
p5234
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5235
(dp5236
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p5237
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5238
(dp5239
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results."
p5240
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5241
(dp5242
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) and data mining\nmethods to automatically detect significant changes, without requiring\nauthors to specify explicitly what changes are of interest to them.\nFurthermore, these capabilities go beyond prior approaches for\nsupporting change awareness in that they can predict parts of the\ndocument that have not changed but that are likely to require edits as a\nresult of other changes.'
p5243
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5244
(dp5245
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p5246
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5247
(dp5248
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p5249
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5250
(dp5251
g10
S'While Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.'
p5252
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5253
(dp5254
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such change, we\ncompute the cosine similarity between word vectors that represent the\ntwo versions of a paragraph, using a Latent Semantic Indexing topic\nmodeling approach~\\cite{deerwester1990indexing}. If the cosine\nsimilarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold of 0.8\nwas determined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p5255
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5256
(dp5257
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent."
p5258
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5259
(dp5260
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.'
p5261
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5262
(dp5263
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p5264
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5265
(dp5266
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p5267
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5268
(dp5269
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p5270
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5271
(dp5272
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of topic similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold of 0.8, we labeled about 15\\% of the edits as significant.'
p5273
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5274
(dp5275
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.'
p5276
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5277
(dp5278
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p5279
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5280
(dp5281
g10
S"\\includegraphics{figs/parChangesNew.pdf}\\\\To evaluate the accuracy of the predictions of paragraphs that will\nrequire attention following a significant edit to another paragraph, we\ncheck whether the predicted paragraphs undergo a significant change in\nconsequent revisions. Specifically, we iterate over all the revisions of\neach of the documents \\(d\\), and for each revision \\(d_t\\) we use only\ninformation known at that time (\\(t\\)) to predict paragraphs that will\nchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two\nmeasures: (1) whether paragraphs related to a ``triggering paragraph''\nthat changed significantly in revision \\(d_t\\) underwent at least one\nsignificant change in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2)\nwhether those paragraphs continue to be related by edit patterns to the\ntriggering paragraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is,\nwhether they keep changing together (or remain unchanged together) more\nthan half the time in the following 10 revisions. This second measure\nprovides a stronger indication of a possible interdependency between the\nparagraphs."
p5282
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5283
(dp5284
g10
S'The frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).'
p5285
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5286
(dp5287
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.'
p5288
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5289
(dp5290
g10
S'With respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.'
p5291
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5292
(dp5293
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p5294
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5295
(dp5296
g10
S"In future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'')."
p5297
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5298
(dp5299
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p5300
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p5301
sba(iversion
Version
p5302
(dp5303
g7
g8
(S'\x07\xdf\x02\t\x13\x0b\x1b\t\xb0x'
tRp5304
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) methods to\nautomatically detect significant changes, without requiring authors to\nspecify explicitly what changes are of interest to them. Furthermore,\nthese capabilities go beyond prior approaches for supporting change\nawareness in that they can predict parts of the document that have not\nchanged but that are likely to require edits as a result of other\nchanges.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such change, we\ncompute the cosine similarity between word vectors that represent the\ntwo versions of a paragraph, using a Latent Semantic Indexing topic\nmodeling approach~\\cite{deerwester1990indexing}. If the cosine\nsimilarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold was\ndetermined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of topic similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold of 0.8, we labeled about 15\\% of the edits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nTo evaluate the accuracy of the predictions of paragraphs that will\nrequire attention following a significant edit to another paragraph, we\ncheck whether the predicted paragraphs undergo a significant change in\nconsequent revisions. Specifically, we iterate over all the revisions of\neach of the documents \\(d\\), and for each revision \\(d_t\\) we use only\ninformation known at that time (\\(t\\)) to predict paragraphs that will\nchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two\nmeasures: (1) whether paragraphs related to a ``triggering paragraph''\nthat changed significantly in revision \\(d_t\\) underwent at least one\nsignificant change in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2)\nwhether those paragraphs continue to be related by edit patterns to the\ntriggering paragraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is,\nwhether they keep changing together (or remain unchanged together) more\nthan half the time in the following 10 revisions. This second measure\nprovides a stronger indication of a possible interdependency between the\nparagraphs.\n\nThe frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.\n\nWith respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p5305
sg12
(lp5306
(iversion
Paragraph
p5307
(dp5308
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results."
p5309
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5310
(dp5311
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p5312
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5313
(dp5314
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results."
p5315
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5316
(dp5317
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) methods to\nautomatically detect significant changes, without requiring authors to\nspecify explicitly what changes are of interest to them. Furthermore,\nthese capabilities go beyond prior approaches for supporting change\nawareness in that they can predict parts of the document that have not\nchanged but that are likely to require edits as a result of other\nchanges.'
p5318
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5319
(dp5320
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p5321
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5322
(dp5323
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p5324
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5325
(dp5326
g10
S'While Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.'
p5327
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5328
(dp5329
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such change, we\ncompute the cosine similarity between word vectors that represent the\ntwo versions of a paragraph, using a Latent Semantic Indexing topic\nmodeling approach~\\cite{deerwester1990indexing}. If the cosine\nsimilarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold was\ndetermined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p5330
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5331
(dp5332
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent."
p5333
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5334
(dp5335
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.'
p5336
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5337
(dp5338
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p5339
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5340
(dp5341
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p5342
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5343
(dp5344
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p5345
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5346
(dp5347
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of topic similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold of 0.8, we labeled about 15\\% of the edits as significant.'
p5348
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5349
(dp5350
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.'
p5351
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5352
(dp5353
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p5354
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5355
(dp5356
g10
S"\\includegraphics{figs/parChangesNew.pdf}\\\\To evaluate the accuracy of the predictions of paragraphs that will\nrequire attention following a significant edit to another paragraph, we\ncheck whether the predicted paragraphs undergo a significant change in\nconsequent revisions. Specifically, we iterate over all the revisions of\neach of the documents \\(d\\), and for each revision \\(d_t\\) we use only\ninformation known at that time (\\(t\\)) to predict paragraphs that will\nchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two\nmeasures: (1) whether paragraphs related to a ``triggering paragraph''\nthat changed significantly in revision \\(d_t\\) underwent at least one\nsignificant change in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2)\nwhether those paragraphs continue to be related by edit patterns to the\ntriggering paragraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is,\nwhether they keep changing together (or remain unchanged together) more\nthan half the time in the following 10 revisions. This second measure\nprovides a stronger indication of a possible interdependency between the\nparagraphs."
p5357
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5358
(dp5359
g10
S'The frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).'
p5360
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5361
(dp5362
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.'
p5363
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5364
(dp5365
g10
S'With respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.'
p5366
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5367
(dp5368
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p5369
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5370
(dp5371
g10
S"In future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'')."
p5372
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5373
(dp5374
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p5375
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p5376
sba(iversion
Version
p5377
(dp5378
g7
g8
(S'\x07\xdf\x02\t\x14/\x1c\x08\xd1\xd0'
tRp5379
sg10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results.\n\n\\section{Introduction}\\label{introduction}\n\nCollaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits.\n\nThis paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results.\n\n\\subsection{Related Work}\\label{related-work}\n\nPrior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) methods to\nautomatically detect significant changes, without requiring authors to\nspecify explicitly what changes are of interest to them. Furthermore,\nthese capabilities go beyond prior approaches for supporting change\nawareness in that they can predict parts of the document that have not\nchanged but that are likely to require edits as a result of other\nchanges.\n\n\\section{Approach}\\label{approach}\n\nThis section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities.\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nAs a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.\n\nWhile Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.\n\ntracking\\textsubscript{v}is\\textsubscript{p}aper.png\n\n\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}\n\nWe consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such change, we\ncompute the cosine similarity between word vectors that represent the\ntwo versions of a paragraph, using a Latent Semantic Indexing topic\nmodeling approach~\\cite{deerwester1990indexing}. If the cosine\nsimilarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold was\ndetermined empirically by manually evaluating differences between\nparagraphs with varied similarity values.\n\nWe chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent.\n\n\\subsection{Predicting Future Edits}\\label{predicting-future-edits}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.\n\nWe considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\n\n\\section{Empirical Evaluation}\\label{empirical-evaluation}\n\nThis section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.\n\n\\subsection{Data}\\label{data}\n\nWe used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.\n\n\\subsection{Findings}\\label{findings}\n\nThis section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.\n\n\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nFigure~{[}fig:lsi{]} shows the distribution of topic similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold of 0.8, we labeled about 15\\% of the edits as significant.\n\n\\includegraphics{figs/lsiRatios1.pdf}\\\\\n\nWe manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.\n\n\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\n\n\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}\n\nWe confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.\n\n\\includegraphics{figs/parChangesNew.pdf}\\\\\n\nTo evaluate the accuracy of the predictions of paragraphs that will\nrequire attention following a significant edit to another paragraph, we\ncheck whether the predicted paragraphs undergo a significant change in\nconsequent revisions. Specifically, we iterate over all the revisions of\neach of the documents \\(d\\), and for each revision \\(d_t\\) we use only\ninformation known at that time (\\(t\\)) to predict paragraphs that will\nchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two\nmeasures: (1) whether paragraphs related to a ``triggering paragraph''\nthat changed significantly in revision \\(d_t\\) underwent at least one\nsignificant change in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2)\nwhether those paragraphs continue to be related by edit patterns to the\ntriggering paragraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is,\nwhether they keep changing together (or remain unchanged together) more\nthan half the time in the following 10 revisions. This second measure\nprovides a stronger indication of a possible interdependency between the\nparagraphs.\n\nThe frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).\n\nWith respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.\n\nWith respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.\n\n\\section{Discussion and Future Work}\\label{discussion-and-future-work}\n\nOur long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.\n\nIn future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'').\n\n\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n"
p5380
sg12
(lp5381
(iversion
Paragraph
p5382
(dp5383
g10
S"Many documents (e.g., academic papers, government reports) are typically\nwritten by multiple authors. While existing tools facilitate and support\nsuch collaborative efforts (e.g., Dropbox, Google Docs), these tools\nlack intelligent information sharing mechanisms. Capabilities such as\n``track changes'' and ``diff'' visualize changes to authors, but do not\ndistinguish between minor and major edits and do not consider the\npossible effects of edits on other parts of the document. Drawing\ncollaborators' attention to specific edits and describing them remains\nthe responsibility of authors. This paper presents our initial work\ntoward the development of a collaborative system that supports\nmulti-author writing. We describe methods for tracking paragraphs,\nidentifying significant edits, and predicting parts of the paper that\nare likely to require changes as a result of previous edits. Preliminary\nevaluation of these methods shows promising results."
p5384
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5385
(dp5386
g10
S"\\section{Introduction}\\label{introduction}Collaborative writing is a common activity for many people: scientists\nwrite papers and proposals together, lawyers draft contracts,\nlegislators draft legislation. In recent years, collaborative writing of\ndocuments has become even more widespread with the support of frameworks\nthat simplify distributed editing (e.g., Google Docs, Dropbox). While\ndocument processors provide capabilities such as ``track changes'',\n``diff'', and commenting, they lack intelligent information sharing\nmechanisms. They do not attempt to reason about the importance of\nchanges to different authors and do not consider how edits might affect\nother parts of the document. As a result, significant coordination\noverhead remains: authors need to re-read the entire document frequently\nor rely on communication from their co-authors in order to keep track of\nthe current state of the document and ensure that their edits are\nconsistent with other edits."
p5387
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5388
(dp5389
g10
S"This paper proposes methods for tracking paragraphs across revisions,\nidentifying significant changes, and predicting paragraphs that are\nlikely to be edited following a significant edit of a particular\nparagraph. The development of these methods is a first step toward the\ndesign of a collaborative system capable of (1) drawing authors'\nattention to edits that are important and relevant for them, and (2)\npointing out other parts of the document that are likely to require\nfurther editing. Systems with such capabilities have the potential to\nimprove coherence of documents and coordination among authors while\nreducing the amount of communication required between authors. An\nempirical evaluation of the proposed approach on a corpus of Wikipedia\narticles shows promising initial results."
p5390
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5391
(dp5392
g10
S'\\subsection{Related Work}\\label{related-work}Prior work has studied coordination in collaborative\nwriting~\\cite[interalia]{neuwirth2001computer,kittur2007he}), as well as\nthe social aspects that arise as a result of edits and comments made by\ncollaborators~\\cite{birnholtz2013write}, and has developed tools for\nsupporting such collaboration (e.g., Quilt~\\cite{fish1988quilt}). Most\nclosely related to our work are methods and tools for supporting\nimproved \\emph{awareness} of collaborators about document changes. These\ninclude flexible diffing for reporting significant\nchanges~\\cite{neuwirth1992flexible}, methods for categorizing edits and\npresenting them to\nauthors~\\cite{fong2010did,papadopoulou2007structured,tam2006framework},\nmethods for detecting and alerting authors about merge\nconflicts~\\cite{hainsworth2006enabling}, and methods for detecting\nstructure in text and helping co-authors create coherent documents~\n\\cite{de2007narrative}. Our approach differs from these prior works in\nthat it leverages natural language processing (NLP) methods to\nautomatically detect significant changes, without requiring authors to\nspecify explicitly what changes are of interest to them. Furthermore,\nthese capabilities go beyond prior approaches for supporting change\nawareness in that they can predict parts of the document that have not\nchanged but that are likely to require edits as a result of other\nchanges.'
p5393
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5394
(dp5395
g10
S"\\section{Approach}\\label{approach}This section describes methods for: (1) tracking paragraphs; (2)\nidentifying significant changes to paragraphs, and (3) predicting future\nchanges to the document. Capability (1) is required for both monitoring\nchanges and predicting them. Capability (2) can help identify important\nchanges and decide whether to alert authors of a change. Capability (3)\nis required in order to draw authors' attention to other parts of the\ndocument that might require changes as a result of a recent edit. We\ndescribe our use of lightweight NLP techniques, which provide the\nfoundation for these important capabilities."
p5396
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5397
(dp5398
g10
S'\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}As a document is being edited, paragraphs can be added, moved or\ndeleted. Thus, we developed an algorithm for tracking paragraphs across\nrevisions. The algorithm compares paragraphs based on their Levenshtein\ndistance, that is, the number of changed characters required to move\nfrom one paragraph to another, including additions, deletions, and\nsubstitutions. We use the Levenshtein edit ratio (LR) measure, which is\ndefined as follows:\n\\(LR(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A LR close to 1 indicates high similarity, while a ratio close to 0\nindicates the opposite. For each revision of a document, the algorithm\ncomputes the LR between each paragraph in the current version and each\nparagraph in the previous version. Two paragraphs are mapped across the\nrevision if they each have the highest LR with the other. If a paragraph\nin the new version has no matching paragraphs in the old version (i.e.,\nnone of its ratios are above a threshold of 0.4), we label the paragraph\nas an addition. If a paragraph in the old version is not matched with\nany paragraphs in the new version, we consider it deleted.\nFigure~{[}fig:mapping{]} illustrates this algorithm: some paragraphs\nfound clear matches (e.g., 0, 1, 2), while paragraph 11 from the old\nversion was deleted and 6, 9, 10, and 12 were added in the new version.'
p5399
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5400
(dp5401
g10
S'While Wikipedia provides a diff visualization using an algorithm that\nmaps unique sentences between revisions\\footnote{\\url{http://en.wikipedia.org/wiki/User:Cacycle/diff}},\nthe use of LR with forward and backward mapping allows for more robust\ndetection of paragraph movement even when there are significant changes\nto the content.'
p5402
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5403
(dp5404
g10
S"tracking\\textsubscript{v}is\\textsubscript{p}aper.png\\subsection{Identifying Significant\nChanges}\\label{identifying-significant-changes}We consider a change to be significant if it results in a noticeable\nchange in the paragraph's topic and content. To detect such change, we\ncompute the cosine similarity between word vectors that represent the\ntwo versions of a paragraph, using a Latent Semantic Indexing topic\nmodeling approach~\\cite{deerwester1990indexing}. If the cosine\nsimilarity between new and old versions of a paragraph is below a\nthreshold of 0.8, we consider the edit significant. The threshold was\ndetermined empirically by manually evaluating differences between\nparagraphs with varied similarity values."
p5405
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5406
(dp5407
g10
S"We chose a topic modeling approach for this task because, in contrast\nwith the LR approach used for mapping paragraphs, topic modeling\nconsiders the content of the text. To illustrate, if two of a\nparagraph's sentences switch places, the LR would decrease despite no\nmeaningful change in content. On the other hand, changing a couple of\nkey words will slightly lower the LR, but could drastically affect the\ncontent."
p5408
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5409
(dp5410
g10
S'\\subsection{Predicting Future Edits}\\label{predicting-future-edits}We hypothesized that a paragraph that underwent a significant change\nwould prompt edits in related paragraphs, and investigated which\nparagraphs are likely to change in future revisions as a result of such\nedits.'
p5411
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5412
(dp5413
g10
S'We considered three possible types of inter-paragraph relationships: (1)\n\\emph{proximity}, i.e., neighboring paragraphs; (2) \\emph{edit\nhistories}, i.e., paragraphs that tended to be edited together in\nprevious revisions, and (3) \\emph{topic similarity}, i.e., paragraphs\nwith similar content. For (2), we labeled pairs of paragraphs that\nchanged or remained unchanged together in at least 5 of the previous 10\nrevisions. We chose a window of 10 revisions as it allowed us to obtain\na meaningful signal of correlation between edits, while not looking too\nfar in the past where the content might be significantly different. For\n(3), we labeled pairs as related if their cosine similarity was above an\nempirically determined threshold of 0.4. (There are rarely paragraphs\nwith a higher similarity than 0.4, while a lower similarity does not\nreally capture a similarity in content.)\\section{Empirical Evaluation}\\label{empirical-evaluation}This section describes a preliminary evaluation of the proposed methods\nfor tracking paragraphs, detecting significant edits, and predicting\nfuture changes using a corpus of Wikipedia articles and their revision\nhistories.'
p5414
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5415
(dp5416
g10
S'\\subsection{Data}\\label{data}We used the complete revision histories of 41 different articles chosen\nfrom a diverse set of topics, ranging from famous people and places to\nmathematical algorithms to novels. We removed Wikipedia-specific tags\nthat indicate formatting and other irrelevant data, and eliminated\nversions of articles under 150 characters, as they did not contain\nenough text. To focus on revisions that contained a substantial change,\nthe versions with simple typo fixes (Levenshtein distance \\(< 15\\) )\nwere eliminated.'
p5417
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5418
(dp5419
g10
S'\\subsection{Findings}\\label{findings}This section describes findings from a preliminary empirical evaluation.\nWe focused mostly on the prediction of future edits, but also manually\nevaluated paragraph mapping and significant change detection, which form\nthe basis for edit prediction.'
p5420
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5421
(dp5422
g10
S'\\subsubsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Figure~{[}fig:lsi{]} shows the distribution of topic similarity between\nparagraphs in consecutive versions. As shown, most edits are minor. With\nthe threshold of 0.8, we labeled about 15\\% of the edits as significant.'
p5423
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5424
(dp5425
g10
S'\\includegraphics{figs/lsiRatios1.pdf}\\\\We manually evaluated a random sample of more than 100 mapped paragraphs\nto ensure that paragraphs were correctly mapped and to determine whether\nthe method successfully classified edits as significant or\ninsignificant. Figure~{[}fig:pars{]} shows an example of a significant\nedit: while the bottom paragraph is clearly a revision of the same\nparagraph (recurring text shown in bold), the edit is significant\nbecause it adds new content and alters the tone of the text. Overall, we\nfound that paragraphs were rarely mapped incorrectly (less than\n\\(5\\%\\)), even when their content (as measured by topic similarity)\nchanged significantly. Similarly, we found the classification of\nsignificant edits to be correct in most cases, though this is a more\nsubjective measure which we plan to evaluate further in future work.'
p5426
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5427
(dp5428
g10
S'\\includegraphics{figs/parTopicChangeBigger1.pdf}\\\\\\subsubsection{Predicting Future Edits}\\label{predicting-future-edits-1}We confirmed our hypothesis that a significant edit to a paragraph often\ntriggers edits in other paragraphs in the next revisions. This is\ndemonstrated in Figure~{[}fig:edits{]}, where each line represents a\nparagraph that is edited significantly at time 0. After a period of\nrelative inactivity, a significant edit triggers further adjustments in\nthe near future (as represented by downward spikes). We evaluated the\nthree inter-paragraph relationships (proximity, edit history, and topic\nsimilarity) to determine which paragraphs are more likely to require\nfurther editing after a significant change occurs in the article.'
p5429
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5430
(dp5431
g10
S"\\includegraphics{figs/parChangesNew.pdf}\\\\To evaluate the accuracy of the predictions of paragraphs that will\nrequire attention following a significant edit to another paragraph, we\ncheck whether the predicted paragraphs undergo a significant change in\nconsequent revisions. Specifically, we iterate over all the revisions of\neach of the documents \\(d\\), and for each revision \\(d_t\\) we use only\ninformation known at that time (\\(t\\)) to predict paragraphs that will\nchange in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\). We look at two\nmeasures: (1) whether paragraphs related to a ``triggering paragraph''\nthat changed significantly in revision \\(d_t\\) underwent at least one\nsignificant change in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), and (2)\nwhether those paragraphs continue to be related by edit patterns to the\ntriggering paragraph in revisions \\(d_{t+1}\\) to \\(d_{t+10}\\), that is,\nwhether they keep changing together (or remain unchanged together) more\nthan half the time in the following 10 revisions. This second measure\nprovides a stronger indication of a possible interdependency between the\nparagraphs."
p5432
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5433
(dp5434
g10
S'The frequency of occurrence of each type of inter-paragraph relationship\nvaried. On average, 1.6 pairs of paragraphs related by edit history were\nfound per revision of the text. A pair related by topic similarity was\nonly found once every ten versions. Proximity relationships always exist\nin each version, as each paragraph has at least one neighboring\nparagraph (and most have two).'
p5435
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5436
(dp5437
g10
S'With respect to the first measure, the relationship of edit history is\nmuch more predictive of a future significant edit than proximity, as\nshown in Table~{[}table:futureEdits{]}. We computed the proximity\nmeasure for the original paragraph as well as randomly sampled\nparagraphs and found a significantly lower likelihood than for\nparagraphs related by edit similarity.'
p5438
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5439
(dp5440
g10
S'With respect to the second measure, we found that 71\\% of paragraph\npairs related by edit history and 63\\% related by topic similarity\ncontinued being modified (or unmodified) together in the next 10\nversions. (Proximity was not evaluated for this measure, as it did\nalmost no better than the random control for the first, less strict,\nmeasure.) Further, we obtained a recall of 80\\% with predictions based\non edit history and topic similarity. That is, only 20\\% of the\nparagraphs that should have been labeled as related were not included in\nthe set of related paragraphs predicted by edit history and topic\nsimilarity.'
p5441
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5442
(dp5443
g10
S'\\section{Discussion and Future Work}\\label{discussion-and-future-work}Our long-term goal is to build a system that will improve the\ncollaborative writing process. The methods we developed for tracking\nparagraphs throughout document revisions, detecting significant edits,\nand predicting future edits provide the basis for such a system. These\ncapabilities can inform decisions about alerting authors to specific\nchanges and places in the document that are likely to require revisions.'
p5444
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5445
(dp5446
g10
S"In future work, we will incorporate information about author identity to\ndesign personalized alerts for authors depending on the edits they have\nmade. We also plan to develop additional algorithms for summarizing\nchanges and to investigate the use of algorithms that measure text\ncoherence (e.g.,Textiling \\cite{hearst1994multi}) in order to alert\nauthors to parts of the text that could be improved. Finally, we will\nexplore alternative interface designs for presenting the information\nchosen by the algorithms for authors to consider and ways to incorporate\nexplanations for system recommendations (e.g., ``we recommend reading\nthe introduction because it is often edited following edits to the\nresults section'')."
p5447
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5448
(dp5449
g10
S'\\textbf{Acknowledgments.} The work was funded in part by the Nuance\nFoundation. We thank Stuart Shieber for helpful discussions.\n'
p5450
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p5451
sba(iversion
Version
p5452
(dp5453
g7
g8
(S'\x07\xde\x0c\x0f\x16!\x1f\x08\x978'
tRp5454
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}..\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}..\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nCaption: After a significant change at version 0, consequent edits are\nmore frequent.\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Topic Similarity \\&\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p5455
sg12
(lp5456
(iversion
Paragraph
p5457
(dp5458
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p5459
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5460
(dp5461
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}..'
p5462
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5463
(dp5464
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p5465
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5466
(dp5467
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p5468
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5469
(dp5470
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p5471
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5472
(dp5473
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p5474
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5475
(dp5476
g10
S"\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p5477
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5478
(dp5479
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p5480
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5481
(dp5482
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics."
p5483
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5484
(dp5485
g10
S"\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing is a form of\ntopic modeling that calculates the topic similarity between two texts.\nIts strengths lie in accounting for synonyms and not penalizing for\ntypographical errors. The process begins by composing a corpus for each\nWikipedia article from all of the documents (paragraphs of the versions\nof the article). It analyzes tokens (a specific instance of a word),\neliminating those that only occur once, as well as stopword tokens, such\nas `the' or `and'. It then creates a TF-IDF matrix, which assigns a\nweight to every token in each document, which indicates the importance\nof that token for this document. This weight increases proportionally to\nthe frequency of the word in the document, but accounts for the\nfrequency of the word in the corpus, such that the frequent occurrence\nof a usually uncommon word is given a larger weight to signify this\nimportance."
p5486
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5487
(dp5488
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p5489
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5490
(dp5491
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p5492
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5493
(dp5494
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p5495
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5496
(dp5497
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p5498
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5499
(dp5500
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p5501
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5502
(dp5503
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p5504
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5505
(dp5506
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}..'
p5507
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5508
(dp5509
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p5510
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5511
(dp5512
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p5513
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5514
(dp5515
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p5516
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5517
(dp5518
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\Caption: After a significant change at version 0, consequent edits are\nmore frequent.'
p5519
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5520
(dp5521
g10
S'We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p5522
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5523
(dp5524
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p5525
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5526
(dp5527
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Topic Similarity \\&\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\Relationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p5528
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5529
(dp5530
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Relationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p5531
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5532
(dp5533
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p5534
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5535
(dp5536
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p5537
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5538
(dp5539
g10
S'We imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.'
p5540
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5541
(dp5542
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n'
p5543
sg17
I00
sg18
Nsg19
Nsbasg101
S'SebastianGehrmann'
p5544
sba(iversion
Version
p5545
(dp5546
g7
g8
(S'\x07\xde\x0c\x0f\x16)/\x04\x9b\xb0'
tRp5547
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}..\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio, but the scores are not correlated.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}..\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\ Proximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nRelationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nRelationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.\n\n\\section{Conclusion}\\label{conclusion}\n\nBoth of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n"
p5548
sg12
(lp5549
(iversion
Paragraph
p5550
(dp5551
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p5552
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5553
(dp5554
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}..'
p5555
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5556
(dp5557
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p5558
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5559
(dp5560
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p5561
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5562
(dp5563
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p5564
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5565
(dp5566
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p5567
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5568
(dp5569
g10
S"\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p5570
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5571
(dp5572
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p5573
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5574
(dp5575
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio, but the scores are not correlated."
p5576
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5577
(dp5578
g10
S"\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance."
p5579
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5580
(dp5581
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p5582
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5583
(dp5584
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p5585
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5586
(dp5587
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p5588
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5589
(dp5590
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p5591
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5592
(dp5593
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p5594
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5595
(dp5596
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p5597
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5598
(dp5599
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}..'
p5600
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5601
(dp5602
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p5603
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5604
(dp5605
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p5606
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5607
(dp5608
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p5609
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5610
(dp5611
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p5612
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5613
(dp5614
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p5615
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5616
(dp5617
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\ Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\Relationship or Control Percentage of times that paragraph experienced\nat least one significant change Edit History 81\\% Topic Similarity .\nPhysical Proximity 24\\% Paragraph with original significant change 40\\%\nRandom Sample of Paragraphs 15\\%More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p5618
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5619
(dp5620
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Relationship Number Found Successfully Linked Ratio of Successfully\nLinked Topic Similarity 1,869 1,203 63\\% Editing History 27,722 19,685\n71\\%Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p5621
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5622
(dp5623
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p5624
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5625
(dp5626
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p5627
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5628
(dp5629
g10
S'We imagine a couple other helpful components for an assistive system\nthat our methods could provide the foundation for. Using text summary\nalgorithms, the system could provide a succinct textual summary of\nsignificant changes already detected. The system could also \\ldots{}.'
p5630
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5631
(dp5632
g10
S'\\section{Conclusion}\\label{conclusion}Both of these measures of relatedness are successful in determining\nwhether a paragraph will change together in the future. Consequently, we\nassert that if significant edit occurs, related paragraphs should also\nbe edited. A proposed assistive system will alert the relevant authors\nof related paragraphs if this resulting edit does not occur. By\ndetecting relationships between paragraphs in a multi-authored paper,\nour system can predict and alert appropriate authors if a significant\nchange has the potential to create a semantic conflict within the paper.\n'
p5633
sg17
I00
sg18
Nsg19
Nsbasg101
S'LaurenUrke'
p5634
sba(iversion
Version
p5635
(dp5636
g7
g8
(S'\x07\xde\x0c\x0f\x17\x0b\x01\x01S\xd8'
tRp5637
sg10
S"\\section{Introduction}\\label{introduction}\n\nIn order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly.\n\nWhen authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.\n\nWe hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically.\n\nIn order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit.\n\n\\subsection{Background}\\label{background}\n\nSystems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.\n\n\\section{Approach}\\label{approach}\n\n\\subsection{Data}\\label{data}\n\nThe described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.\n\n\\includegraphics{figs/authors_contrib.JPG}\\\\\n\n\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}\n\nWe developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)\n\nA Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches.\n\n\\includegraphics{figs/mapping_example.png}\\\\\n\n\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}\n\nWe define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content.\n\nAs shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio, but the scores are not correlated.\n\n\\includegraphics{figs/distribution_of_differences.png}\\\\\n\nTherefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance.\n\nThe latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue.\n\nBy calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}\n\nWe hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.\n\nWe looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.\n\nTo evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange.\n\n\\section{Findings}\\label{findings}\n\n\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}\n\nTo evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions.\n\n\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}\n\nUsing the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.\n\n\\includegraphics{figs/LSI_sim_hist.JPG}\\\\\n\nWe evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.\n\nOLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused.\n\n\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}\n\nWe evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.\n\n\\includegraphics{figs/change_after_streak.png}\\\\\n\nWe looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.\n\nWith respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.\n\n{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\\n\nProximity \\& 24\\%\\\\\n\nParagraph with original change \\& 40\\%\\\\\n\nRandom sampled paragraph \\& 15\\%\\\\\n\nMore importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.\n\n\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}\n\nLastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.\n\n\\section{Discussion}\\label{discussion}\n\nAs demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.\n\nIn the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later.\n\nWe imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.\n\n\\section{Conclusion}\\label{conclusion}\n\nOur goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n"
p5638
sg12
(lp5639
(iversion
Paragraph
p5640
(dp5641
g10
S"\\section{Introduction}\\label{introduction}In order to assist with the collaborative writing process, we propose an\nintelligent assistive system with two primary tasks. First, it should\ndetect important edits and promote them to the relevant authors. Second,\nit should anticipate possible semantic conflicts between various\nauthors' contributions, alerting when appropriate in order to ensure\nthat the writing process goes smoothly."
p5642
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5643
(dp5644
g10
S'When authors collaborate on a paper, they need to communicate constantly\nto ensure they are on the same page. Because the authors need to make\nsure their edits are coherent with the rest of the paper, including\nsections written by others, they need to read the entire paper\nfrequently, or rely on updates communicated by their co-authors. Even\nwith constant communication, authors can get lost in the volume of edits\nfrom other collaborators. Further, Kittur et al. have shown that in a\ncollaborative environment such as Wikipedia, the majority of edits no\nlonger add content but instead do maintenance work and add discussions\n\\cite{kittur2007he}. Therefore, an assistive system with a summary of\nthe significant changes contributed by other authors would be helpful,\nas shown by Birnholtz et al. \\cite{birnholtz2012tracking}.'
p5645
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5646
(dp5647
g10
S"We hypothesized that when an author makes a significant edit to a\nparagraph, it eventually triggers a series of adjustments in related\nparagraphs. In fact, a significant edit prompted changes in related\nparagraphs eighty percent of the time. However, in collaborative\nwriting, these resulting edits do not occur instantaneously. Before\nthese adjustments occur, semantic conflicts might occur between the\nauthors' content. Instead of waiting for other authors to discover the\ninconsistency caused by one author's edit, we want an assistive system\nto predict when and where these conflicts may occur, in order to alert\neven more specifically."
p5648
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5649
(dp5650
g10
S"In order to achieve this, the system is composed of the following three\ncomponents: (1) tracking paragraphs; (2) identifying significant changes\nto paragraphs, and (3) predicting future changes to the article.\nTracking paragraphs through paper revisions is a core capability\nrequired for monitoring changes and predicting them. The identification\nof significant content changes is helps the system promote only the most\nimportant changes and decide whether to alert collaborating authors.\nPredicting future changes enables the system to not only report changes\nthat have already been made, but also draw authors' attention to other\nparts of the document that might require changes as a result of a recent\nedit."
p5651
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5652
(dp5653
g10
S'\\subsection{Background}\\label{background}Systems that support collaborative writing can dramatically improve the\nwriting process, as shown by Birnholtz et al.\n\\cite{birnholtz2012tracking}.There has been some research on the topic\nof analyzing relevant changes between two versions of a text. Neuwirth\net al. use flexible diffing \\cite{neuwirth1992flexible} to detect and\nreport important changes. Fong et al. attempt to categorize edits\n\\cite{fong2010did}, which, according to Papadopoulou et al.\n\\cite{papadopoulou2007structured}, can be useful for detecting important\nchanges. Tam et al. developed an interface to show these categorized\nchanges to users \\cite{tam2006framework}. Hainsworth et al.\n\\cite{hainsworth2006enabling} detect and alert authors about merge\nconflicts. De Silva uses edit histories in order to find structure\nwithin a text and to help co-authors write coherent documents\n\\cite{de2007narrative}. Nunes et al. analyze the impact of public events\non the frequency of edits in the collaborative writing environment,\nWikipedia, and argue that edits are predictable\n\\cite{nunes2008wikichanges}.'
p5654
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5655
(dp5656
g10
S'\\section{Approach}\\label{approach}\\subsection{Data}\\label{data}The described research is based on the revision history from a wide\nvariety of Wikipedia articles that undergo intense editing processes.\nWikipedia is a unique source because it presents extensive data for\ncollaborative writing. The findings use the complete revision revision\nhistory of 41 different articles chosen from a diverse set of topics,\nfrom famous people and places to mathematical algorithms to novels. This\napproach was used in various other papers\n\\cite{wohner2009assessing, fong2010did}. The revision histories were\ndownloaded as raw xml data. We removed Wikipedia-specific tags that\nindicate formatting and other irrelevant data, and eliminated versions\nof the articles under 150 characters, as they did not contain enough\ninformation. To focus only on revisions with consequential changes, the\nversions with simple typo fixes~\\footnote{We defined minor edits as\n  having a Levenshtein distance of under fifteen.} were eliminated as\nwell to reduce the number of maintenance edits \\cite{kittur2007he}. This\nresulted in a total of 17,199 versions across the 41 articles, with an\naverage length of 25.71 paragraphs. Wikipedia data affords results\napplicable to other collaborative writing spaces, because although the\naverage article has over 400 contributing authors, most of these authors\nmake a one-time change. In fact, on average, 15 authors make 80\\% of the\nedits to an article (see Figure~{[}fig:authors{]}). This enables the\nconsideration of interactions between authors, which is crucial for\nlearning about collaborative behavior.'
p5657
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5658
(dp5659
g10
S"\\includegraphics{figs/authors_contrib.JPG}\\\\\\subsection{Tracking paragraphs}\\label{tracking-paragraphs}We developed a novel mapping algorithm that uses the Levenshtein edit\nratio measure, which is defined as follows:\n\\(Levenshtein Ratio(a,b) = 1-\\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \\)A Levenshtein ratio close to one between two paragraphs indicates a high\nsimilarity between them, while a ratio close to zero indicates the\nopposite. For each revision, we computed the Levenshtein ratio between\neach paragraph in the old version and each paragraph in the new version.\nTwo paragraphs are mapped across the revision if they each had the\nhighest Levenshtein ratio for the other. If a paragraph in the new\nversion had no ``matches'', meaning that none of its ratios were above a\nthreshold of 0.4, this paragraph was new. If a paragraph in the old\nversion had no ``matches'', then it was deleted in the revision.\nFigure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10\nand 12 of the old version were deleted, while the others found clear\nmatches."
p5660
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5661
(dp5662
g10
S"\\includegraphics{figs/mapping_example.png}\\\\\\subsection{Detect Significant\nChanges}\\label{detect-significant-changes}We define a significant change as a noticeable change in the paragraph's\ntopic and content. For this calculation, the Levenshtein ratio does not\nprovide the right kind of information. For example, if two of the\nparagraph's sentences switch places, the Levenshtein ratio would\ndecrease despite no meaningful change in content. On the other hand,\nchanging a couple key words will slightly lower the Levenshtein ratio,\nbut could drastically affect the content."
p5663
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5664
(dp5665
g10
S"As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of\nthe differences between a paragraph's Levenshtein ratios and LSI ratios,\nthe Levenshtein and LSI ratios demonstrate very different statistics. In\ngeneral, the topic similarity ratio is closer to one than the\nlevenshtein ratio, but the scores are not correlated."
p5666
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5667
(dp5668
g10
S"\\includegraphics{figs/distribution_of_differences.png}\\\\Therefore, we use a topic modeling approach, which is a better fit for\nassessing changes in content. Latent Semantic Indexing\n\\cite{deerwester1990indexing} is a form of topic modeling that\ncalculates the topic similarity between two texts. Its strengths lie in\naccounting for synonyms and not penalizing for typographical errors. The\nprocess begins by composing a corpus for each Wikipedia article from all\nof the documents (paragraphs of the versions of the article). It\nanalyzes tokens (a specific instance of a word), eliminating those that\nonly occur once, as well as stopword tokens, such as `the' or `and'. It\nthen creates a TF-IDF matrix, which assigns a weight to every token in\neach document, which indicates the importance of that token for this\ndocument. This weight increases proportionally to the frequency of the\nword in the document, but accounts for the frequency of the word in the\ncorpus, such that the frequent occurrence of a usually uncommon word is\ngiven a larger weight to signify this importance."
p5669
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5670
(dp5671
g10
S"The latent semantic indexing method then reduces the dimensions of the\nmatrix, clustering synonyms, words with similar topics, and words that\nusually occur together. When comparing two paragraphs, the method\ncomputes the cosine similarity between each paragraph's row vector.\nParagraphs that have similar topics will have a large cosine similarity\nvalue."
p5672
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5673
(dp5674
g10
S'By calculating the topic similarity between two concurrent versions of\nan edited paragraph, the system can detect whether a significant change\nhas occurred. If the cosine similarity between the two paragraphs was\nbelow an empirically determined threshold of 0.8, we label the edit as\nsignificant.'
p5675
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5676
(dp5677
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts}We hypothesized that a paragraph that underwent a significant change\nwould cause inconsistencies in related paragraphs, prompting edits.\nTherefore, in order to predict future conflicts, an assistive system\nneeds to detect significant changes and then determine consequently\nwhich paragraphs were most likely to change.'
p5678
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5679
(dp5680
g10
S'We looked at three possible types of inter-paragraph relationships.\nParagraphs could be related by physical proximity: perhaps the\nneighboring paragraphs would require adjustments, as they are likely\npart of the same section. Paragraphs could also be related by topic. For\nexample, in an academic paper, the discussion section and the conclusion\nshould present similar themes. If one changes, the other may need to be\nedited to reflect this change. For each significant change, we used the\nexisting LSI Topic Model to determine which paragraphs discussed similar\ntopics. Lastly, paragraphs could be related because of similar edit\nhistories. For each significant change, we evaluated the edit history of\nthis paragraph with every other paragraph in the article. We labeled\npairs as related if they changed or remained unchanged together over\nhalf the time. With a higher threshold, the sample size decreases, but\nwith a lower threshold, the results become less predictive of a\nsignificant change prompting further edits. This threshold strikes a\nbalance between these two outcomes.'
p5681
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5682
(dp5683
g10
S"To evaluate these both of these suspected relationships, we looked at\nthe related paragraphs' edit patterns in the ten versions following the\nsignificant change. If the related paragraphs changed together over half\nthe time, the paragraphs with this relationship proved to be related in\nthe future, verifying the relationship at the time of the significant\nchange."
p5684
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5685
(dp5686
g10
S"\\section{Findings}\\label{findings}\\subsection{Tracking Paragraphs}\\label{tracking-paragraphs-1}To evaluate the method for tracking paragraphs through consecutive\nversions of a paper, we calculated the number of versions from the\nparagraphs' inception to its demise. On average, paragraphs lasted 83\narticle revisions."
p5687
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5688
(dp5689
g10
S'\\subsection{Detecting Significant\nChanges}\\label{detecting-significant-changes}Using the LSI Topic Similarity model and a threshold ratio of 0.8, we\nlabeled about 15\\% of the edits as significant, as shown in\nFigure~{[}fig:lsi{]}.'
p5690
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5691
(dp5692
g10
S'\\includegraphics{figs/LSI_sim_hist.JPG}\\\\We evaluated a random sample of these edits to determine that this\nmethod successfully classifies edits. We provide an example of a\nsignificant edit below. While these paragraphs are clearly the same, the\nedit is significant because it contributes content and changes the tone\nof the paragraph.'
p5693
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5694
(dp5695
g10
S"OLD: After complaints arose during the renovation in the late 1980s of\nthe early residential colleges, a swing dormitory was built in 1998 to\nfacilitate housing students during the massive overhaul of buildings\nthat had seen only intermediate improvements in plumbing, heating,\nelectrical and network wiring, and general maintenance over their\n35-to-80-year existence. The new Residence Hall is not a residential\ncollege, but houses students from other colleges during renovations. It\nis commonly called ``Swing Space'' by the students; it's official name\n``Boyd Hall'' is unused. ---------------------------------------------\nNEW: In 1990, Yale launched a series of massive overhauls to the older\nresidential buildings, whose decades of existence had seen only routine\nmaintenance and incremental improvements to plumbing, heating, and\nelectrical and network wiring. Calhoun College was the first to see\nrenovation. Various unwieldy schemes were used to house displaced\nstudents during the yearlong projects, but complaints finally moved Yale\nto build a new residence hall between the gym and the power plant. It is\ncommonly called ``Swing Space'' by the students; its official name\n``Boyd Hall'' is unused."
p5696
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5697
(dp5698
g10
S'\\subsection{Predicting Future\nConflicts}\\label{predicting-future-conflicts-1}We evaluated various inter-paragraph relationships to determine which\nparagraphs are more likely to require editing after a significant change\noccurs in the article. As seen in Figure~{[}fig:edits{]}, when a\nparagraph is edited for the first time in a while, further adjustments\nare triggered in the near future.'
p5699
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5700
(dp5701
g10
S'\\includegraphics{figs/change_after_streak.png}\\\\We looked at two measures that indicate that a paragraph may need\nattention. First, the related paragraphs experience at least one\nsignificant change within the next ten versions, indicating that a\nsemantic discrepancy was introduced and required fixing. Second, and\nmore importantly, the related paragraphs relationship was correctly\npredicted; that is, they are still related ten versions after the\nsignificant change, meaning that they change together (or remain\nunchanged together) more than half the time. This is a stronger\nindication than just undergoing at least one significant change.'
p5702
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5703
(dp5704
g10
S'With respect to the first measure, the relationships of edit history and\ntopic similarity are much more predictive than physical proximity, as\nshown in Table~{[}table:futureEdits{]}. They are also significantly more\npredictive than random sample controls. For controls, we compare with\nthe original paragraph as well as a random sample of any ten consecutive\nversions within Wikipedia article histories.'
p5705
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5706
(dp5707
g10
S'{\\textbar{}p{4cm}\\textbar{}p{4cm}\\textbar{}} \\textbf{Relationship} \\&\n\\textbf{Percentage of times of at least one significant change}\\\\Edit\nHistory \\& 81\\%\\\\Proximity \\& 24\\%\\\\Paragraph with original change \\& 40\\%\\\\Random sampled paragraph \\& 15\\%\\\\More importantly, with respect to the second measure, we correctly\npredicted 63\\% of pairs related by topic and 71\\% of pairs related by\nedit history. Further, we obtained a recall of 80\\% for these correct\npredictions; thus, only 20\\% of the paragraphs that should have been\nlabeled as related (based on information ten versions in the future)\nwere missed.'
p5708
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5709
(dp5710
g10
S'\\begin{longtable}[c]{@{}llll@{}}\n\\caption{Linked paragraphs by relationship.{}}\\tabularnewline\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endfirsthead\n\\toprule\n\\textbf{Relationship} & \\textbf{N} & \\textbf{Linked} &\n\\textbf{Ratio}\\tabularnewline\n\\midrule\n\\endhead\nTopic Similarity & 1,869 & 1,203 & 63\\%\\tabularnewline\nEdit Similarity & 27,722 & 19,685 & 71\\%\\tabularnewline\nProximity? & ? & ? & ?\\tabularnewline\n\\bottomrule\n\\end{longtable}Lastly, to ensure independence from specific articles, we calculated the\ncorrelation between our statistics across all of our Wikipedia articles.\nThe correlation coefficient was 0.99 for all numbers.'
p5711
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5712
(dp5713
g10
S'\\section{Discussion}\\label{discussion}As demonstrated by the long average lifespan of a paragraph, our\nalgorithm for tracking paragraphs throughout versions of an article is\ncapable of following paragraphs through complex edits. This provides the\nbasis for detecting significant changes and anticipating future semantic\nconflicts. Our edit evaluation method successfully detects the most\nsignificant changes using the LSI Topic Similarity model. Based on these\nsignificant changes, we anticipate possible semantic conflicts in linked\nparagraphs. After a significant change, paragraphs related to the edited\nparagraph were indeed more likely to be edited in response a couple\nversions later. Paragraphs linked by similar edit histories were most\nlikely to need editing, with paragraphs linked by topic similarity not\nfar behind.'
p5714
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5715
(dp5716
g10
S"In the future, we can build an assistive system that uses our methods to\nimprove the collaborative writing environment. The paragraph tracking\nalgorithm makes it possible to create a list of authors who have\ncontributed to a specific paragraph, which is crucial for determining\nwho to alert when significant edits occur. By labeling edits as\nsignificant, the system can save authors time, since they will no longer\nneed to discern which of their peers' edits actually matter. Then, when\na significant edit occurs, the system can alert authors to related\nparagraphs that will likely need adjusting, allowing authors to fix\nsemantic conflicts immediately, instead of discovering them later."
p5717
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5718
(dp5719
g10
S'We imagined another helpful component for an assistive system that can\nbe based on our foundational methods. Using text summary algorithms, the\nsystem could provide a succinct textual summary of significant changes\nalready detected, rather than just an output of the significant edits.'
p5720
sg17
I00
sg18
Nsg19
Nsba(iversion
Paragraph
p5721
(dp5722
g10
S'\\section{Conclusion}\\label{conclusion}Our goal was to provide the algorithmic foundation for an intelligent\nsystem that could assist in the field of collaborative writing. We\nsuccessfully formulated a method to detect which edits are most\nsignificant. Consequently, we discovered that if significant edit\noccurs, related paragraphs will probably also be edited. A proposed\nassistive system will alert the relevant authors of related paragraphs\nif this resulting edit does not occur. By detecting relationships\nbetween paragraphs in a multi-authored paper, our system could predict\nand alert if a significant change has the potential to create a semantic\nconflict within the paper.\n'
p5723
sg17
I00
sg18
Nsg19
Nsbasg101
S'OfraAmir'
p5724
sbasS'title'
p5725
S'colWriting'
p5726
sb.