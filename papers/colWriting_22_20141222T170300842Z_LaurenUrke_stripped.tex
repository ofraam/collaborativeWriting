\section{Introduction}\label{introduction}

Collaborative writing is a common activity, for example, researchers
write papers and proposals together, lawyers draft contracts, etc. In
recent years, collaborative writing of documents has become even more
widespread with the support of frameworks that simplify distributed
editing (e.g., google docs, dropbox). However, while document processors
provide capabilities such as ``track changes'', ``diff'' and commenting,
they lack intelligent information sharing mechanisms. They do not
attempt to reason about the importance or relevance of changes to
different authors and do not consider how edits might affect other parts
of the document.

In practice, the collaborative writing process requires significant
communication between authors to update each other. Because the authors
need to make sure their edits are coherent with the document as a whole,
including sections written by others, they need to read the entire
document frequently, or rely on updates from their co-authors. Even when
authors communicate with each other frequently, they can get lost in the
volume of edits from other collaborators or become overwhelmed with too
much information.

This paper presents our initial work on developing methods that provide
the basis for intelligent interactive systems that support collaborating
authors. These methods include drawing their attention to edits that are
important and relevant for them, as well as to other parts of the
document that are likely to require consequent editing. Systems with
such capabilities have potential to improve coherence and coordination
while reducing the communication burden.

The proposed methods use NLP techniques such as distance metrics and
topic models to track paragraphs across revisions and to identify
significant changes made to the document. Analysis of co-occurrence of
changes in past revisions is used to identify parts of the document that
tend to change together, which is used to predict which parts of a
document will require edits as a result of a significant change to a
paragraph. An empirical evaluation of the approach on a corpus of
Wikipedia articles shows promising initial results, as it is able to
track paragraph across revisions, identify significant changes, and
predict which paragraphs are likely to be edited following significant
edits.

\subsection{Related Work}\label{related-work}

Prior work has studied coordination in collaborative writing (e.g.,
~\cite{neuwirth2001computer,kittur2007he}), as well as the social
aspects that arise as a result of edits and comments made by
collaborators~\cite{birnholtz2012tracking,birnholtz2013write}, and has
developed tools for supporting such collaboration (e.g.,
Quilt~\cite{fish1988quilt}). Most closely related to our work are
methods and tools for supporting improved \emph{awareness} of
collaborators about changes made to a document. These include flexible
diffing for reporting significant changes~\cite{neuwirth1992flexible},
methods for categorization of edits and interfaces for presenting them
to
authors~\cite{fong2010did,papadopoulou2007structured,tam2006framework},
methods for detecting and alerting authors about merge
conflicts~\cite{hainsworth2006enabling}, and methods for detecting
structure in text and help co-authors create coherent documents~
\cite{de2007narrative}. Our approach differs from these prior works in
that it leverages natural language processing and data mining methods to
automatically detect significant edits and furthermore predict future
edits, without requiring authors to specify explicitly what changes are
of interest to them. These capabilities go beyond prior approaches for
supporting change awareness in that they can support authors not only in
finding the changes that have been made, but also in drawing their
attention to parts of the document that are likely to require edits as a
result of those changes.

\section{Approach}\label{approach}

This section describes the developed methods for providing three key
capabilities: (1) tracking paragraphs; (2) identifying significant
changes to paragraphs, and (3) predicting future changes to the article.
Tracking paragraphs through paper revisions is a core capability
required for monitoring changes and predicting them. The identification
of significant content changes can help promote only the most important
changes and decide whether to alert collaborating authors. Predicting
future changes is required in order to draw authors' attention to other
parts of the document that might require changes as a result of a recent
edit.

\subsection{Tracking paragraphs}\label{tracking-paragraphs}

We developed a mapping algorithm that compares paragraphs based on their
Levenshtein distance, that is, the number of changed characters required
to move from one paragraph to another, including additions, deletions,
and substitutions. In particular, we use the Levenshtein edit ratio
measure, which is defined as follows:
\(Levenshtein Ratio(a,b) = 1-\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \)

A Levenshtein ratio between two paragraphs close to one indicates a high
similarity between them, while a ratio close to zero indicates the
opposite. For each revision of a document, the algorithm computes the
Levenshtein ratio between each paragraph in the old version and each
paragraph in the new version. Two paragraphs are mapped across the
revision if they each have the highest Levenshtein ratio for the other.
If a paragraph in the new version has no matching paragraphs in the old
version, meaning that none of its ratios were above a threshold of 0.4,
we label the paragraph as an addition. If a paragraph in the old version
is not matched with any paragraphs in the next version, then we consider
it a deletion. Figure~{[}fig:mapping{]} illustrates this algorithm:
paragraphs 9, 10, and 12 of the old version were deleted, while the
others found clear matches (e.g., paragraph 11 in the revised document
was mapped with paragraph 9 in the older version of the document).

\includegraphics{figs/mapping_example.png}\\

\subsection{Detect Significant
Changes}\label{detect-significant-changes}

We consider a significant change to be a noticeable change in the
paragraph's topic and content. For this calculation, the Levenshtein
ratio does not provide the right kind of information. For example, if
two of the paragraph's sentences switch places, the Levenshtein ratio
would decrease despite no meaningful change in content. On the other
hand, changing a couple of key words will slightly lower the Levenshtein
ratio, but could drastically affect the content.

Therefore, we use a topic modeling approach, which is a better fit for
assessing changes in content. Specifically, we use Latent Semantic
Indexing~\cite{deerwester1990indexing} (LSI) which accounts for synonyms
and does not penalize for typographical errors. The process begins by
composing a corpus for each Wikipedia article from all of the documents
(paragraphs of the versions of the article). It analyzes tokens (a
specific instance of a word), eliminating those that only occur once, as
well as stopword tokens, such as `the' or `and'. It then creates a
TF-IDF matrix, which assigns a weight to every token in each document,
which indicates the importance of that token for this document. This
weight increases proportionally to the frequency of the word in the
document, but accounts for the frequency of the word in the corpus, such
that the frequent occurrence of a usually uncommon word is given a
larger weight to signify this importance.

The latent semantic indexing method then reduces the dimensions of the
matrix, clustering synonyms, words with similar topics, and words that
usually occur together. When comparing two paragraphs, the method
computes the cosine similarity between each paragraph's row vector.
Paragraphs that have similar topics will have a large cosine similarity
value.

As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of
the differences between a paragraph's Levenshtein ratios and LSI ratios,
the Levenshtein and LSI ratios demonstrate very different statistics. In
general, the topic similarity ratio is closer to one than the
levenshtein ratio.

\includegraphics{figs/distribution_of_differences.png}\\

By calculating the topic similarity between two concurrent versions of
an edited paragraph, the system can detect whether a significant change
has occurred. If the cosine similarity between the two paragraphs was
below an empirically determined threshold of 0.8, we label the edit as
significant.

\subsection{Predicting Future Edits}\label{predicting-future-edits}

We hypothesized that a paragraph that underwent a significant change
would cause inconsistencies in related paragraphs, prompting edits.
Therefore, we developed methods for predicting which paragraphs are
likely to change in future revisions as a result of significant edits in
other parts of the document

We considered three possible types of inter-paragraph relationships.
Paragraphs could be related by \emph{proximity}: perhaps the neighboring
paragraphs would require adjustments, as they are likely part of the
same section. Paragraphs could also be related by \emph{topic
similarity}. For example, in an academic paper, the discussion section
and the conclusion should present similar themes. If one changes, the
other may need to be edited to reflect this change. For each significant
change, we used the existing LSI Topic Model to determine which
paragraphs discussed similar topics. Lastly, paragraphs could be related
because of similar \emph{edit histories}. For each paragraph that
underwent a significant change, we evaluated the edit history of this
paragraph with every other paragraph in the document. We labeled pairs
as related if they changed or remained unchanged together over half the
time. With a higher threshold, the sample size decreases, but with a
lower threshold, the results become less predictive of a significant
change prompting further edits. This threshold strikes a balance between
these two outcomes, as discussed in the Findings section.

\section{Empirical Evaluation}\label{empirical-evaluation}

This section describes our preliminary evaluation of the proposed
methods, using a corpus of Wikipedia articles and their revision
histories.

\subsection{Data}\label{data}

Wikipedia is a unique source for collaborative writing, providing
extensive data. For our empirical evaluation, we used the complete
revision history of 41 different articles chosen from a diverse set of
topics, ranging from famous people and places to mathematical algorithms
to novels. This approach was used in various other papers
\cite{wohner2009assessing, fong2010did}. The revision histories were
downloaded as raw xml data. We removed Wikipedia-specific tags that
indicate formatting and other irrelevant data, and eliminated versions
of the articles under 150 characters, as they did not contain enough
information. To focus only on revisions that contain some substantial
changes, the versions with simple typo fixes~\footnote{We defined minor
  edits as having a Levenshtein distance of under fifteen.} were
eliminated as well to reduce the number of maintenance edits
\cite{kittur2007he}. This resulted in a total of 17,199 versions across
the 41 articles, with an average length of 25.71 paragraphs each.
Wikipedia data affords results applicable to other collaborative writing
spaces with smaller groups of collaborators, because although the
average article has over 400 contributing authors, most of these authors
make a one-time change. In our corpus, 15 authors on average made 80\%
of the edits to an article (see Figure~{[}fig:authors{]}).

\subsection{Findings}\label{findings}

\subsubsection{Detecting Significant
Changes}\label{detecting-significant-changes}

Using the LSI Topic Similarity model and a threshold ratio of 0.8, we
labeled about 15\% of the edits as significant, as shown in
Figure~{[}fig:lsi{]}.

\includegraphics{figs/LSI_sim_hist.JPG}\\

We evaluated a random sample of these edits to determine 1) that
paragraphs were correctly mapped and 2) that this method successfully
classifies edits. We provide an example of a significant edit below.
While these paragraphs are clearly the same, the edit is significant
because it contributes content and changes the tone of the paragraph.

OLD: After complaints arose during the renovation in the late 1980s of
the early residential colleges, a swing dormitory was built in 1998 to
facilitate housing students during the massive overhaul of buildings
that had seen only intermediate improvements in plumbing, heating,
electrical and network wiring, and general maintenance over their
35-to-80-year existence. The new Residence Hall is not a residential
college, but houses students from other colleges during renovations. It
is commonly called ``Swing Space'' by the students; it's official name
``Boyd Hall'' is unused. ---------------------------------------------
NEW: In 1990, Yale launched a series of massive overhauls to the older
residential buildings, whose decades of existence had seen only routine
maintenance and incremental improvements to plumbing, heating, and
electrical and network wiring. Calhoun College was the first to see
renovation. Various unwieldy schemes were used to house displaced
students during the yearlong projects, but complaints finally moved Yale
to build a new residence hall between the gym and the power plant. It is
commonly called ``Swing Space'' by the students; its official name
``Boyd Hall'' is unused.

\subsubsection{Predicting Future
Conflicts}\label{predicting-future-conflicts}

We evaluated various inter-paragraph relationships to determine which
paragraphs are more likely to require editing after a significant change
occurs in the article. As seen in Figure~{[}fig:edits{]}, where each
line represents a paragraph that is edited significantly at time zero
for the first time in a while, further adjustments (as represented by
downward spikes) are triggered in the near future.

\includegraphics{figs/change_after_streak.png}\\

We looked at two measures that indicate that a paragraph may need
attention. First, the related paragraphs experience at least one
significant change within the next ten versions, indicating that a
semantic discrepancy was introduced and required fixing. Second, and
more importantly, the related paragraphs relationship was correctly
predicted; that is, they are still related ten versions after the
significant change, meaning that they change together (or remain
unchanged together) more than half the time. This is a stronger
indication than just undergoing at least one significant change.

In the Wikipedia data, paragraphs related by edit history were found on
average 1.6 times per version, and paragraphs related by topic
similarity were rarer and only found on average once every ten versions
of the text.

With respect to the first measure, the relationships of edit history and
topic similarity are much more predictive than physical proximity, as
shown in Table~{[}table:futureEdits{]}. They are also significantly more
predictive than random sample controls. For controls, we compare with
the original paragraph as well as a random sample of any ten consecutive
versions within Wikipedia article histories.

{\textbar{}p{4cm}\textbar{}p{4cm}\textbar{}} \textbf{Relationship} \&
\textbf{Percentage of times there exists at least one significant
change}\\Edit History \& 81\%\\

Proximity \& 24\%\\

Paragraph with original change \& 40\%\\

Random sampled paragraph \& 15\%\\

More importantly, with respect to the second measure, we correctly
predicted 63\% of pairs related by topic and 71\% of pairs related by
edit history. Further, we obtained a recall of 80\% for these correct
predictions; thus, only 20\% of the paragraphs that should have been
labeled as related (based on information ten versions in the future)
were missed.

\begin{longtable}[c]{@{}llll@{}}
\caption{Ratio of correctly-predicted future linking by
relationship{}}\tabularnewline
\toprule
\textbf{Relationship} & \textbf{Ratio} & &\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Relationship} & \textbf{Ratio} & &\tabularnewline
\midrule
\endhead
Topic Similarity & 63\% & &\tabularnewline
Edit Similarity & 71\% & &\tabularnewline
Proximity{[}a{]}? & ? & &\tabularnewline
\bottomrule
\end{longtable}

Lastly, to ensure independence from specific articles, we calculated the
correlation between our statistics across all of our Wikipedia articles.
The correlation coefficient was 0.99 for all numbers.

\section{Discussion}\label{discussion}

As demonstrated by the long average lifespan of a paragraph, our
algorithm for tracking paragraphs throughout versions of an article is
capable of following paragraphs through complex edits. This provides the
basis for detecting significant changes and anticipating future semantic
conflicts. Our edit evaluation method successfully detects the most
significant changes using the LSI Topic Similarity model. Based on these
significant changes, we anticipate possible semantic conflicts in linked
paragraphs. After a significant change, paragraphs related to the edited
paragraph were indeed more likely to be edited in response a couple
versions later. Paragraphs linked by similar edit histories were most
likely to need editing, with paragraphs linked by topic similarity not
far behind.

In the future, we can build an assistive system that uses our methods to
improve the collaborative writing environment. The paragraph tracking
algorithm makes it possible to create a list of authors who have
contributed to a specific paragraph, which is crucial for determining
who to alert when significant edits occur. By labeling edits as
significant, the system can save authors time, since they will no longer
need to discern which of their peers' edits actually matter. Then, when
a significant edit occurs, the system can alert authors to related
paragraphs that will likely need adjusting, allowing authors to fix
semantic conflicts immediately, instead of discovering them later.

We imagined another helpful component for an assistive system that can
be based on our foundational methods. Using text summary algorithms, the
system could provide a succinct textual summary of significant changes
already detected, rather than just an output of the significant edits.

\section{Conclusion}\label{conclusion}

Our goal was to provide the algorithmic foundation for an intelligent
system that could assist in the field of collaborative writing. We
successfully formulated a method to detect which edits are most
significant. Consequently, we discovered that if significant edit
occurs, related paragraphs will probably also be edited. A proposed
assistive system will alert the relevant authors of related paragraphs
if this resulting edit does not occur. By detecting relationships
between paragraphs in a multi-authored paper, our system could predict
and alert if a significant change has the potential to create a semantic
conflict within the paper.
