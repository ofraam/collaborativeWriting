\section{Introduction}\label{introduction}

In order to assist with the collaborative writing process, we propose an
intelligent assistive system with two primary tasks. First, it should
detect important edits and promote them to the relevant authors. Second,
it should anticipate possible semantic conflicts between various
authors' contributions, alerting when appropriate in order to ensure
that the writing process goes smoothly.

When authors collaborate on a paper, they need to communicate constantly
to ensure they are on the same page. Because the authors need to make
sure their edits are coherent with the rest of the paper, including
sections written by others, they need to read the entire paper
frequently, or rely on updates communicated by their co-authors. Even
with constant communication, authors can get lost in the volume of edits
from other collaborators. Further, Kittur et al. have shown that in a
collaborative environment such as Wikipedia, the majority of edits no
longer add content but instead do maintenance work and add discussions
\cite{kittur2007he}. Therefore, an assistive system with a summary of
the significant changes contributed by other authors would be helpful,
as shown by Birnholtz et al. \cite{birnholtz2012tracking}..

We hypothesized that when an author makes a significant edit to a
paragraph, it eventually triggers a series of adjustments in related
paragraphs. In fact, a significant edit prompted changes in related
paragraphs eighty percent of the time. However, in collaborative
writing, these resulting edits do not occur instantaneously. Before
these adjustments occur, semantic conflicts might occur between the
authors' content. Instead of waiting for other authors to discover the
inconsistency caused by one author's edit, we want an assistive system
to predict when and where these conflicts may occur, in order to alert
even more specifically.

In order to achieve this, the system is composed of the following three
components: (1) tracking paragraphs; (2) identifying significant changes
to paragraphs, and (3) predicting future changes to the article.
Tracking paragraphs through paper revisions is a core capability
required for monitoring changes and predicting them. The identification
of significant content changes is helps the system promote only the most
important changes and decide whether to alert collaborating authors.
Predicting future changes enables the system to not only report changes
that have already been made, but also draw authors' attention to other
parts of the document that might require changes as a result of a recent
edit.

\subsection{Background}\label{background}

Systems that support collaborative writing can dramatically improve the
writing process, as shown by Birnholtz et al.
\cite{birnholtz2012tracking}.There has been some research on the topic
of analyzing relevant changes between two versions of a text. Neuwirth
et al. use flexible diffing \cite{neuwirth1992flexible} to detect and
report important changes. Fong et al. attempt to categorize edits
\cite{fong2010did}, which, according to Papadopoulou et al.
\cite{papadopoulou2007structured}, can be useful for detecting important
changes. Tam et al. developed an interface to show these categorized
changes to users \cite{tam2006framework}. Hainsworth et al.
\cite{hainsworth2006enabling} detect and alert authors about merge
conflicts. De Silva uses edit histories in order to find structure
within a text and to help co-authors write coherent documents
\cite{de2007narrative}. Nunes et al. analyze the impact of public events
on the frequency of edits in the collaborative writing environment,
Wikipedia, and argue that edits are predictable
\cite{nunes2008wikichanges}.

\section{Approach}\label{approach}

\subsection{Data}\label{data}

The described research is based on the revision history from a wide
variety of Wikipedia articles that undergo intense editing processes.
Wikipedia is a unique source because it presents extensive data for
collaborative writing. The findings use the complete revision revision
history of 41 different articles chosen from a diverse set of topics,
from famous people and places to mathematical algorithms to novels. This
approach was used in various other papers
\cite{wohner2009assessing, fong2010did}. The revision histories were
downloaded as raw xml data. We removed Wikipedia-specific tags that
indicate formatting and other irrelevant data, and eliminated versions
of the articles under 150 characters, as they did not contain enough
information. To focus only on revisions with consequential changes, the
versions with simple typo fixes~\footnote{We defined minor edits as
  having a Levenshtein distance of under fifteen.} were eliminated as
well to reduce the number of maintenance edits \cite{kittur2007he}. This
resulted in a total of 17,199 versions across the 41 articles, with an
average length of 25.71 paragraphs. Wikipedia data affords results
applicable to other collaborative writing spaces, because although the
average article has over 400 contributing authors, most of these authors
make a one-time change. In fact, on average, 15 authors make 80\% of the
edits to an article (see Figure~{[}fig:authors{]}). This enables the
consideration of interactions between authors, which is crucial for
learning about collaborative behavior.

\includegraphics{figs/authors_contrib.JPG}\\

\subsection{Tracking paragraphs}\label{tracking-paragraphs}

We developed a novel mapping algorithm that uses the Levenshtein edit
ratio measure, which is defined as follows:
\(Levenshtein Ratio(a,b) = 1-\frac{Levenshtein Distance(a,b)}{max(|a|,|b|)} \)

A Levenshtein ratio close to one between two paragraphs indicates a high
similarity between them, while a ratio close to zero indicates the
opposite. For each revision, we computed the Levenshtein ratio between
each paragraph in the old version and each paragraph in the new version.
Two paragraphs are mapped across the revision if they each had the
highest Levenshtein ratio for the other. If a paragraph in the new
version had no ``matches'', meaning that none of its ratios were above a
threshold of 0.4, this paragraph was new. If a paragraph in the old
version had no ``matches'', then it was deleted in the revision.
Figure~{[}fig:mapping{]} demonstrates this algorithm: paragraphs 9, 10
and 12 of the old version were deleted, while the others found clear
matches.

\includegraphics{figs/mapping_example.png}\\

\subsection{Detect Significant
Changes}\label{detect-significant-changes}

We define a significant change as a noticeable change in the paragraph's
topic and content. For this calculation, the Levenshtein ratio does not
provide the right kind of information. For example, if two of the
paragraph's sentences switch places, the Levenshtein ratio would
decrease despite no meaningful change in content. On the other hand,
changing a couple key words will slightly lower the Levenshtein ratio,
but could drastically affect the content.

As shown in figure~{[}fig:difflevtop{]}, which shows the distribution of
the differences between a paragraph's Levenshtein ratios and LSI ratios,
the Levenshtein and LSI ratios demonstrate very different statistics. In
general, the topic similarity ratio is closer to one than the
levenshtein ratio, but the scores are not correlated.

\includegraphics{figs/distribution_of_differences.png}\\

Therefore, we use a topic modeling approach, which is a better fit for
assessing changes in content. Latent Semantic Indexing
\cite{deerwester1990indexing} is a form of topic modeling that
calculates the topic similarity between two texts. Its strengths lie in
accounting for synonyms and not penalizing for typographical errors. The
process begins by composing a corpus for each Wikipedia article from all
of the documents (paragraphs of the versions of the article). It
analyzes tokens (a specific instance of a word), eliminating those that
only occur once, as well as stopword tokens, such as `the' or `and'. It
then creates a TF-IDF matrix, which assigns a weight to every token in
each document, which indicates the importance of that token for this
document. This weight increases proportionally to the frequency of the
word in the document, but accounts for the frequency of the word in the
corpus, such that the frequent occurrence of a usually uncommon word is
given a larger weight to signify this importance.

The latent semantic indexing method then reduces the dimensions of the
matrix, clustering synonyms, words with similar topics, and words that
usually occur together. When comparing two paragraphs, the method
computes the cosine similarity between each paragraph's row vector.
Paragraphs that have similar topics will have a large cosine similarity
value.

By calculating the topic similarity between two concurrent versions of
an edited paragraph, the system can detect whether a significant change
has occurred. If the cosine similarity between the two paragraphs was
below an empirically determined threshold of 0.8, we label the edit as
significant.

\subsection{Predicting Future
Conflicts}\label{predicting-future-conflicts}

We hypothesized that a paragraph that underwent a significant change
would cause inconsistencies in related paragraphs, prompting edits.
Therefore, in order to predict future conflicts, an assistive system
needs to detect significant changes and then determine consequently
which paragraphs were most likely to change.

We looked at three possible types of inter-paragraph relationships.
Paragraphs could be related by physical proximity: perhaps the
neighboring paragraphs would require adjustments, as they are likely
part of the same section. Paragraphs could also be related by topic. For
example, in an academic paper, the discussion section and the conclusion
should present similar themes. If one changes, the other may need to be
edited to reflect this change. For each significant change, we used the
existing LSI Topic Model to determine which paragraphs discussed similar
topics. Lastly, paragraphs could be related because of similar edit
histories. For each significant change, we evaluated the edit history of
this paragraph with every other paragraph in the article. We labeled
pairs as related if they changed or remained unchanged together over
half the time. With a higher threshold, the sample size decreases, but
with a lower threshold, the results become less predictive of a
significant change prompting further edits. This threshold strikes a
balance between these two outcomes.

To evaluate these both of these suspected relationships, we looked at
the related paragraphs' edit patterns in the ten versions following the
significant change. If the related paragraphs changed together over half
the time, the paragraphs with this relationship proved to be related in
the future, verifying the relationship at the time of the significant
change.

\section{Findings}\label{findings}

\subsection{Tracking Paragraphs}\label{tracking-paragraphs-1}

To evaluate the method for tracking paragraphs through consecutive
versions of a paper, we calculated the number of versions from the
paragraphs' inception to its demise. On average, paragraphs lasted 83
article revisions.

\subsection{Detecting Significant
Changes}\label{detecting-significant-changes}

Using the LSI Topic Similarity model and a threshold ratio of 0.8, we
labeled about 15\% of the edits as significant, as shown in
Figure~{[}fig:lsi{]}..

\includegraphics{figs/LSI_sim_hist.JPG}\\

We evaluated a random sample of these edits to determine that this
method successfully classifies edits. We provide an example of a
significant edit below. While these paragraphs are clearly the same, the
edit is significant because it contributes content and changes the tone
of the paragraph.

OLD: After complaints arose during the renovation in the late 1980s of
the early residential colleges, a swing dormitory was built in 1998 to
facilitate housing students during the massive overhaul of buildings
that had seen only intermediate improvements in plumbing, heating,
electrical and network wiring, and general maintenance over their
35-to-80-year existence. The new Residence Hall is not a residential
college, but houses students from other colleges during renovations. It
is commonly called ``Swing Space'' by the students; it's official name
``Boyd Hall'' is unused. ---------------------------------------------
NEW: In 1990, Yale launched a series of massive overhauls to the older
residential buildings, whose decades of existence had seen only routine
maintenance and incremental improvements to plumbing, heating, and
electrical and network wiring. Calhoun College was the first to see
renovation. Various unwieldy schemes were used to house displaced
students during the yearlong projects, but complaints finally moved Yale
to build a new residence hall between the gym and the power plant. It is
commonly called ``Swing Space'' by the students; its official name
``Boyd Hall'' is unused.

\subsection{Predicting Future
Conflicts}\label{predicting-future-conflicts-1}

We evaluated various inter-paragraph relationships to determine which
paragraphs are more likely to require editing after a significant change
occurs in the article. As seen in Figure~{[}fig:edits{]}, when a
paragraph is edited for the first time in a while, further adjustments
are triggered in the near future.

\includegraphics{figs/change_after_streak.png}\\

We looked at two measures that indicate that a paragraph may need
attention. First, the related paragraphs experience at least one
significant change within the next ten versions, indicating that a
semantic discrepancy was introduced and required fixing. Second, and
more importantly, the related paragraphs relationship was correctly
predicted; that is, they are still related ten versions after the
significant change, meaning that they change together (or remain
unchanged together) more than half the time. This is a stronger
indication than just undergoing at least one significant change.

With respect to the first measure, the relationships of edit history and
topic similarity are much more predictive than physical proximity, as
shown in Table~{[}table:futureEdits{]}. They are also significantly more
predictive than random sample controls. For controls, we compare with
the original paragraph as well as a random sample of any ten consecutive
versions within Wikipedia article histories.

{\textbar{}p{4cm}\textbar{}p{4cm}\textbar{}} \textbf{Relationship} \&
\textbf{Percentage of times of at least one significant change}\\Edit
History \& 81\%\\ Proximity \& 24\%\\

Paragraph with original change \& 40\%\\

Random sampled paragraph \& 15\%\\

Relationship or Control Percentage of times that paragraph experienced
at least one significant change Edit History 81\% Topic Similarity .
Physical Proximity 24\% Paragraph with original significant change 40\%
Random Sample of Paragraphs 15\%

More importantly, with respect to the second measure, we correctly
predicted 63\% of pairs related by topic and 71\% of pairs related by
edit history. Further, we obtained a recall of 80\% for these correct
predictions; thus, only 20\% of the paragraphs that should have been
labeled as related (based on information ten versions in the future)
were missed.

\begin{longtable}[c]{@{}llll@{}}
\caption{Linked paragraphs by relationship.{}}\tabularnewline
\toprule
\textbf{Relationship} & \textbf{N} & \textbf{Linked} &
\textbf{Ratio}\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Relationship} & \textbf{N} & \textbf{Linked} &
\textbf{Ratio}\tabularnewline
\midrule
\endhead
Topic Similarity & 1,869 & 1,203 & 63\%\tabularnewline
Edit Similarity & 27,722 & 19,685 & 71\%\tabularnewline
Proximity? & ? & ? & ?\tabularnewline
\bottomrule
\end{longtable}

Relationship Number Found Successfully Linked Ratio of Successfully
Linked Topic Similarity 1,869 1,203 63\% Editing History 27,722 19,685
71\%

Lastly, to ensure independence from specific articles, we calculated the
correlation between our statistics across all of our Wikipedia articles.
The correlation coefficient was 0.99 for all numbers.

\section{Discussion}\label{discussion}

As demonstrated by the long average lifespan of a paragraph, our
algorithm for tracking paragraphs throughout versions of an article is
capable of following paragraphs through complex edits. This provides the
basis for detecting significant changes and anticipating future semantic
conflicts. Our edit evaluation method successfully detects the most
significant changes using the LSI Topic Similarity model. Based on these
significant changes, we anticipate possible semantic conflicts in linked
paragraphs. After a significant change, paragraphs related to the edited
paragraph were indeed more likely to be edited in response a couple
versions later. Paragraphs linked by similar edit histories were most
likely to need editing, with paragraphs linked by topic similarity not
far behind.

In the future, we can build an assistive system that uses our methods to
improve the collaborative writing environment. The paragraph tracking
algorithm makes it possible to create a list of authors who have
contributed to a specific paragraph, which is crucial for determining
who to alert when significant edits occur. By labeling edits as
significant, the system can save authors time, since they will no longer
need to discern which of their peers' edits actually matter. Then, when
a significant edit occurs, the system can alert authors to related
paragraphs that will likely need adjusting, allowing authors to fix
semantic conflicts immediately, instead of discovering them later.

We imagine a couple other helpful components for an assistive system
that our methods could provide the foundation for. Using text summary
algorithms, the system could provide a succinct textual summary of
significant changes already detected. The system could also \ldots{}.

\section{Conclusion}\label{conclusion}

Both of these measures of relatedness are successful in determining
whether a paragraph will change together in the future. Consequently, we
assert that if significant edit occurs, related paragraphs should also
be edited. A proposed assistive system will alert the relevant authors
of related paragraphs if this resulting edit does not occur. By
detecting relationships between paragraphs in a multi-authored paper,
our system can predict and alert appropriate authors if a significant
change has the potential to create a semantic conflict within the paper.
