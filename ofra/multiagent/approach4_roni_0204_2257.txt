\section{An Auction for Multi-Agent Pathfinding}
\label{sec:approach}

%This section describes my approach to representing and solving the MAPF problem with iterative combinatorial auctions. 
This section describes how to implement iBundle in the MAPF domain drawing on insights and techniques from both the MAPF and auction literature×“. We use the term MAPF-iBundle to refer to this iBundle implementation. 
%In the context of MAPF, we can use an the iBundle auction mechanism to allocate non-colliding paths to agents. 

The items in MAPF-iBundle are pairs of grid location and time step. A bundles correspond to a set of location-times pairs that together constitute a path. The auction begins with an ask price of $0$ assigned to all bundles (paths). We next describe the implementation of each component of the auction. This implementation assumes that edges have a uniform cost and that agents have infinite budgets where each unit in the budget corresponds to a travel cost of 1 time step. I.e. waiting for one time step corresponds to spending one budget unit. These assumption are made in typical MAPF algorithms and are fitting with fully cooperative settings. We discuss extensions to more general settings later.

We use as a running example the problem shown in Figure~\ref{fig:mapf}(a). Agents (depicted by the mice icons) are located on grid squares and need to reach their corresponding goal location. For example,  $a_1$'s starting location is $(0,1)$ and its goal is located at square $(1,1)$). Agents can move one square at each time step, vertically or horizontally. Only one agent can be present in a grid location at any time and agents are assumed to stay at the goal location once they arrive there.  If each of the agents $a_1$, $a_2$ and $a_3$ were alone on the grid, their shortest paths would be of cost 1, 2 and 4 respectively. However, no combination of their shortest paths does not collide and at least one agent has to wait. The optimal allocation of paths in this problem has a total cost of 8, rather than 7 which is the sum of the shortest individual paths. We denote agents' travel costs by $c$. 


% It terminates when the provisional allocation includes all agents. 
%We next describe how to model each component of the auction mechanism, focusing on the representation and computational challenges that arise in the pathfinding domain and how we solve them drawing on insights from both the pathfinding and auction literatures. 
%Finally, I describe the independence-detection framework~\cite{standley2010finding} which I used to decompose the auction to multiple, smaller auctions.

\subsection{Bidding on Paths}

%In the MAPF domain we can assume that each agent has an infinite budget, and that units of this budget correspond to path cost units. I.e.. waiting for one time step corresponds to spending one budget unit.

 Agents' valuations for bundles, or paths, are relative -- for example, $a_1$ will be willing to pay for its shortest path with $c=1$ up to one unit more than for a path with $c=2$ (for example, a path in which it waits at its starting location for one turn and only then moves to $(1,1)$). 
 % if there is a path $A$ with cost $c_a$ and a path $B$ of cost $c_{b} = c_{a}+1$, an agent would be willing to pay up to one unit more on path $A$ compared to path $B$. However, there is no absolute limit to the amount an agent would be willing to pay for a particular path.
We implemented a myopic best response bidding strategy~\cite{parkes1999bundle} for the agents. According to this strategy, agents bid at each iteration on paths that minimize $c+p$, where $p$ denotes the current price of the path in the auction. 
%A bid is represented by a tuple $\langle c,p \rangle$.
For example, in the first iteration of an auction solving the problem shown in Figure~\ref{fig:mapf}, $a_1$ would bid on its shortest path, $[\langle(0,1),t_1\rangle,\langle(1,1),t_2\rangle]$. $a_2$ would place a $XOR$ bid on its three shortest paths:$[\langle(0,2),t_1\rangle,\langle(0,1),t_2,\langle(1,1),t_3,\langle(2,1),t_4\rangle]$; $[\langle(0,2),t_1\rangle,\langle(1,2),t_2,\langle(1,1),t_3,\langle(2,1),t_4\rangle]$; $[\langle(0,2),t_1\rangle,\langle(1,2),t_2,\langle(2,2),t_3,\langle(2,1),t_4\rangle]$. Similarly, $a_3$ will bid on all of its shortest paths (paths with $c=4$). Note that if agents bid on paths that end at an earlier time than some of the other agents' paths, we extend their paths by adding their last location to the next time steps.

As prices increase, agents begin to consider longer paths. Specifically, their best response should include all paths that reach the goal with a minimum value of $c+p$. For example, given that all paths with $c=3$ that $a_2$ can traverse to reach its goal are priced at 1 ($p=1$) and paths with $c=4$ are priced at 0, $a_2$ will bid on all paths with $c=3$ at price 1 and all paths with $c=4$ at price 0, as they have the same total cost ($c+p=4$). 

Importantly, there could be exponentially more paths for an agent when increasing cost. This is because the agent can consider waiting at any of the location on its lower cost paths, as well as finding new paths of that cost.
This increase in the number of bundles (paths) agents bid on is atypical of auction problems and poses a representation problem as well as a computational difficulty for the winner determination problem (which is already computationally hard). To address these problems, agents bid on MDDs that compactly represent their desired paths. Note that the cost used in the MDDs refers to the travel cost ($c$) and does not consider the prices of the MDDs in the auction. Each bid can therefore be represented by the pair $\langle mdd,p_{mdd} \rangle$.

Figure~\ref{fig:mapf}(b) shows the MDD for agent $a_2$ with $c=3$. This MDD represents all of the paths that $a_2$ can take from its location to its goal, at a cost of 3. Each level of the MDD includes all of the locations that $a_2$ might be at in a specific time step when traversing a path of cost 3 to the goal. An edge connects an MDD node with locations in the next level that can be arrived at from the current location. For example, at level 1, $a_2$ could be at either location $(1,2)$ or $(0,1)$. From $(1,2)$ it can move to either $(1,1)$ or $(2,2)$, while from $(0,1)$ it can only move to $(1,1)$ in order to reach the goal in cost 3. As explained above, we align the MDDs to have the same cost by replicating the goal node in the next time steps as show for agent $a_1$ in Figure~\ref{fig:mapf}(c) (dashed nodes and edges were added to match the length of $a_2$'s MDD).




\subsection{Winner Determination}
At the end of each iteration, a \emph{provisional allocation} is determined. The provisional allocation is chosen such that it maximizes revenue and includes non-conflicting paths for the set of agents included in the allocation. Ties are broken in favor of allocations that include more agents. In the example problem shown in Figure~\ref{fig:mapf}(a), the provisional allocation at the end of the first iteration will include one of the three possible pairs of agents. This is because there is no combination of the three agents' shortest paths that does not conflict. However, all pairs of MDDs are possible as they include at least one non-conflicting combination of paths. Therefore, one of these pairs will be chosen (recall ties are broken in favor of more agents, so there is no reason to include only one agent in the provisional allocation). This means that at the end of this iteration two agents will be included in the provisional allocation while the third agent will remain ``unhappy''.  


%The winner determination problem is computationally hard~\cite{sandholm2002algorithm}: a naive approach would need to consider all possible combinations of paths that could be assigned to each subset of agents in the problem. For example, given the bids from the agents in the problem shown in Figure~\ref{fig:mapf}, the winner determination process needs to consider an allocation that includes all three agents (which requires considering every combination of the paths they bid on), the 3 combinations of two agents (again, considering all their possible paths combinations based on bids) and finally all allocations that include only one of the agents, one for each of its bids. 


At a high-level, the winner determination (WD) problem has the following components: (1) generating candidate allocations based on agents' bids; (2) checking whether the allocation is feasible, and (3) computing the revenue of each allocation and choosing the candidate allocation that gives the highest revenue. Auctions typically have a limited set of items and checking the feasibility of an allocation simply goes over the requested items and verifies that no item is requested by two agents. 

%The pathfinding domain poses additional computational challenges for the winner determination process. First, the set of items is very large due to the time dimension. Second, agents have relative valuations for MDDs. This means agents keep bidding on all paths they bid on in previous iterations, resulting in a large number of bids and an increasing number of candidate allocations to be considered. Finally, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD.
% In the pathfinding domain, checking whether an allocation is feasible requires solving a sub-problem of the complete pathfinding problem, namely searching for non-conflicting paths for the agents given their MDD. This problem requires significant computation, making the winner determination a particularly hard problem in the pathfinding context. 

We used a Branch and Bound search to generate candidate allocations, pruning allocations that have lower revenue than the best allocation found so far. This approach is similar to that proposed by Sandholm~\cite{sandholm2002algorithm} with some modifications to allow it to work with MDDs rather than searching the space of individual bundles. Using MDDs, we reduce this computational complexity of the feasibility verification, eliminating the need to consider every possible path separately. To check whether a candidate allocation is feasible, we use and algorithm for solving a set of MDDs introduced by Sharon et al.~\cite{sharon2012increasing}. Computing the revenue of an allocation is straightforward (summing the prices of the MDDs in the allocation).


\subsection{Price Update}
Price updating in iBundle works as follows: initial prices for all bundles are $0$. At the end of each iteration, the prices of bundles that ``unhappy'' agents bid on are raised. Specifically, the price is raised to the maximal amount bid on the bundle by an agent plus $epsilon$, where $epsilon$ is a parameter of the acution. We implement the same mechanism and increase the prices for any MDD that an ``unhappy'' agent bid on. The MDDs compactly represent all the paths (bundles) agents bid on, and we can increase the price of the entire MDD directly rather than considering each path separately.\footnote{We assume that no two agents bid on the same bundles (MDDs) and thus agents are not affected by changes in prices for bundles (MDDs) of other agents. This is a reasonable assumption as agents typically have different starting locations and goals. If a path of an agent is a subset of a path of another agent, our approach can be viewed as discriminatory pricing, where different agents have different prices for the same bundle~\cite{parkes2001iterative}.}


For example, recall that at the end of the first iteration of an auction for the problem from Figure~\ref{fig:mapf}(a), the provisional allocation includes two agents. Let us assume that $MDD^3_2$ and $MDD^1_1$ were arbitrarily chosen to be included in the provisional allocation. Then, the price for the paths $a_3$ bid on, namely $MDD^4_3$, is raised by $\epsilon$. 


The choice of $\epsilon$ in the auction affects the efficiency of the algorithm. Generally, as $\epsilon$ approaches $0$ the iBundle auction is known to terminate with the optimal (most efficient) allocation when agents submit their myopic best response bids at each iteration. However, using smaller values of $\epsilon$ leads to more iterations of the auctions and thus sometimes a larger value is preferred in order to terminate earlier. 

Interestingly, due to the particular valuation function in MAPF, while increasing $\epsilon$ leads to fewer iterations, each iteration requires more computation in the winner determination stage. This is because when we increase the price of an MDD by a greater amount, agents will bid on additional MDDs. For example, consider increasing the price of paths with travel cost 4 from 0 to 5. Now, the agent should bid on all paths that are within $\epsilon$ of its best price. It will thus submit more bids (i.e., MDDs with $c=5,6,7$ and $8$). This requires more computation at each iteration and therefore does not reduce complexity. We used $epsilon=1$ in our implementation, as this is the smallest increment that would cause agents to submit bids on new MDDs. Choosing lower value will only make the auction slower, but will not lead to a different result.



\subsection{Allocation Efficiency}
It has been proven that iBundle with myopic best response bids finds the optimal allocation as  $\epsilon \rightarrow 0$~\cite{parkes2006iterative}. In the pathfinding domain, settings $\epsilon = 1$ would result in the same bids as setting any $\epsilon \rightarrow 0$. This is because agents are indifferent between a path with $c=x$ and $p=y$ and a path with $c=x$ and $p=y-1$. They will therefore not submit new bids until the price of an MDD increments by 1 (they will just bid higher on the same bid, but this cannot lead to a solution). Thus, using $\epsilon=1$ is sufficient for the auction to terminate with the optimal allocation with agents bidding their myopic best response at each iteration of the auction. 
